\documentclass[12pt,a4paper,figuresright]{book}
%\documentclass[12pt,a4paper,figuresright]{book}

% make sure sessions and talks are not split between pages
\usepackage{needspace}
\usepackage{hyperref}
\usepackage{bm}

\ExplSyntaxOn
\cs_new:Npn \expandableinput #1
{ \use:c { @@input } { \file_full_name:n {#1} } }
\AddToHook{env/tabular/begin}
{ \cs_set_eq:NN \input \expandableinput }
\AddToHook{env/tabularx/begin}
{ \cs_set_eq:NN \input \expandableinput }
\ExplSyntaxOff

% These commands show the draft water mark
%\usepackage{draftwatermark}
%\SetWatermarkAngle{60}
%\SetWatermarkLightness{0.85}
%\SetWatermarkFontSize{5cm}
%\SetWatermarkScale{8.5}
%\SetWatermarkText{DRAFT}

\usepackage{tabularx,booktabs,enumitem}
\usepackage{multirow,multicol}
% The package allows rows and columns to be coloured, and even individual cells.
\usepackage{colortbl,longtable}
\usepackage{amsmath,amssymb,ifthen}
\usepackage{graphicx,url,wrapfig,xcolor,rotating,epsfig}

%===== Define geometry of the page
\setlength{\textheight}{25.2cm}
\setlength{\textwidth}{16.5cm} %\setlength{\textwidth}{18.2cm}
\setlength{\voffset}{-1.6cm}
\setlength{\hoffset}{-0.3cm} %\setlength{\hoffset}{-1.2cm}
\setlength{\evensidemargin}{-0.3cm}
\setlength{\oddsidemargin}{0.3cm}
\setlength{\parindent}{0cm}
\setlength{\parskip}{0.3cm}

\renewcommand{\topfraction}{1}
\renewcommand{\textfraction}{0}
\setlength{\floatsep}{12pt plus 2pt minus 2pt}

\hyphenation{quasi-random}
\hyphenation{models}
\hyphenation{poly-nomial}
\hyphenation{poly-nomials}

\definecolor{MySpecial1}{rgb}{0.9,1,0.9} % lighter green
\definecolor{MySpecial2}{rgb}{0.75,1,0.75} % green
\definecolor{MySpecial3}{rgb}{0.6,1,0.6} % darker green
\definecolor{MyPlenary}{rgb}{1,1,0.8} % yellow
\definecolor{MyEvent}{rgb}{1,0.83,0.61} % orange
\definecolor{MyBlank}{rgb}{0.97,0.97,0.97} % gray

\definecolor{UWGrey1}{HTML}{DFDFDF} % light grey
\definecolor{UWGrey2}{HTML}{A2A2A2} % bright grey
\definecolor{UWGrey3}{HTML}{787878} % grey
\definecolor{UWGrey4}{HTML}{000000} % dark grey

\definecolor{UWYellow1}{HTML}{F2EDA8} % light yellow
\definecolor{UWYellow2}{HTML}{FAE100} % bright yellow
\definecolor{UWYellow3}{HTML}{FED34C} % yellow
\definecolor{UWYellow4}{HTML}{EAAB00} % dark yellow

\definecolor{UWPink0}{HTML}{FFBEEF} % lighter pink
\definecolor{UWPink1}{HTML}{EFBBF0} % light pink
\definecolor{UWPink2}{HTML}{EF60AD} % bight pink
\definecolor{UWPink3}{HTML}{DF1AA0} % pink
\definecolor{UWPink4}{HTML}{A2006E} % dark pink

\newcommand{\EmptyColor}{UWGrey1}
\newcommand{\EventColor}{UWGrey1}
\newcommand{\PlenaryColor}{UWYellow3}
\newcommand{\TutorialColor}{UWYellow2}
\newcommand{\SessionTitleColor}{UWPink2}
\newcommand{\SessionLightColor}{UWPink1}
\newcommand{\SessionDarkColor}{UWPink0}

\newcommand{\update}[1]{\begingroup\color{blue}#1\endgroup}
\newcommand{\todo}[1]{\begingroup\color{red}#1\endgroup}

\newcommand{\scnote}[1]{{\color{red}{\bf Sou-Cheng}: #1}}

% ------------------------------------------------------------------------
% New Definitions
% ------------------------------------------------------------------------

\newcommand{\mask}[1]{}		% this comment is not used, consider deleting it

\makeatletter
\newcommand{\clearemptydoublepage}{%
 \newpage{\pagestyle{empty}{\cleardoublepage}}}

% -- chapter ---------------------------------------------------------------
% -- starts on a new odd page with no page number
% -- no numbering
% -- appears in the table of content
% -- becomes the running header on even pages
\renewcommand{\chapter}{%
 \clearemptydoublepage\thispagestyle{empty}%
 \secdef \Chapter \sChapter}%
\newcommand{\Chapter}[2][default]{\sChapter {#2}}%
\newcommand{\sChapter}[1]{%
 \refstepcounter{chapter}%
 \addcontentsline{toc}{chapter}{#1}%
 \markboth{{\sffamily\small#1}}{{\sffamily\small#1}}%
 \quad\vskip 8cm\hfill{\sffamily\Huge #1}\vskip 0.5cm\hrule%\vskip 1 cm% %\clearpage%
 \pagebreak%
 }

% -- section ---------------------------------------------------------------
% -- starts on a new page with no page number
% -- no numbering
% -- appears in the table of content
% -- becomes the running header on odd pages
\renewcommand{\section}{%
 \clearpage%
 \secdef \Section \sSection}%
\newcommand{\Section}[2][default]{\sSection {#2}}%
\newcommand{\sSection}[1]{%
 \refstepcounter{section}%
 \addcontentsline{toc}{section}{#1}%
 \markright{{\sffamily\small #1}}%
 {\sffamily\Large #1}\vskip 0.3cm\hrule\vskip 0.6cm%
 }

% -- table of contents -----------------------------------------------------
% -- looks like a section
\renewcommand\tableofcontents{%
 \section{\contentsname}%
 \@starttoc{toc}%
 }

% -- other sectioning commands ---------------------------------------------
% -- no numbering
% -- change the font style
\setcounter{secnumdepth}{-2}
\renewcommand\subsection{\@startsection {subsection}{1}{\z@}%
 {-3.5ex \@plus -1ex \@minus -.2ex}%
 {2.3ex \@plus.2ex}%
 {\sffamily\large\underline}}
\renewcommand\subsubsection{\@startsection{subsubsection}{2}{\z@}%
 {-3.25ex\@plus -1ex \@minus -.2ex}%
 {1.5ex \@plus .2ex}%
 {\sffamily\large}}
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}%
 {3.25ex \@plus1ex \@minus.2ex}%
 {-1em}%
 {\normalfont\normalsize\bfseries}}
\renewcommand\subparagraph{\@startsection{subparagraph}{5}{\parindent}%
 {3.25ex \@plus1ex \@minus .2ex}%
 {-1em}%
 {\normalfont\normalsize\bfseries}}

% -- bibliography ---------------------------------------------------------
% -- just comment out two lines so that it is not a chapter
\renewenvironment{thebibliography}[1]
 {%\chapter*{\bibname
 % \@mkboth{\MakeUppercase\bibname}{\MakeUppercase\bibname}}%
 \list{\@biblabel{\@arabic\c@enumiv}}%
 {\settowidth\labelwidth{\@biblabel{#1}}%
 \leftmargin\labelwidth
 \advance\leftmargin\labelsep
 \@openbib@code
 \usecounter{enumiv}%
 \let\p@enumiv\@empty
 \renewcommand\theenumiv{\@arabic\c@enumiv}}%
 \sloppy\clubpenalty4000\widowpenalty4000%
 \sfcode`\.\@m}
 {\def\@noitemerr
 {\@latex@warning{Empty `thebibliography' environment}}%
 \endlist}

\makeatother

% -- adding a talk
\newcounter{talk}
\newenvironment{talk}[9]% [1] talk title
 % [2] speaker name, [3] affiliations, [4] email,
 % [5] coauthors, [6] special session
 % [7] time slot
 % [8] talk id, [9] session id or photo
 {\needspace{6\baselineskip}%
 \refstepcounter{talk}
 \vskip 0pt\nopagebreak%
 \colorbox{UWPink0}{\makebox[\textwidth][r]{#7}}\nopagebreak%
 \ifthenelse{\equal{#9}{photo}}{%
 \\\\\colorbox{UWPink0}{\makebox{\includegraphics[width=3cm]{./Photos/#8.jpg}}} 
 %\ifthenelse{\equal{#10}{}{}}{#10}
 \nopagebreak}{}%
 \vskip 0pt\nopagebreak%
 \label{#8}%
 \textbf{#1}\vspace{3mm}\\\nopagebreak%
 \textit{#2}\\\nopagebreak%
 #3\\\nopagebreak%
 \url{#4}\vspace{3mm}\\\nopagebreak%
 \ifthenelse{\equal{#5}{}}{}{Coauthor(s): #5\vspace{3mm}\\\nopagebreak}%
 \ifthenelse{\equal{#6}{}}{}{Special session: #6\quad p.\pageref{#9}\vspace{3mm}\\\nopagebreak}%
}
 {\leavevmode\vspace{1cm}\\\nopagebreak}%

 % -- adding a talk with photo credit
\newcounter{talkcr}
\newenvironment{talkcr}[9]% [1] talk title
 % [2] speaker name, [3] affiliations, [4] email,
 % [5] coauthors, [6] special session
 % [7] time slot
 % [8] talk id, [9] session id or photo
 {\needspace{6\baselineskip}%
 \refstepcounter{talkcr}
 \vskip 0pt\nopagebreak%
 \colorbox{UWPink0}{\makebox[\textwidth][r]{#7}}\nopagebreak%
 \ifthenelse{\equal{#9}{photo}}{%
 \\\\\colorbox{UWPink0}{\makebox{\includegraphics[width=3cm]{./Photos/#8.jpg}}} 
 %\ifthenelse{\equal{#10}{}{}}{#10}
 {\tiny Photo: @ Claudia B\"orner}
 \nopagebreak}{}%
 \vskip 0pt\nopagebreak%
 \label{#8}%
 \textbf{#1}\vspace{3mm}\\\nopagebreak%
 \textit{#2}\\\nopagebreak%
 #3\\\nopagebreak%
 \url{#4}\vspace{3mm}\\\nopagebreak%
 \ifthenelse{\equal{#5}{}}{}{Coauthor(s): #5\vspace{3mm}\\\nopagebreak}%
 \ifthenelse{\equal{#6}{}}{}{Special session: #6\quad p.\pageref{#9}\vspace{3mm}\\\nopagebreak}%
}
 {\leavevmode\vspace{1cm}\\\nopagebreak}%

 % -- adding a panel session
\newcounter{talkp}
\newenvironment{talkp}[5]% [1] talk title
 % [2] speaker name, [3] panelists  [4] time slot
 % [5] talk id
 {\needspace{6\baselineskip}%
 \refstepcounter{talkp}
 \vskip 0pt\nopagebreak%
 \colorbox{UWPink0}{\makebox[\textwidth][r]{#4}}\nopagebreak%
 %\ifthenelse{\equal{#9}{photo}}{%
 %\\\\\colorbox{UWPink0}{\makebox{\includegraphics[width=3cm]{./Photos/#8.jpg}}}
 %\ifthenelse{\equal{#10}{}{}}{#10}
 %{\tiny Photo: @ Claudia B\"orner}
 %\nopagebreak}{}%
 \vskip 0pt\nopagebreak%
 \label{#5}%
 \textbf{#1}\vspace{3mm}\\\nopagebreak%
 \textit{Moderator: #2}\\\nopagebreak%
 %#3\\\nopagebreak%
 %\url{#4}\vspace{3mm}\\\nopagebreak%
 \ifthenelse{\equal{#3}{}}{}{Panelists: #3\vspace{3mm}\\\nopagebreak}%
 %
}
 {\leavevmode\vspace{1cm}\\\nopagebreak}%

% -- adding a special session
\usepackage{titlecaps}
\Resetlcwords
\Addlcwords{and as but for if nor or so yet} % short conjunctions
\Addlcwords{a an the} % articles
\Addlcwords{as at by for in of off on per to up via} % short prepositions
\newcounter{specialsession}
\newenvironment{session}[9] % [1] session title
 % [2] organiser name, [3] affiliations, [4] email
 % [5] organiser name, [6] affiliations, [7] email
 % [8] session id
 % [9] third organiser info, if any
 {\needspace{6\baselineskip}
 \refstepcounter{specialsession}
 \vskip 0pt\nopagebreak%
 \label{#8}%
% \textbf{Special Session~\ifnum\value{specialsession}<10 0\fi\arabic{specialsession}. 
\textbf{\titlecap{#1}}\vspace{3mm}\\\nopagebreak%
 \ifthenelse{\equal{#5}{}}{Organizer:}{Organizers:}\vspace{2mm}\\\nopagebreak%
 \textit{#2}\\\nopagebreak%
 #3\\\nopagebreak%
 \url{#4}\vspace{3mm}\\\nopagebreak%
 \ifthenelse{\equal{#5}{}}{}{\textit{#5}\\\nopagebreak%
 #6\\\nopagebreak%
 \url{#7}\vspace{3mm}\\\nopagebreak}%
 \ifthenelse{\equal{#9}{}}{}{#9}%
 \quad\\\nopagebreak%
 \textbf{Session Description}:\\\nopagebreak%
}
 {\vskip 0pt\nopagebreak}%

% third organiser info, if any
\newcommand{\thirdorganizer}[3]
% [1] organiser name, [2] affiliations, [3] email
{\textit{#1}\\\nopagebreak%
 #2\\\nopagebreak%
 \protect\url{#3}\vspace{3mm}\\\nopagebreak}%


% -- adding a special session part
\newcommand{\sessionPart}[2]{% [1] part title,
 % [2] time slot
 \vspace{12pt}
 \ifthenelse{\equal{#1}{}}{}{\colorbox{UWYellow2}{\makebox[\textwidth][l]{#1}}\nopagebreak\\}%
 \colorbox{UWYellow2}{\makebox[\textwidth][l]{#2}}\nopagebreak%
 \vskip 0pt\nopagebreak%
}%

% -- adding a special session talk
\newcommand{\sessionTalk}[3]{% [1] talk title, [2] speaker name, [3] label
 \needspace{3\baselineskip}%
 \vskip 0pt\nopagebreak%
 \textit{#2}\\\nopagebreak%
 {\titlecap{#1}} \qquad p.~\pageref{#3}\nopagebreak%
 \vskip 0pt\nopagebreak%
}%

% -- adding a participant
\newcommand{\participant}[5]{% [1] name, [2] address, [3] email, [4-8] page refs
 \begin{minipage}{0.45\textwidth} \raggedright%
 \vskip 0pt\nopagebreak%
 \textbf{#1}\\\nopagebreak%
 #2\\ \nopagebreak%
 %\ifthenelse{\equal{#2}{}}{}{#2\\ \nopagebreak}%
 \url{#3}\\\nopagebreak%
 \ifthenelse{\equal{#4}{}}{}{p.~\pageref{#4}}%
 \ifthenelse{\equal{#5}{}}{}{, p.~\pageref{#5}}%
 %\ifthenelse{\equal{#6}{}}{}{, p.~\pageref{#6}}%
% \ifthenelse{\equal{#7}{}}{}{, p.~\pageref{#7}}%
% \ifthenelse{\equal{#8}{}}{}{, p.~\pageref{#8}}%
 \end{minipage}%
 \vskip 0.5cm%
}%

% -- adding a participant no email
\newcommand{\participantne}[4]{% [1] name, [2] address, , [3-7] page refs
 \begin{minipage}{0.45\textwidth} \raggedright%
 \vskip 0pt\nopagebreak%
 \textbf{#1}\\\nopagebreak%
 #2\\ \nopagebreak%
 %\ifthenelse{\equal{#2}{}}{}{#2\\ \nopagebreak}%
 %\url{#3}\\\nopagebreak%
 \ifthenelse{\equal{#3}{}}{}{p.~\pageref{#3}}%
 \ifthenelse{\equal{#4}{}}{}{, p.~\pageref{#4}}%
 %\ifthenelse{\equal{#6}{}}{}{, p.~\pageref{#6}}%
% \ifthenelse{\equal{#7}{}}{}{, p.~\pageref{#7}}%
% \ifthenelse{\equal{#8}{}}{}{, p.~\pageref{#8}}%
 \end{minipage}%
 \vskip 0.5cm%
}%

% -- adding a time slot
\newcommand{\timeslot}[4]{% [1] day, [2] from, [3] to, [4] room
 #1, #2 -- #3, #4}%

% -- use this command if we do not want to show the schedule
%\renewcommand{\timeslot}[4]{% [1] day, [2] from, [3] to, [4] room
% Schedule to be announced later}%

%---------------------------------------------------------
% The following commands are for producing the timetables
%---------------------------------------------------------
%==== schedule table style
% number of non-time columns, usually equals to number of parallel sessions
\newcommand{\numcols}{4}
\newcommand{\numgaps}{\the\dimexpr\numcols-1}
\arrayrulecolor{white}		% default table border color
\newcolumntype{Y}{>{\raggedright\arraybackslash}X}
\newcolumntype{Z}{>{\hsize=\dimexpr\numcols\hsize+\tabcolsep * (2 * (\numcols - 1) ) + \arrayrulewidth* (\numcols - 1) \relax}Y}

% -- adding a table heading
\newcommand{\TableHeading}[1] % [1] day, date -- time segment (e.g. Afternoon II)
 {& \multicolumn{\numcols}{Z}{\cellcolor{white}%
 	\large\textbf{#1}
 }}

% -- adding a table time, consider deleting it
\newcommand{\tableTime}[2] % [1] from, [2] to
 {#1 -- #2}%

% -- adding a table event, usually a coffee break
\newcommand{\TableEvent}[2]{
	\rowcolor{\EventColor}				% color of the row
	#1 &		 					% start time -- end time (e.g., 12:00 -- 18:00)
	\multicolumn{\numcols}{Z}{#2}		% activity and note
}

% -- adding a table plenary entry
\newcommand{\tablePlenary}[6]{
% [1] time, [2] location, [3] chair,
% [4] speaker, [5] talk title, [6] talk id.
	\rowcolor{\PlenaryColor} #1 &
	\multicolumn{\numcols}{Z}{
	#2\par%
	\textbf{Plenary Talk} \vspace{1mm}\par%
	\textbf{\textit{#4}} \par%
	\textbf{#5} \quad p.~\pageref{#6} \vspace{1mm}\par%
	\qquad Chair: \textit{#3}}
}%

% -- adding a table tutorial entry
\newcommand{\tableTutorial}[6]{
	% [1] time, [2] location, [3] chair,
	% [4] speaker, [5] talk title, [6] talk id.
	\rowcolor{\TutorialColor} #1 &
	\multicolumn{\numcols}{Z}{
		#2\par%
		\textbf{Tutorial} \vspace{1mm}\par%
		\textbf{\textit{#4}} \par%
		\textbf{#5} \quad p.~\pageref{#6} \vspace{1mm}\par%
		\qquad Chair: \textit{#3}}
}%

% -- adding a table discussion entry
\newcommand{\tableDiscussion}[5] % [1] location, [2] chair
 % [3] speaker, [4] talk title, [5] talk id
 {#1\par%
 \textbf{Open Forum}: %\vspace{1mm}\par%
 \textbf{#4} \quad p.~\pageref{#5} \vspace{1mm}\par%
 \qquad Chair: \textit{#3}}% chair by speaker



% -- adding a table special session entry
\newcommand{\tableSpecial}[8]
% [1] location, [2] organiser, [3] organiser
% [4] session title, [5] part, [6] of, [7] session id, [8] chair
 {#1\par%
  \textbf{Special Session} \par%
  \ifthenelse{\equal{#3}{}}{\textit{#2}}%
                           {\textit{#2} and \textit{#3}}\par%
  #4\ifthenelse{\equal{#6}{1}}{}{, Part #5 of #6}\quad p.~\pageref{#7} \par%
  Chair: \textit{#8}}%

% -- adding a table contributed session entry
\newcommand{\tableContributed}[5] % [1] location, [2] chair
                                  % [3] description, [4] part, [5] of
 {#1\par%
  \textbf{Technical Session} \vspace{2mm} \par%
  Chair: \textit{#2}}%

% -- adding a table talk entry
\newcommand{\tableTalk}[3] % [1] speaker, [2] talk title, [3] talk id
 {\textit{#1} \par%
  #2\quad p.~\pageref{#3}}%

 

% -- adding a table special session entry
\newcommand{\tableSpecialCL}[4]
% [1] location, 
% [2] session title, [3] session id, [4] chair
%if it's part 1 or part 2 just put it in the title
 {#1\par%
 \textbf{Special Session} \par%
 #2\quad p.~\pageref{#3} \par%
 Chair: \textit{#4}}% 

% -- adding a table contributed session entry
\newcommand{\tableContributedCL}[3] % [1] location, [3] chair
 % [2] description, 
 {#1\par%
 #2\quad  \par%
 Chair: \textit{#3}}%

% -- adding a table contributed session entry
\newcommand{\tableContributedCancelled}[2] % [1] location, [3] chair
 % [2] description, 
 {#1\par%
 #2\quad  \par%
 CANCELLED SESSION}%


% ----------------------------------------------------------------------------------------------------------
% -- This reduces the spacing in the enumerate environment
\newcounter{myenum}
\renewenvironment{enumerate}
 {\begin{list}{\arabic{myenum}.}{%
 \usecounter{myenum}%
 \setlength{\labelsep}{0.7em}%
 \setlength{\topsep}{0em}%
 \setlength{\itemsep}{0em}%
 \setlength{\leftmargin}{30pt}}}{\end{list}}

% ------------------------------------------------------------------------
% Document begins here
% ------------------------------------------------------------------------
\begin{document}

\input{MCQMC2024_book_front}


% ----------------------------------------------------------------
% ----------------------------------------------------------------
% ----------------------------------------------------------------
\chapter{Schedule}

\begin{center}


\begin{sideways}\small
\begin{tabularx}{\textheight}{l*{\numcols}{|Y}}
 	\TableHeading{August 18th, 2024}\\
 	\TableEvent{13:30 -- 16:00}{Registration -- STC 1st floor foyer, outside of STC 1012}
 	\\
 	\tableTutorial{14:15 -- 15:45} % [1] time
 	{STC 1012}	% [2] room
 	{Alexander Keller}		% [3] chair
 	{Fred J.~Hickernell}	% [4] speaker
 	{Quasi-Monte Carlo Methods: What, Why, and How?}		% [5] talk title
 	{TUT02}			% [6] talk id
 	\\
 	\TableEvent{15:45 -- 16:00}{Coffee break -- STC lower level atrium}
 	\\
 \tableTutorial{16:00 -- 17:30} % [1] time
 	{STC 1012}	% [2] room
 	{Ben Feng}		% [3] chair
 	{Peter Frazier}	% [4] speaker
 	{Grey-box Bayesian Optimization}		% [5] talk title
 	{TUT01}			% [6] talk id
	\\
\end{tabularx}
\end{sideways}


\pagebreak

%% 2024 schedule is in Schedule.tex

\input{Schedule.tex}

\end{center}

%\clearpage

%% old 2022 schedule for commparison



\clearpage



%-------------------------------------------------------------------------------
% Sunday Tutorials
%-------------------------------------------------------------------------------
\chapter{Sunday Tutorials}


\begin{talk}
 {Quasi-Monte Carlo Methods:  What, Why, and How?}% [1] talk title
 {Fred J.~Hickernell}% [2] speaker name
 {Department of Applied Mathematics and Center for Interdisciplinary Scientific Computation, Illinois Institute of Technology}% [3] affiliations
 {hickernell@iit.edu}% [4] email
 {}% [5] coauthors
 {}% [6] special session
 {\timeslot{Sunday, Aug 18, 2024}{14:15}{15:45}{STC 1012}}% [7] time slot
 {TUT02}% [8] talk id
 {photo}% [9] session id or photo
Many problems in  quantitative finance, uncertainty quantification, and other areas can be formulated as computing $\mu := \mathbb{E}(Y)$, where instances of $Y:=f(\boldsymbol{X})$ are generated by numerical simulation. The population mean, $\mu$, can be approximated by the sample mean, $\hat{\mu}_n := n^{-1} \sum_{i=1}^n f(\boldsymbol{X}_i)$.  Computing $\mu$ is equivalent to computing a $d$-dimensional integral.

Quasi-Monte Carlo methods replace independent and identically distributed  sequences of random vectors, $\{\boldsymbol{X}_1, \boldsymbol{X}_2, \ldots \}$, by low discrepancy sequences.  This accelerates the convergence of $\hat{\mu}_n$ to $\mu$ as $n \to \infty$. 


This tutorial describes  low discrepancy sequences  and their quality measures.  We demonstrate the performance gains possible with quasi-Monte Carlo methods.  Moreover, we describe how to formulate problems to realize the most increase in performance using quasi-Monte Carlo methods.  We also briefly describe the use of quasi-Monte Carlo methods for problems beyond computing the mean.

\end{talk}

\clearpage


\begin{talk}
 {Grey-box Bayesian Optimization}% [1] talk title
 {Peter Frazier}% [2] speaker name
 {Cornell University}% [3] affiliations
 {pf98@cornell.edu}% [4] email
 {}% [5] coauthors
 {}% [6] special session
 {\timeslot{Sunday, Aug 18, 2024}{16:00}{17:30}{STC 1012}}% [7] time slot
 {TUT01}% [8] talk id
 {photo}% [9] session id or photo
Bayesian optimization (BayesOpt) is powerful tool for optimizing objective functions evaluated using Monte Carlo or Quasi Monte Carlo. It aims to produce an approximate global optimum with few objective function evaluations by combining a machine-learning-based surrogate for the objective function (often a Gaussian process) with a decision-theoretic acquisition function that efficiently directs sampling effort.  It is widely used for optimizing social media platforms, tuning hyperparameters in deep neural networks, designing new drugs and materials, and beyond. While BayesOpt has historically been deployed as a black-box optimizer, recent advances show orders-of-magnitude improvement through new grey-box methods that "peek inside the box".  For example, consider optimizing product interventions in simulation to improve a ridesharing market averaged over exogenous shocks. New grey-box BayesOpt methods use a machine learning surrogate for how market outcomes depend on both the exogenous shocks and the product intervention to evaluate for the most informative shocks first rather than sampling blindly. This tutorial introduces Gaussian process regression, standard (black-box) BayesOpt, and new grey-box methods, motivating with examples from machine learning, engineering and the physical sciences. We close by identifying research opportunities where the MCQMC community can have a particularly large impact.

\end{talk}

\clearpage

%-------------------------------------------------------------------------------
% Plenary Talks: to be done/ordered manually
%-------------------------------------------------------------------------------
\chapter{Plenary Talks}
\newpage

\begin{talk}
	{Stochastic Approximation beyond the gradient case}% [1] talk title
	{Gersende Fort}% [2] speaker name
	{CNRS, Institut de Math\'ematiques de Toulouse, France}% [3] affiliations
	{gersende.fort@math.univ-toulouse.fr}% [4] email
	{}% [5] coauthors
	{}% [6] special session
	{\timeslot{Monday, August 19, 2024}{14:00}{15:00}{STC 1012}}% [7] time slot
	{PL01}% [8] talk id
	{photo}% [9] session id or photo
	In statistical learning, many analyses and methods rely on optimization, including its stochastic versions introduced for example, to overcome an intractability of the objective function or to reduce the computational cost of the deterministic optimization step.

In 1951, H. Robbins and S. Monro introduced a novel iterative algorithm, named "Stochastic Approximation", for the computation of the zeros of a function defined by an expectation with no closed-form expression. This algorithm produces a sequence of iterates, by replacing at each iteration the unknown expectation with a Monte Carlo approximation based on one sample. Then, this method was generalized: it is a stochastic algorithm designed to find the zeros of a vector field  when only stochastic oracles of this vector field are available.

 

Stochastic Gradient Descent algorithms are the most popular examples of Stochastic Approximation : oracles come from a Monte Carlo approximation of a large sum. Possibly less popular are examples named "beyond the gradient case", for at least two reasons. First, they rely on oracles that are biased approximation of the vector field, as it  occurs when biased Monte Carlo sampling is used for the definition of the oracles. Second, the vector field is not necessarily a gradient vector field. Many examples in Statistics and more generally in statistical learning are "beyond the gradient case": among examples, let us cite compressed stochastic gradient descent, stochastic Majorize-Minimization methods such as the Expectation-Maximization algorithm, or the Temporal Difference algorithm in reinforcement learning.

 

In this talk, we will show that these "beyond the gradient case" Stochastic Approximation algorithms  still converge, even when the oracles are biased, as soon as some parameters of the algorithm are tuned enough. We will discuss what 'tuned enough' means  when the convergence criterion relies on epsilon-approximate stationarity, and we will comment the efficiency of the algorithm through sample complexity.  Such analyses are based on non-asymptotic convergence bounds in expectation: we will present a unified method to obtain such bounds for a large class of Stochastic Approximation methods including both the gradient case and the beyond the gradient case.


\end{talk}

\clearpage

\begin{talk}
	{Randomized lattice rules for high-dimensional integration}% [1] talk title
	{Takashi Goda}% [2] speaker name
	{School of Engineering, The University of Tokyo}% [3] affiliations
	{goda@frcer.t.u-tokyo.ac.jp}% [4] email
	{}% [5] coauthors
	{}% [6] special session
	{\timeslot{Thursday, August 22, 2024}{09:00}{10:00}{STC 1012}}% [7] time slot
	{PL02}% [8] talk id
	{photo}% [9] session id or photo
	Lattice rules have been extensively studied for high-dimensional numerical integration. One crucial question has been how to select good generating vectors. It has been shown both in theory and practice that good generating vectors can be selected by component-wise greedy optimization, known as the component-by-component construction. On the other hand, the standard error analyses for such constructive approaches rely on the averaging argument (i.e., the best one is better than the average), and so, the Markov inequality implies that there exist many equally good generating vectors. The aim of this talk is to present some new results for randomized lattice rules by exploiting the property that ``the most of the generating vectors are good.''

The first result involves randomly selecting generating vectors multiple times, obtaining several integral estimates, and then using their median as the final estimate. This method is proven robust to the smoothness and weight parameters of the weighted Korobov spaces. Secondly, when employing the mean square error as a measure criterion, we provide two implementable randomization methods that exploit the property that ``the most of the generating vectors are good'' to improve the convergence rate compared to worst-case error.

This talk builds up on the results from several papers and acknowledges the contributions of my collaborators (in alphabetical order): Josef Dick, Pierre L'Ecuyer, and Kosuke Suzuki.
\end{talk}

\clearpage

\begin{talkcr}
	{Some recent approaches to sampling recovery}% [1] talk title
	{David Krieg}% [2] speaker name
	{University of Passau, Germany}% [3] affiliations
	{david.krieg@uni-passau.de}% [4] email
	{}% [5] coauthors
	{}% [6] special session
	{\timeslot{Monday, August 19, 2024}{09:00}{10:00}{STC 1012}}% [7] time slot
	{PL03}% [8] talk id
	{photo}% [9] session id or photo
	Recovering a function based on a finite sample of its function values is a very natural problem.
The question for good sampling nodes and for good recovery algorithms 
already fueled mathematical research 
more than a hundred years ago
when, for instance, the Chebyshev nodes turned out to be almost optimal
for the task of uniform approximation of univariate functions by polynomials. 
The question is no less important now, as intelligent people and intelligent machines alike try to find (typically very high-dimensional) functions that describe the behavior of their data and which are suited to give reliable predictions. 
Consequently, the theory is immense and there is a great variety of results, especially when it comes to particular instances of function approximation problems.

In this talk, I want to present some recent results and approaches to the problem that are of a general nature and which are supposed to give some insight on the power of sampling algorithms in general. 
Namely, we discuss how close sampling algorithms can get you
to (a)~the best approximation within a finite-dimensional space of your choice,
(b)~the best sparse approximation with respect to a dictionary,
or (c)~the best linear approximation procedure (like a truncated singular value decomposition).

In other words, 
we want to compare the sampling numbers 
\[
 g_n(F,L_p) \,:=\, \inf_{\substack{x_1,\hdots,x_n\in D \\ \phi\colon \mathbb{C}^n \to L_p(D)}}
 \,\sup_{f\in F}\, \big\Vert f - \phi\big( f(x_1),\dots,f(x_n)\big)\big\Vert_{L_p(D)}
\]
of a class $F$ of functions on a measure space $D$ 
with singular numbers, with approximation numbers, with Kolmogorov widths, and with best $m$-term widths. 
It turns out that, in many scenarios, sampling algorithms 
can get us surprisingly close to the three desired approximation benchmarks 
if we choose the sampling points $x_i$ and the recovery map $\phi$ optimally.
\end{talkcr}

\clearpage

\begin{talk}
 {Lattice rules, kernel methods, DNNs, and how to connect them}% [1] talk title
 {Frances Kuo}% [2] speaker name
 {University of New South Wales (Sydney), Australia}% [3] affiliations
 {f.kuo@unsw.edu.au}% [4] email
 {}% [5] coauthors
 {}% [6] special session
 {\timeslot{Wednesday, August 21, 2024}{14:00}{15:00}{STC 1012}}% [7] time slot
 {PL04}% [8] talk id
 {photo}% [9] session id or photo

Lattice rules are my favorite family of quasi-Monte Carlo methods. They are proven to be effective for high dimensional integration and multivariate function approximation in a number of settings. They are extremely easy to implement thanks to their very simple formulation --- all we require is a ``good'' integer vector of length matching the dimensionality of the problem. We know how to construct such good vectors tailored to applications in different areas, e.g., in PDEs with random coefficients, both for computing expected values (integrals) of quantities of interest as well as in obtaining surrogates of the PDE solution using lattice-based kernel interpolants. In recent years there has been a burst of research activities on the application and theory of Deep Neural Networks (DNNs). We explore how lattice rules can be used in the framework of DNNs.

This is based on joint work with Alexander Keller (NVIDIA), Dirk Nuyens (KU Leuven) and Ian H. Sloan (UNSW Sydney). 
\end{talk}

\clearpage

\begin{talk}
 {Bootstrap with One (or Few) Resamples: Statistical Optimality and an Integrative View on Data and Monte Carlo Uncertainties}% [1] talk title
 {Henry Lam}% [2] speaker name
 {Columbia University, USA}% [3] affiliations
 {khl2114@columbia.edu}% [4] email
 {}% [5] coauthors
 {}% [6] special session
 {\timeslot{Thursday, August 22, 2024}{14:00}{15:00}{STC 1012}}% [7] time slot
 {PL05}% [8] talk id
 {photo}% [9] session id or photo
 
While the bootstrap is demonstrably powerful in quantifying statistical uncertainty, its implementation could face substantial computation from repeated resampling. We present a bootstrap implementation that can drive down the number of resamples to minimally possible, namely as low as one, while maintaining valid coverage guarantees. Our approach is empowered by an integrative view on the statistical noise in the data and the Monte Carlo noise in the resampling together, in contrast to separately handling them in conventional bootstraps. We leverage our idea to efficiently quantify uncertainty in several tasks, including neural network training, simulation modeling and stochastic gradient descent. We also explain the statistical optimality of our implementation and compare it against other competing low-computation inference methods.
\end{talk}

\clearpage

\begin{talk}
	{Richardson Extrapolation meets Multi-Fidelity Modelling}% [1] talk title
	{Chris Oates}% [2] speaker name
	{Newcastle University, UK}% [3] affiliations
	{chris.oates@ncl.ac.uk}% [4] email
	{Toni Karvonen, Aretha Teckentrup, Marina Strocchi, Steven Niederer}% [5] coauthors
	{}% [6] special session
	{\timeslot{Wednesday, August 21, 2024}{09:00}{10:00}{STC 1012}}% [7] time slot
	{PL06}% [8] talk id
	{photo}% [9] session id or photo
	For over a century, extrapolation methods have provided a powerful tool to improve the convergence order of a numerical method. However, these tools are not well-suited to modern computer codes, where multiple continua are discretised and convergence orders are not easily analysed. To address this challenge we present a probabilistic perspective on Richardson extrapolation, a point of view that unifies classical extrapolation methods with modern multi-fidelity modelling, and handles uncertain convergence orders by allowing these to be statistically estimated. The approach is developed using Gaussian processes, leading to Gauss-Richardson Extrapolation (GRE). Conditions are established under which extrapolation using the conditional mean achieves a polynomial (or even an exponential) speed-up compared to the original numerical method. Further, the probabilistic formulation unlocks the possibility of experimental design, casting the selection of fidelities as a continuous optimisation problem which can then be (approximately) solved. A case-study involving a computational cardiac model demonstrates that practical gains in accuracy can be achieved using the GRE method.
\end{talk}

\clearpage

\begin{talk}
	{Simulation algorithms for branching recursions}% [1] talk title
	{Mariana Olvera-Cravioto}% [2] speaker name
	{UNC-Chapel Hill, USA}% [3] affiliations
	{molvera@email.unc.edu}% [4] email
	{}% [5] coauthors
	{}% [6] special session
	{\timeslot{Tuesday, August 20, 2024}{14:00}{15:00}{STC 1012}}% [7] time slot
	{PL07}% [8] talk id
	{photo}% [9] session id or photo
	Many interesting problems today, ranging from the analysis of centrality measures on large complex networks, some algorithms for community detection, to problems in statistical physics and the analysis of opinions on social networks, involve large graphs whose analysis leads to branching recursions. The analysis of branching recursions can often be done using distributional fixed-point equations, which in some cases can easily provide formulas for means and variances of the processes being studied. In general, computing the distribution of such processes, or even their moments in non-linear recursions, must be done numerically. However, large graphs in the original problems give rise to branching recursions with very large mean number of offspring, i.e., fast geometric growth, making any naïve simulation idea impractical. This talk discusses two different types of efficient simulation algorithms: one for computing the distribution of solutions to branching stochastic fixed-point equations, known as population dynamics, and one for computing rare event probabilities for the branching random walk.
\end{talk}

\clearpage

\begin{talk}
	{Recent progress in error estimation for quasi-Monte Carlo}% [1] talk title
	{Art Owen}% [2] speaker name
	{Stanford University, USA}% [3] affiliations
	{owen@stanford.edu}% [4] email
	{Michael Gnewuch, Peter Kritzer, Pierre L'Ecuyer, Marvin Nakayama,  Zexin Pan, Bruno Tuffin}% [5] coauthors
	{}% [6] special session
	{\timeslot{Tuesday, August 20, 2024}{09:00}{10:00}{STC 1012}}% [7] time slot
	{PL08}% [8] talk id
	{photo}% [9] session id or photo
	For many high dimensional integration problems, Quasi-Monte Carlo methods
attain the best accuracy.  In settings where high accuracy is required it is
also valuable to show that it has been attained. Those two criteria are somewhat
at odds with each other.  This talk looks at recent ways to quantify the
accuracy attained by QMC.  It includes progress in forming confidence
intervals based on replication of randomized QMC.  The surprise there is that
a plain Student's t based confidence interval method proved to be much more
reliable than some bootstrap methods that were expected to be best [1].  A second
area of recent progress provides computable and provable upper and lower
bounds on the integral.  These methods require special QMC points that
have a non-negative local discrepancy property along with an integrand
that has a complete monotonicity property [2]. Briefly: some of the best
QMC accuracy results arise for a median of means strategy [3,4].  That raises
a severe challenge of quantifying the uncertainty in a mean when one
has computed a median.				

\medskip

[1] L’Ecuyer P, Nakayama MK, Owen AB, Tuffin B. Confidence intervals for randomized quasi-Monte Carlo estimators. In 2023 Winter Simulation Conference (pp. 445--456).

[2] Gnewuch M, Kritzer P, Owen AB, Pan Z. Computable error bounds for quasi-Monte Carlo using points with non-negative local discrepancy. arXiv preprint arXiv:2309.04209. 

[3] Pan Z, Owen A. Super-polynomial accuracy of one dimensional randomized nets using the median of means. Mathematics of Computation. 2023. 92(340):805--837.

[4] Pan Z, Owen A. Super-polynomial accuracy of multidimensional randomized nets using the median-of-means. Mathematics of Computation. 2024.

\end{talk}

\begin{talkp}
    {30 years of MCQMC -- Panel Discussion}
    {Aretha Teckentrup}
    {Josef Dick, Fred J.~Hickernell, Alexander Keller, Frances~Y.~Kuo, Art B.~Owen}
    {\timeslot{Friday, August 23, 2024}{09:00}{10:00}{STC 1012}}% [7] time slot}
    {PL30}
    The first MCQMC Conference was initiated by Harald Niederreiter and was held in Las Vegas in 1994. This 16th installment of the MCQMC Conference therefore marks the 30th anniversary of the conference. With this panel discussion, we wish to reflect as a community on how the field evolved in 30 years, what has been the impact of the MCQMC conference on our respective research careers, and what are the new big ideas or interesting open problems. Questions will be asked to the panelists by the moderator to initiate the conversation, followed by a Q\&A and general sharing of comments and reflections. 
    
\end{talkp}

%-------------------------------------------------------------------------------
% Special Sessions
%-------------------------------------------------------------------------------
\chapter{Special Sessions}\newpage

\begin{session}
 {Stochastic Computation and Complexity, Part I: SDEs, Stochastic optimization and neural networks}% [1] session title
 {Thomas M\"uller-Gronbach}% [2] organizer name
 {University of Passau}% [3] affiliations
 {Thomas.Mueller-Gronbach@uni-passau.de}% [4] email
 {}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS3}
 %%{SP03}% [8] session id
 {}% [9] third organizer, if any
The session is devoted to algorithms and complexity for
\begin{itemize}[itemsep=0pt,topsep=0pt]
 \item quadrature and strong approximation of SDEs and SPDEs, in particular under nonstandard assumptions,

 \item high and infinite dimensional integration and approximation, and

 \item stochastic optimization and neural networks,
\end{itemize}
including connections to functional analysis and stochastic analysis.
\end{session}

\input{sessSS3.tex}


\clearpage

\begin{session}
    {Optimization under uncertainty}% [1] session title
    {Philipp A. Guth}% [2] organizer name
    {RICAM, Austrian Academy of Sciences}% [3] affiliations
    {philipp.guth@ricam.oeaw.ac.at}% [4] email
    {Vesa Kaarnioja}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
    {University of Potsdam}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
    {vesa.kaarnioja@iki.fi}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
    {SS13}% [8] session id
    {\thirdorganizer{Claudia Schillings}{Free University of Berlin}{c.schillings@fu-berlin.de}}% [9] third organizer, if any
  Large-scale optimization problems based on partial differential equation models typically involve a number of uncertainties: for example, the material parameters, domain shape or sensor locations used to collect the measurements may not be perfectly known. The quantification of these uncertainties leads to challenging high-dimensional integration problems, which can be tackled efficiently using, e.g., multilevel Monte Carlo or quasi-Monte Carlo methods. The intersection of optimization and uncertainty quantification is an actively developing field of research, and this session aims to cover some recent advances in the computational and theoretical treatment of these topics.
 \end{session}

\input{sessSS13}


\clearpage

\begin{session}
 {Efficient Bayesian Surrogate Modeling, Part I}% [1] session title
 {Aleksei Sorokin}% [2] organizer name
 {Illinois Institute of Technology}% [3] affiliations
 {asorokin@hawk.iit.edu}% [4] email
 {Pieterjan Robbe}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Sandia National Laboratories}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {pmrobbe@sandia.gov}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS9}% [8] session id
 {}% [9] third organizer, if any
 Common tasks in stochastic modeling include model calibration and sensitivity analysis. These tasks typically require many model evaluations, which can be prohibitively expensive in case model evaluations are costly. This has motivated the development of surrogate models, which are fit offline on a limited budget and then enable rapid online evaluations for predictive purposes. An important decision is where to evaluate the model in order to maximize information captured by the surrogate. While Monte Carlo points are a conventional choice, their independent nature often leads to sampling in locations of little value to the surrogate. In contrast, dependent structures, such as quasi-random (low discrepancy) points or Bayesian optimal experimental designs, have proven to produce more reliable surrogate models. This session will discuss some of the recent developments in these sampling techniques, and will bring together researchers from both communities to explore collaborations.
\end{session}

\input{sessSS9}

%\input{sessSS10}


\clearpage


\begin{session}
 {Stochastic Computation and Complexity, Part II: Approximation of SDEs under non-standard assumptions}% [1] session title
 {Stefan Heinrich}% [2] organizer name
 {RPTU Kaiserslautern-Landau}% [3] affiliations
 {heinrich@informatik.uni-kl.de}% [4] email
 {}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS4}
 %%{SP04}% [8] session id
 {}% [9] third organizer, if any
The session is devoted to algorithms and complexity for
\begin{itemize}[itemsep=0pt,topsep=0pt]
 \item quadrature and strong approximation of SDEs and SPDEs, in particular under nonstandard assumptions,

 \item high and infinite dimensional integration and approximation, and

 \item stochastic optimization and neural networks,
\end{itemize}
including connections to functional analysis and stochastic analysis.
\end{session}

\input{sessSS4.tex}



\clearpage

\begin{session}
 {Efficient Bayesian Surrogate Modeling, Part II}% [1] session title
 {Aleksei Sorokin}% [2] organizer name
 {Illinois Institute of Technology}% [3] affiliations
 {asorokin@hawk.iit.edu}% [4] email
 {Pieterjan Robbe}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Sandia National Laboratories}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {pmrobbe@sandia.gov}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS10}% [8] session id
 {}% [9] third organizer, if any
 Common tasks in stochastic modeling include model calibration and sensitivity analysis. These tasks typically require many model evaluations, which can be prohibitively expensive in case model evaluations are costly. This has motivated the development of surrogate models, which are fit offline on a limited budget and then enable rapid online evaluations for predictive purposes. An important decision is where to evaluate the model in order to maximize information captured by the surrogate. While Monte Carlo points are a conventional choice, their independent nature often leads to sampling in locations of little value to the surrogate. In contrast, dependent structures, such as quasi-random (low discrepancy) points or Bayesian optimal experimental designs, have proven to produce more reliable surrogate models. This session will discuss some of the recent developments in these sampling techniques, and will bring together researchers from both communities to explore collaborations.
\end{session}

%\input{sessSS9}

\input{sessSS10}

\clearpage
\begin{session}
 {Variance reduction techniques for rare events}% [1] session title
 {Nadhir Ben Rached}% [2] organizer name
 {University of Leeds}% [3] affiliations
 {n.benrached@leeds.ac.uk}% [4] email
 {Ra\'{u}l Tempone}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {RWTH Aachen University and KAUST}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {tempone@uq.rwth-aachen.de}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS20}% [8] session id
 {\thirdorganizer{Shyam Mohan Subbiah Pillai}{RWTH Aachen University}{subbiah@uq.rwth-aachen.de}}% [9] third organizer, if any
Rare events are events with small probabilities, but their occurrences are critical in many real-life applications. The problem of estimating rare event probabilities is encountered in various engineering applications (finance, wireless communications, system reliability, Biology, etc.). Naive Monte Carlo simulations are, in this case, substantially expensive. This session focuses on methods belonging to the class of variance reduction techniques. These alternative methods deliver, when appropriately used, accurate estimates with a substantial amount of variance reduction compared to the naive Monte Carlo estimator.
\end{session}

\input{sessSS20}


\clearpage

\begin{session}
 {Stochastic Computation and Complexity, Part III: Approximation of SDEs under non-standard assumptions}% [1] session title
 {Thomas M\"uller-Gronbach}% [2] organizer name
 {University of Passau}% [3] affiliations
 {Thomas.Mueller-Gronbach@uni-passau.de}% [4] email
 {}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS5}
 %{SP05}% [8] session id
 {}% [9] third organizer, if any
The session is devoted to algorithms and complexity for
\begin{itemize}[itemsep=0pt,topsep=0pt]
 \item quadrature and strong approximation of SDEs and SPDEs, in particular under nonstandard assumptions,

 \item high and infinite dimensional integration and approximation, and

 \item stochastic optimization and neural networks,
\end{itemize}
including connections to functional analysis and stochastic analysis.
\end{session}

\input{sessSS5.tex}


\clearpage

\begin{session}
 {Efficient methods for uncertainty quantification in differential equations, Part I}% [1] session title
 {Anastasia Istratuca}% [2] organizer name
 {University of Edinburgh, Heriot-Watt University}% [3] affiliations
 {a.istratuca@sms.ed.ac.uk}% [4] email
 {Aretha Teckentrup}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {University of Edinburgh}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {a.teckentrup@ed.ac.uk}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS18}% [8] session id
 {}% [9] third organizer, if any
 One of the most common approaches to modelling physical phenomena consists of ordinary and partial differential equations, which allow for computer simulations through the use of modern numerical solvers. These models encompass parameters that often have to be measured or inferred from data. To account for error measurements and scarce availability of the data, we express our uncertainty about the parameters by associating, for example, a probability distribution to them. This mini-symposium focuses on recent advances in algorithms for quantifying the uncertainty in such models.
\end{session}

\input{sessSS18}

%\input{sessSS19}



\clearpage



\begin{session}
 {Recent Advances in QMC Methods for Computational Finance and Financial Risk Management}% [1] session title
 {Chiheb Ben Hammouda}% [2] organizer name
 {Utrecht University}% [3] affiliations
 {c.benhammouda@uu.nl}% [4] email
 {Ra\'{u}l Tempone}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {RWTH Aachen University, King Abdullah University of Science and Technology}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {rtempone@gmail.com}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS14}% [8] session id
 {}% [9] third organizer, if any
 The session is about recent numerical and theoretical advances in quasi-Monte Carlo (QMC) methods to address different challenges in computational finance and Risk management. Challenges range from pricing high-dimensional financial derivatives, computing sensitivities, and efficiently estimating nested expectations arising in financial risk estimation.
\end{session}

\input{sessSS14}



\clearpage

\begin{session}
 {Efficient methods for uncertainty quantification in differential equations, Part II}% [1] session title
 {Anastasia Istratuca}% [2] organizer name
 {University of Edinburgh, Heriot-Watt University}% [3] affiliations
 {a.istratuca@sms.ed.ac.uk}% [4] email
 {Aretha Teckentrup}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {University of Edinburgh}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {a.teckentrup@ed.ac.uk}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS19}% [8] session id
 {}% [9] third organizer, if any
 One of the most common approaches to modelling physical phenomena consists of ordinary and partial differential equations, which allow for computer simulations through the use of modern numerical solvers. These models encompass parameters that often have to be measured or inferred from data. To account for error measurements and scarce availability of the data, we express our uncertainty about the parameters by associating, for example, a probability distribution to them. This mini-symposium focuses on recent advances in algorithms for quantifying the uncertainty in such models.
\end{session}

%\input{sessSS18}

\input{sessSS19}

\clearpage

\begin{session}
 {Learning to Solve Related Integrals}% [1] session title
 {Chris. J. Oates}% [2] organizer name
 {Newcastle University, UK}% [3] affiliations
 {chris.oates@ncl.ac.uk}% [4] email
 {}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS2}
 %%NK on May 7 {SP02}% [8] session id
 {}% [9] third organizer, if any
 The standard perspective on numerical analysis deals with solving individual numerical tasks, but in practice the experience gained from using numerical methods to solve related problems provides valuable insight into their performance, which can shape how and when numerical methods are used.
 Developments at the intersection of probability, statistics, and numerical analysis seek to leverage experience to improve performance on subsequent numerical tasks as they are encountered.
 This session will shine a light on emerging methodology for the solution of related integration problems, arising in areas of research that include sensitivity analysis, computational finance, the solution of partial differential equations, decision-making under uncertainty, and diffusion-based generative modelling.
 Fran\c{c}ois-Xavier Briol from University College London will present a probabilistic approach to estimating related conditional expectations, which operates by sharing statistical information regarding the integrand.
 Jon Cockayne from the University of Southampton will present a novel statistical approach to solving related linear systems of equations, such as occur when integrating a partial differential equation that is parameter-dependent.
 Zheyang Shen from Newcastle University will present a novel perspective on diffusion-based generative modelling, which casts the problem of generating realistic image data as the estimation of related kernel mean embeddings in a reproducing kernel Hilbert space framework.
\end{session}

\input{sessSS2.tex}


%%% NK commenting out this and all subsequent similar sections on May 7

\clearpage


\begin{session}
 {Function recovery and discretization problems, Part I}% [1] session title
 {David Krieg}% [2] organizer name
 {Institute of Analysis, Johannes Kepler University Linz, Austria}% [3] affiliations
 {david.krieg@jku.at}% [4] email
 {Kateryna Pozharska}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Institute of Mathematics of NAS of Ukraine, Kyiv, Ukraine; \\ Faculty of Mathematics, Chemnitz University of Technology,
Germany}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {pozharska.k@gmail.com}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS6}% [8] session id
 {}% [9] third organizer, if any
In this session, we would like to bring together experts who contributed to the theory of function recovery and related problems.
Recently, there has been much progress in understanding the power of different types of information (function values vs.\ linear measurements, optimal vs.\ random)
as well as different classes of algorithms (linear vs.\ nonlinear, random vs.\ deterministic, adaptive vs.\ nonadaptive), but also with regard to the error analysis for specific recovery schemes.
The session is concerned with these new developments, which also include the impact of a large dimension, discretization in function spaces and modern methods in data science.
\end{session}

\input{sessSS6.tex}

%\input{sessSS7.tex}


\clearpage


\begin{session}
 {Testing and analysis of pseudorandom number generators}% [1] session title
 {Emil Løvbak}% [2] organizer name
 {Karlsruhe Institute of Technology}% [3] affiliations
 {emil.loevbak@kit.edu}% [4] email
 {Michael Mascagni}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Florida State University}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {mascagni@fsu.edu}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS23}% [8] session id
 {}% [9] third organizer, if any
 Pseudorandom number generators are a core part of scientific computing, lying at the foundation of Monte Carlo methods. Over the history of the field, the quality of such generators has consistently been improved to produce streams of numbers that are hard to distinguish from truly random numbers. There are two approaches to quantify the randomness of a given generator. On the one hand, one can use mathematical techniques to determine the theoretical properties of the generator such as period length, uniformity, and sequence correlation. On the other hand, one can apply statistical benchmarks to empirically test the streams produced by a generator. This minisymposium aims to bring together researchers working on the design and testing of practical random number generators to exchange ideas on how to make use of these two complementary approaches in their evaluation.
\end{session}

\input{sessSS23}


\clearpage

\begin{session}
 {Function recovery and discretization problems, Part II}% [1] session title
 {David Krieg}% [2] organizer name
 {Institute of Analysis, Johannes Kepler University Linz, Austria}% [3] affiliations
 {david.krieg@jku.at}% [4] email
 {Kateryna Pozharska}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Institute of Mathematics of NAS of Ukraine, Kyiv, Ukraine; \\ Faculty of Mathematics, Chemnitz University of Technology,
Germany}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {pozharska.k@gmail.com}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS7}% [8] session id
 {}% [9] third organizer, if any
In this session, we would like to bring together experts who contributed to the theory of function recovery and related problems.
Recently, there has been much progress in understanding the power of different types of information (function values vs.\ linear measurements, optimal vs.\ random)
as well as different classes of algorithms (linear vs.\ nonlinear, random vs.\ deterministic, adaptive vs.\ nonadaptive), but also with regard to the error analysis for specific recovery schemes.
The session is concerned with these new developments, which also include the impact of a large dimension, discretization in function spaces and modern methods in data science.
\end{session}

\input{sessSS7.tex}







\begin{session}
 {Universality in QMC and related algorithms}% [1] session title
 {Peter Kritzer}% [2] organizer name
 {RICAM, Austrian Academy of Sciences}% [3] affiliations
 {peter.kritzer@oeaw.ac.at}% [4] email
 {}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS8}% [8] session id
 {}% [9] third organizer, if any
 In the literature on QMC and related methods, it is often the case that one can tailor an algorithm to a specific problem, usually depending on a certain (fixed) choice
 of problem parameters such as smoothness parameters or coordinate weights. This may
 have the advantage that one obtains an excellent algorithm for this particular problem,
 but the obvious downside is that it is not clear whether the same algorithm could be applied in other settings, e.g., when some of the parameters change. There have been recent attempts to make QMC and related algorithms more universal, and a number of interesting open questions remain. This special session brings together four speakers who have recently contributed to this aspect of multivariate algorithms.
\end{session}

\input{sessSS8}


\clearpage


\begin{session}
 {Multilevel methods for SDEs and SPDEs, Part I}% [1] session title
 {Mike Giles}% [2] organizer name
 {University of Oxford}% [3] affiliations
 {mike.giles@maths.ox.ac.uk}% [4] email
 {}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS21}% [8] session id
 {}% [9] third organizer, if any
 Speakers in this session will present and analyse multilevel algorithms for an interesting variety of applications, including chaotic SDEs, stochastic PDEs and kinetic particle models.
\end{session}

\input{sessSS21}

%\input{sessSS22}


\clearpage

\begin{session}
 {Recent Advances in Monte Carlo Methods for Forward and Inverse Problems for Stochastic Reaction Networks, Part I}% [1] session title
 {Chiheb Ben Hammouda}% [2] organizer name
 {Utrecht University}% [3] affiliations
 {c.benhammouda@uu.nl}% [4] email
 {Sophia Wiechert}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {RWTH Aachen University}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {wiechert@uq.rwth-aachen.de}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS15}
 %{SP13}% [8] session id
 {\thirdorganizer{Ra\'{u}l Tempone}{RWTH Aachen University}{tempone@uq.rwth-aachen.de}}% [9] third organizer, if any
The session is about recent advances related to Monte Carlo methods and variance/dimension reduction techniques for forward/inverse problems and sensitivity analysis for pure jump processes and stochastic reaction networks, with a particular focus on stochastic biological and chemical systems.
\end{session}

\input{sessSS15}

%\input{sessSS16}


\clearpage

\begin{session}
 {Kernel approximation and cubature, Part I}% [1] session title
 {Vesa Kaarnioja}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {University of Potsdam}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {vesa.kaarnioja@iki.fi}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Ilja Klebanov}% [2] organizer name
 {Free University of Berlin}% [3] affiliations
 {klebanov@zedat.fu-berlin.de}% [4] email
 {SS11}
 %{SP10}% [8] session id
 {}% [9] third organizer, if any
 Reproducing kernel Hilbert spaces (RKHSs) are very amenable to the development of efficient approximation and cubature methods. To this end, there has been a surge of interest in recent years regarding some of the advantages that kernel-based methods can offer in applications involving collocation over Monte Carlo or quasi-Monte Carlo point sets---some examples include, e.g., Gaussian process regression (kriging), Bayesian neural networks or uncertainty quantification for partial differential equations. This minisymposium showcases some recent theoretical and computational developments in the study of kernel-based approximation and cubature methods.
\end{session}

\input{sessSS11}

%\input{sessSS12}


\clearpage
\begin{session}
 {Multilevel methods for SDEs and SPDEs, Part II}% [1] session title
 {Mike Giles}% [2] organizer name
 {University of Oxford}% [3] affiliations
 {mike.giles@maths.ox.ac.uk}% [4] email
 {}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS22}% [8] session id
 {}% [9] third organizer, if any
 Speakers in this session will present and analyse multilevel algorithms for an interesting variety of applications, including chaotic SDEs, stochastic PDEs and kinetic particle models.
\end{session}

%\input{sessSS21}

\input{sessSS22}
\clearpage

\begin{session}
 {Recent Advances in Monte Carlo Methods for Forward and Inverse Problems for Stochastic Reaction Networks, Part II}% [1] session title
 {Chiheb Ben Hammouda}% [2] organizer name
 {Utrecht University}% [3] affiliations
 {c.benhammouda@uu.nl}% [4] email
 {Sophia Wiechert}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {RWTH Aachen University}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {wiechert@uq.rwth-aachen.de}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS16}
 %{SP13}% [8] session id
 {\thirdorganizer{Ra\'{u}l Tempone}{RWTH Aachen University}{tempone@uq.rwth-aachen.de}}% [9] third organizer, if any
The session is about recent advances related to Monte Carlo methods and variance/dimension reduction techniques for forward/inverse problems and sensitivity analysis for pure jump processes and stochastic reaction networks, with a particular focus on stochastic biological and chemical systems.
\end{session}

%\input{sessSS15}

\input{sessSS16}
\clearpage

\begin{session}
 {Kernel approximation and cubature, Part II}% [1] session title
 {Vesa Kaarnioja}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {University of Potsdam}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {vesa.kaarnioja@iki.fi}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Ilja Klebanov}% [2] organizer name
 {Free University of Berlin}% [3] affiliations
 {klebanov@zedat.fu-berlin.de}% [4] email
 {SS12}
 %{SP10}% [8] session id
 {}% [9] third organizer, if any
 Reproducing kernel Hilbert spaces (RKHSs) are very amenable to the development of efficient approximation and cubature methods. To this end, there has been a surge of interest in recent years regarding some of the advantages that kernel-based methods can offer in applications involving collocation over Monte Carlo or quasi-Monte Carlo point sets---some examples include, e.g., Gaussian process regression (kriging), Bayesian neural networks or uncertainty quantification for partial differential equations. This minisymposium showcases some recent theoretical and computational developments in the study of kernel-based approximation and cubature methods.
\end{session}

%\input{sessSS11}

\input{sessSS12}

\cleardoublepage
\begin{session}
 {MCMC: Convergence and Robustness}% [1] session title
 {Alex Shestopaloff}% [2] organizer name
 {Queen Mary University of London}% [3] affiliations
 {a.shestopaloff@qmul.ac.uk}% [4] email
 {Jun Yang}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {University of Copenhagen}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {jy@math.ku.dk}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 %%%%% from CL, May 4: this session is now labeled SS1
 %%%%% see MasterLists and MCQMC2024Data
 %%%%% we need to change all the labels for the sessions
 {SS1}% [8] session id
 %%%%% CL is commenting out old label on May 4
 %%%%%{SP01}% [8] session id
 {}% [9] third organizer, if any
 As Markov Chain Monte Carlo (MCMC) methods become more complex, a deeper understanding of their convergence and performance guarantees in realistic scenarios becomes an important aspect of using these methods in computational Bayesian statistics. This session aims to further this understanding by focusing on the convergence and robustness of complex MCMC samplers, covering recent work on topics such as convergence of hybrid Gibbs sampling [1], novel methods for evaluation of convergence rates using random number simulations [2] the study of convergence with Dirichlet forms [3] as well as techniques for making MCMC samplers more robust and a study of their corresponding convergence properties, such as [4].

\begin{enumerate}
	\item[{[1]}] Qian Qin, Nianqiao Ju, Guanyang Wang (2023). Spectral gap bounds for reversible hybrid Gibbs chains. arXiv:2312.12782.
	\item[{[2]}] Sabrina Sixta and Jeffrey S. Rosenthal (2023). Bounding and estimating MCMC convergence rates using common random number simulations. arXiv:2309.15735.
	\item[{[3]}] Ning Ning (2022). Convergence of Dirichlet Forms for MCMC Optimal Scaling with General Target Distributions on Large Graphs. arXiv:2210:17042.
	\item[{[4]}] Michael C.H. Choi (2020). Improved Metropolis-Hastings algorithms via landscape modifcation with applications to simulated annealing and the Curie-Weiss model. arXiv: 2011:09680.
\end{enumerate}
\end{session}

%%%%%% from CL on May 4
%%%%%% now we just need to input the corresponding
%%%%%% latex file with sessions description
%%%%%% convention is sess[sessionID].tex so here sessSS1.tex

\input{sessSS1.tex}

\clearpage
\begin{session}
 {Continuous-time dynamics in Monte Carlo and beyond}% [1] session title
 {Neil Chada}% [2] organizer name
 {Heriot-Watt University}% [3] affiliations
 {n.chada@hw.ac.uk}% [4] email
 {Jonas Latz}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {University of Manchester } %[6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {jonas.latz@manchester.ac.uk }% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS17}
 %{SP14}% [8] session id
 {}
 Langevin Monte Carlo methods — such as MALA and ULA [3] — construct a Monte Carlo Markov chain by appropriately discretising certain stochastic differential equations.
 This has the fortunate effect that certain properties of the resulting MCMC algorithms can be derived by studying these SDEs rather than the arising discrete-time Markov chains.
 The idea of analysing an underlying continuous-time system to understand a discrete-time algorithm is much broader and shall be one focus of this minisymposium – with `algorithm’,
 we foremost want to focus on methods in computational statistics, but also look forward to optimisation methods, such as [2], data assimilation, diffusion models, and partial differential equation
 methods in data science. The second focus are Monte Carlo methods that are both posed and used in continuous time, such as piecewise-deterministic Markov processes (cf. [1]).
 \medskip

 \begin{enumerate}
 \item[{[1]}] Bierkens, Joris, Paul Fearnhead \& Gareth Roberts (2019). {\it The Zig-Zag process and super-efficient sampling for Bayesian analysis of big data}. Ann.\ Statist.\ 47(3): 1288-1320.
 \item[{[2]}] Li, Qianxiao , Cheng Tai \& Weinan E (2019). {\it Stochastic Modified Equations and Dynamics of Stochastic Gradient Algorithms I: Mathematical Foundations}. J.\ Mach.\ Learn.\ Res.\ 20(40):1-47.
 \item[{[3]}] Roberts, Gareth \& Richard Tweedie (2002). {\it Exponential convergence of Langevin distributions and their discrete approximations}. Bernoulli 2(4): 341-363.
 \end{enumerate}
\end{session}

\input{sessSS17}


\clearpage


%%FGW

\begin{session}
    {Function spaces and algorithms for high-dimensional problems}% [1] session title
    {Michael Gnewuch}% [2] organizer name
    {University of Osnabr\"uck, Germany}% [3] affiliation(s)
    {michael.gnewuch@uni-osnabrueck.de}% [4] email
    {Klaus Ritter }% [5] Second organizer's name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
    {RPTU Kaiserslautern, Germany}% [6] Second organizer's affiliation(s). Leave unchanged if there is no second organizer, otherwise fill in accordingly.
    {ritter@mathematik.uni-kl.de}% [7] Second organizer's email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
    {SS24}
    %{SP19}%
    {}% [9] third organizer, if any
  High- and infinite-dimensional problems pose serious challenges in numerical practice. An approach to surpass these obstacles is to identify common structural features of the underlying problems. These features are usually encoded in the specific function spaces that are considered in the analysis.
  In this special session we want to bring together researchers from analysis, approximation theory, and information-based complexity to discuss different types of function spaces and algorithmic approaches for high- and infinite-dimensional integration and approximation problems.
\end{session}

\input{sessSS24}


\clearpage

%% NK: organizers cancelled one of four sessions, commenting out part 4 (May 7)
\iffalse
\begin{session}
 {Stochastic Computation and Complexity, Part IV: High dimensional approximation and integration}% [1] session title
 {Larisa Yaroslavtseva}% [2] organizer name
 {University of Graz}% [3] affiliations
 {larisa.yaroslavtseva@uni-graz.at}% [4] email
 {}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {SS6}
 %{SP06}% [8] session id
 {}% [9] third organizer, if any
The session is devoted to algorithms and complexity for
\begin{itemize}[itemsep=0pt,topsep=0pt]
 \item quadrature and strong approximation of SDEs and SPDEs, in particular under nonstandard assumptions,

 \item high and infinite dimensional integration and approximation, and

 \item stochastic optimization and neural networks,
\end{itemize}
including connections to functional analysis and stochastic analysis.
\end{session}



 \fi
\clearpage

% ----------------------------------------------------------------
% ----------------------------------------------------------------
% ----------------------------------------------------------------
\chapter{Abstracts}

%\section{Special Session Talks}

\input{listabstract.tex}

\iffalse
\begin{talk}
 {Talk title \#1}% [1] talk title
 {Awesome Speaker \#1}% [2] speaker name
 {Nice University \#1}% [3] affiliations
 {good.email@gooduni.ca}% [4] email
 {co-author 2, co-author 3}% [5] coauthors
 {This is a TWO-PART session}% [6] special session title
 {\timeslot{Monday, July 18, 2022}{15:30}{16:00}{Lecture Hall 4}}% [7] time slot
 {2011}% [8] talk id
 {2010}% [9] session id
Abstract goes here.
\end{talk}

\begin{talk}
	{Talk title \#2}% [1] talk title
	{Awesome Speaker \#2}% [2] speaker name
	{Nice University \#2}% [3] affiliations
	{good.email@gooduni.ca}% [4] email
	{}% [5] coauthors
	{This is a TWO-PART session}% [6] special session title
	{\timeslot{Monday, July 18, 2022}{15:30}{16:00}{Lecture Hall 4}}% [7] time slot
	{2012}% [8] talk id
	{2010}% [9] session id
	Abstract goes here.
\end{talk}

\begin{talk}
	{Talk title \#3}% [1] talk title
	{Awesome Speaker \#3}% [2] speaker name
	{Nice University \#3}% [3] affiliations
	{good.email@gooduni.ca}% [4] email
	{co-author 2, co-author 3}% [5] coauthors
	{This is a TWO-PART session}% [6] special session title
	{\timeslot{Monday, July 18, 2022}{15:30}{16:00}{Lecture Hall 4}}% [7] time slot
	{2013}% [8] talk id
	{2010}% [9] session id
	Abstract goes here.
\end{talk}

\begin{talk}
	{Talk title \#4}% [1] talk title
	{Awesome Speaker \#4}% [2] speaker name
	{Nice University \#4}% [3] affiliations
	{good.email@gooduni.ca}% [4] email
	{co-author 2, co-author 3}% [5] coauthors
	{This is a TWO-PART session}% [6] special session
	{\timeslot{Monday, July 18, 2022}{15:30}{16:00}{Lecture Hall 4}}% [7] time slot
	{2014}% [8] talk id
	{2010}% [9] session id
	Abstract goes here.
\end{talk}


\begin{talk}
	{Talk title \#5}% [1] talk title
	{Awesome Speaker \#5}% [2] speaker name
	{Nice University \#5}% [3] affiliations
	{good.email@gooduni.ca}% [4] email
	{co-author 2, co-author 3}% [5] coauthors
	{This is a TWO-PART session}% [6] special session title
	{\timeslot{Monday, July 18, 2022}{15:30}{16:00}{Lecture Hall 4}}% [7] time slot
	{2021}% [8] talk id
	{2020}% [9] session id
	Abstract goes here.
\end{talk}

\begin{talk}
	{Talk title \#6}% [1] talk title
	{Awesome Speaker \#6}% [2] speaker name
	{Nice University \#6}% [3] affiliations
	{good.email@gooduni.ca}% [4] email
	{}% [5] coauthors
	{This is a SINGLE-PART session}% [6] special session title
	{\timeslot{Monday, July 18, 2022}{15:30}{16:00}{Lecture Hall 4}}% [7] time slot
	{2022}% [8] talk id
	{2020}% [9] session id
	Abstract goes here.
\end{talk}

\begin{talk}
	{Talk title \#7}% [1] talk title
	{Awesome Speaker \#7}% [2] speaker name
	{Nice University \#7}% [3] affiliations
	{good.email@gooduni.ca}% [4] email
	{co-author 2, co-author 3}% [5] coauthors
	{This is a TWO-PART session}% [6] special session title
	{\timeslot{Monday, July 18, 2022}{15:30}{16:00}{Lecture Hall 4}}% [7] time slot
	{2023}% [8] talk id
	{2020}% [9] session id
	Abstract goes here.
\end{talk}

\begin{talk}
	{Talk title \#8}% [1] talk title
	{Awesome Speaker \#8}% [2] speaker name
	{Nice University \#8}% [3] affiliations
	{good.email@gooduni.ca}% [4] email
	{co-author 2, co-author 3}% [5] coauthors
	{This is a TWO-PART session}% [6] special session
	{\timeslot{Monday, July 18, 2022}{15:30}{16:00}{Lecture Hall 4}}% [7] time slot
	{2024}% [8] talk id
	{2020}% [9] session id
	Abstract goes here.
\end{talk}

\begin{talk}
	{Talk title \#9}% [1] talk title
	{Awesome Speaker \#9}% [2] speaker name
	{Nice University \#9}% [3] affiliations
	{good.email@gooduni.ca}% [4] email
	{co-author 2, co-author 3}% [5] coauthors
	{This is a TWO-PART session}% [6] special session title
	{\timeslot{Monday, July 18, 2022}{15:30}{16:00}{Lecture Hall 4}}% [7] time slot
	{2025}% [8] talk id
	{2020}% [9] session id
	Abstract goes here.
\end{talk}

\begin{talk}
	{Talk title \#10}% [1] talk title
	{Awesome Speaker \#10}% [2] speaker name
	{Nice University \#10}% [3] affiliations
	{good.email@gooduni.ca}% [4] email
	{}% [5] coauthors
	{This is a TWO-PART session}% [6] special session title
	{\timeslot{Monday, July 18, 2022}{15:30}{16:00}{Lecture Hall 4}}% [7] time slot
	{2026}% [8] talk id
	{2020}% [9] session id
	Abstract goes here.
\end{talk}

\begin{talk}
	{Talk title \#11}% [1] talk title
	{Awesome Speaker \#11}% [2] speaker name
	{Nice University \#11}% [3] affiliations
	{good.email@gooduni.ca}% [4] email
	{co-author 2, co-author 3}% [5] coauthors
	{This is a TWO-PART session}% [6] special session title
	{\timeslot{Monday, July 18, 2022}{15:30}{16:00}{Lecture Hall 4}}% [7] time slot
	{2027}% [8] talk id
	{2020}% [9] session id
	Abstract goes here.
\end{talk}

\begin{talk}
	{Talk title \#12}% [1] talk title
	{Awesome Speaker \#12}% [2] speaker name
	{Nice University \#12}% [3] affiliations
	{good.email@gooduni.ca}% [4] email
	{co-author 2, co-author 3}% [5] coauthors
	{}% [6] special session title
	{\timeslot{Monday, July 18, 2022}{15:30}{16:00}{Lecture Hall 4}}% [7] time slot
	{3001}% [8] talk id
	{}% [9] session id
	Abstract goes here.
\end{talk}

\section{Contributed Talks}

\begin{talk}
	{Talk title \#13}% [1] talk title
	{Awesome Speaker \#13}% [2] speaker name
	{Nice University \#13}% [3] affiliations
	{good.email@gooduni.ca}% [4] email
	{co-author 2, co-author 3}% [5] coauthors
	{}% [6] special session title
	{\timeslot{Monday, July 18, 2022}{15:30}{16:00}{Lecture Hall 4}}% [7] time slot
	{3002}% [8] talk id
	{}% [9] session id
	Abstract goes here.
\end{talk}

\begin{talk}
	{Talk title \#14}% [1] talk title
	{Awesome Speaker \#14}% [2] speaker name
	{Nice University \#14}% [3] affiliations
	{good.email@gooduni.ca}% [4] email
	{co-author 2, co-author 3}% [5] coauthors
	{}% [6] special session title
	{\timeslot{Monday, July 18, 2022}{15:30}{16:00}{Lecture Hall 4}}% [7] time slot
	{3003}% [8] talk id
	{}% [9] session id
	Abstract goes here.
\end{talk}

\begin{talk}
	{Talk title \#15}% [1] talk title
	{Awesome Speaker \#15}% [2] speaker name
	{Nice University \#15}% [3] affiliations
	{good.email@gooduni.ca}% [4] email
	{co-author 2, co-author 3}% [5] coauthors
	{}% [6] special session title
	{\timeslot{Monday, July 18, 2022}{15:30}{16:00}{Lecture Hall 4}}% [7] time slot
	{3004}% [8] talk id
	{}% [9] session id
	Abstract goes here.
\end{talk}

\fi

%\newpage
%
%\begin{talk}
% {Linear complexity of some sequences derived from hyperelliptic curves of genus~2} % [1] talk title
% {Vishnupriya Anupindi}% [2] speaker name
% {Austrian Academy of Sciences}% [3] affiliations
% {vishnupriya.anupindi@oeaw.ac.at}% [4] email
% {L\'{a}szl\'{o} M\'{e}rai}% [5] coauthors
% {Pseudo-Random Number Generation}% [6] special session
% {\timeslot{Friday, July 22, 2022}{09:00}{09:30}{Lecture Hall 5}}% [7] time slot
% {2221}% [8] talk id
% {2220}% [9] session id
%In this talk, we investigate the level of randomness of specific sequences derived from hyperelliptic curves of genus $2$. For elliptic curves, the randomness properties of such sequences are well-studied. Here we study the corresponding construction in the hyperelliptic case.
%
%Let $C$ be a hyperelliptic curve of genus $2$ defined by
%$$
%C: \ y^2 = x^5 + b_1x^4 + b_2x^3 + b_3x^2 + b_4x + b_5
%$$
%over a finite field $\mathbb{F}_q$ of odd characteristic.
%One can define a group operation on the \emph{Jacobian} $J_C$ of the curve $C$. For curves of genus $2$, the Jacobian is a $2$ dimensional abelian variety.
%
%We look at two different ways of generating sequences on the Jacobian, that is, the linear congruential generator and the Frobenius endomorphism generator. We show that these sequences posses good pseudorandom properties in term of linear complexity.
%
%Our method uses an embedding of the Jacobian $J_C$ into $\mathbb{P}^8$ provided by David Grant, which gives explicit addition formulas for points on the Jacobian. After tailoring these formulas for the Jacobian over finite fields, we are able to prove the required degree estimates in order to use Stepanov's method.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Constructive subsampling of finite frames with applications in optimal function recovery}% [1] talk title
% {Felix Bartel}% [2] speaker name
% {Chemnitz University of Technology}% [3] affiliations
% {felix.bartel@mathematik.tu-chemnitz.de}% [4] email
% {Martin Sch\"{a}fer, Tino Ullrich}% [5] coauthors
% {Approximation from Random Data}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{11:00}{11:30}{Lecture Hall 3}}% [7] time slot
% {2182}% [8] talk id
% {2180}% [9] session id
%In this talk we present new constructive methods, random and deterministic, for the efficient subsampling of finite frames in $\mathbb{C}^m$. Based on a suitable random subsampling strategy, we are able to extract from any given frame with bounds $0<A\le B<\infty$ (and condition $B/A$) a similarly conditioned reweighted subframe consisting of merely $\mathcal{O}(m\log m)$ elements. Further, utilizing a deterministic subsampling method based on principles developed by Batson, Spielman and Srivastava, we are able to reduce the number of elements to $\mathcal{O}(m)$ (with a constant close to one). By controlling the weights via a preconditioning step, we can, in addition, preserve the lower frame bound in the unweighted case. This allows to derive new quasi-optimal unweighted (left) Marcinkiewicz-Zygmund inequalities for $L_2(D,\nu)$ with constructible node sets of size $\mathcal{O}(m)$ for $m$-dimensional subspaces of bounded functions. Those can be applied e.g.\ for (plain) least-squares sampling reconstruction of functions, where we obtain new quasi-optimal results avoiding the Kadison-Singer theorem. Numerical experiments indicate the applicability of our results.
%\end{talk}
%
%\newpage
%
%
%\begin{talk}
% {Energy measures in Grassmannian spaces}% [1] talk title
% {Carlos Beltr\'{a}n}% [2] speaker name
% {Universidad de Cantabria}% [3] affiliations
% {beltranc@unican.es}% [4] email
% {Diego Cuevas, Ignacio Santamar\'ia, V{\' i}t~Tu{\v c}ek, Gunnar Peters}% [5] coauthors
% {Energy-Minimizing Point Configurations and Measures II}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{16:30}{17:00}{Lecture Hall 3}}% [7] time slot
% {2281}% [8] talk id
% {2280}% [9] session id
%Recall that the Grassmannian $\mathbb G(M,\mathbb K^T)$ is the set of $M$--dimensional subspaces of $\mathbb K^T$ where $\mathbb K=\mathbb R$ or $\mathbb C$ and $M<T$.
%
%Among the many ways to define the energy of a finite collection of elements $X_1,\ldots,X_K\in\mathbb G(M,\mathbb K^T)$, one of particular interest for the so called non--coherent MIMO communication networks is given by the formula:
%$$
%\sum_{k\neq j}\det(\mathrm {Id}_M-X_k^HX_jX_j^HX_k)^{-N},
%$$
%for different values of $N$. In this talk I will describe theoretical and practical advances both in the study of lower and upper bounds for this energy and related concepts, and in the generation of actual structured and unstructured collections of points with quasioptimal energy.
%
%This work is based in papers [1] and [2] and partially supported by grants PID2020-113887GB-I00 and PID2019-104958RB-C43 funded by MCIN/ AEI /10.13039/501100011033, as well as by project GRASSCOM, Huawei Technologies, Sweden.
%
%
%\medskip
%[1] A Fast Algorithm for Designing Grassmannian Constellations. Diego Cuevas, Carlos Beltr\'an Ignacio Santamar\'ia, V{\' i}t~Tu{\v c}ek and Gunnar Peters. WSA 2021, EURECOM, ISBN 978-3-8007-5686-5.
%
%[2] Union Bound Minimization Approach for Designing Grassmannian Constellations. Diego Cuevas, Carlos Beltr\'an Ignacio Santamar\'ia, V{\' i}t~Tu{\v c}ek and Gunnar Peters. To appear.
%\end{talk}
%
%
%\newpage
%
%
%\begin{talk}
% {Quasi-Monte Carlo and multilevel Monte Carlo combined with numerical smoothing for robust and efficient option pricing and density estimation}% [1] talk title
% {Chiheb Ben Hammouda}% [2] speaker name
% {RWTH Aachen University}% [3] affiliations
% {benhammouda@uq.rwth-aachen.de}% [4] email
% {Christian Bayer, Ra\'ul Tempone}% [5] coauthors
% {}% [6] special session
% {\timeslot{Wednesday, July 20, 2022}{14:00}{14:30}{Lecture Hall 5}}% [7] time slot
% {4431}% [8] talk id
% {4430}% [9] session id
%In several applications, when approximating the expectation of a functional of a stochastic process, the robustness and performance of deterministic quadrature, quasi-Monte Carlo (QMC), and multilevel Monte Carlo (MLMC) methods may critically depend on the regularity of the integrand. To overcome this issue and reveal the available regularity, we consider cases in which analytic smoothing cannot be performed. In [1], we introduce a novel numerical smoothing approach by combining a root-finding algorithm with one-dimensional integration with respect to a single well-selected variable. We prove that, under appropriate conditions, the resulting function of the remaining variables is highly smooth, potentially affording the improved efficiency and robustness of QMC and MLMC methods. Our study is motivated by option pricing and density estimation problems, and our focus is on dynamics where the discretization of the asset price is necessary. Our analysis and numerical experiments in [1] demonstrate the advantages of combining numerical smoothing with the adaptive sparse grid quadrature (ASGQ) and QMC methods over ASGQ and QMC methods without smoothing. In [2], our analysis and numerical experiments show that our numerical smoothing improves the robustness (by controlling the kurtosis at deep levels) and complexity of the MLMC method. In particular, the smoothness theorem presented in [1] enables us to recover the MLMC complexities obtained for smooth or Lipschitz functionals. Moreover, our approach efficiently estimates density functions, a task that previous methods based on Monte Carlo or MLMC fail to achieve efficiently, at least in moderate to high dimensions. Finally, our approach in [1,2] is generic and can be applied to solve a broad class of problems, particularly for approximating distribution functions, financial Greeks computation, and risk estimation.
%\medskip
%
%[1] Bayer, Christian, Chiheb Ben Hammouda, and Ra\'{u}l Tempone. "Numerical Smoothing with Hierarchical Adaptive Sparse Grids and Quasi-Monte Carlo Methods for Efficient Option Pricing." arXiv preprint arXiv:2111.01874 (2021).
%
%[2] Bayer, Christian, Chiheb Ben Hammouda, and Ra\'{u}l Tempone. "Multilevel Monte Carlo Combined with Numerical Smoothing for Robust and Efficient Option Pricing and Density Estimation." To appear (2022).
%\end{talk}
%
%\begin{talk}
% {Efficient importance sampling algorithm applied to the performance analysis of wireless communication systems estimation}% [1] talk title
% {Nadhir Ben Rached}% [2] speaker name
% {RWTH Aachen University}% [3] affiliations
% {benrached@uq.rwth-aachen.de}% [4] email
% {Eya Ben Amar, Abdul-Lateef Haji-Ali, Ra\'ul Tempone}% [5] coauthors
% {Variance Reduction Techniques for Rare Events}% [6] special session
% {\timeslot{Tuesday, July 19, 2022}{16:30}{17:00}{Lecture Hall 5}}% [7] time slot
% {2041}% [8] talk id
% {2040}% [9] session id
%When assessing the performance of wireless communication systems operating over fading channels, one often encounters the problem of computing expectations of some functional of sums of independent random variables (RVs). The outage probability (OP) at the output of Equal Gain Combining and Maximum Ratio Combining receivers is among the most important performance metrics that falls within this framework. In general, closed form expressions of expectations of functionals applied to sums of RVs are out of reach.
%A naive Monte Carlo simulation is of course an alternative approach. However, this method requires a large number of samples for rare event problems (small OP values for instance). Therefore, it is of paramount importance to use variance reduction techniques to develop fast and efficient estimation methods. In this work, we use importance sampling (IS), being known for its efficiency in requiring less
%computations for achieving the same accuracy requirement. In this line, we propose a state-dependent IS scheme based on a stochastic optimal control formulation to calculate rare events quantities that could be written in a form of an expectation of some functional of sums of independent RVs. Our proposed algorithm is generic and can be applicable without any restriction on the univariate distributions of the different fading envelops/gains or on the functional that is applied to the sum. We apply our approach to the Log-Normal distribution to compute the OP at the output of diversity receivers with and without co-channel interference. For each case, we show numerically that the proposed state-dependent IS algorithm compares favorably to most of the well-known estimators dealing with similar problems.
%\end{talk}
%
%
%\begin{talk}
% {PDDSparse: a highly scalable algorithm for large-scale PDEs}% [1] talk title
% {Francisco Bernal}% [2] speaker name
% {Universidad Carlos III de Madrid}% [3] affiliations
% {franciscomanuel.bernal@uc3m.es}% [4] email
% {Jorge Morón, Juan A. Acebr\'{o}n, Renato Spigler, Andr\'{e}s Berridi}% [5] coauthors
% {}% [6] special session
% {\timeslot{Wednesday, July 20, 2022}{14:30}{15:00}{Lecture Hall 3}}% [7] time slot
% {4232}% [8] talk id
% {4230}% [9] session id
%I will present a new probabilistic domain decomposition method [1]---called PDDSparse---intended for the solution of large-scale PDEs on parallel computers. The idea is to first solve the PDE along the subdomain interfaces with Feynman-Kac-based Monte Carlo simulations, thus rendering the subdomain-restricted PDEs well posed. The new insight of PDDSparse is to integrate the Feynman-Kac diffusions in the subdomains only, by coupling the unknown boundary conditions by interpolation. In this way, a stochastic linear system arises whose solution are the interfacial nodal values. This system is only ${\cal O}(\sqrt{N})$ (where $N$ is the total size of the PDE discretisation), highly structured and sparse, and apparently stable. On the other hand, the Feynman-Kac diffusions are orders of magnitude faster and take only local information of the PDE for integration, while variance reduction can be incorporated naturally [2]. Preliminary results obtained in the supercomputing facility CINECA will be discussed.
%
%\medskip
%
%
%[1] J.A. Acebr\'{o}n, M.P. Busico, P. Lanucara, R. Spigler (2005). Domain decomposition solution of elliptic problems via probabilistic methods, SIAM J. Sci. Comput. 27, 440-457
%
%[2] F. Bernal, and J.A. Acebr\'{o}n (2016). A multigrid-like algorithm for probabilistic domain decomposition. Computers and Mathematics with Applications 72, 1790-1810.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Higher order approximations of piecewise deterministic Markov processes with splitting schemes}% [1] talk title
% {Andrea Bertazzi}% [2] speaker name
% {Delft University of Technology}% [3] affiliations
% {a.bertazzi@tudelft.nl}% [4] email
% {Paul Dobson, Pierre Monmarch\'{e}}% [5] coauthors
% {Recent Advances in Piecewise Deterministic Monte Carlo Methods}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{12:00}{12:30}{Lecture Hall 6}}% [7] time slot
% {2054}% [8] talk id
% {2050}% [9] session id
%Piecewise deterministic Markov processes (PDMPs) received substantial interest in recent years as an alternative to classical Markov chain Monte Carlo algorithms. While theoretical properties of PDMPs have been studied extensively, their practical implementation remains limited to specific applications in which bounds on the gradient of the negative log-target can be derived. In order to address this problem, we propose to approximate PDMPs using splitting schemes, that means simulating the deterministic dynamics and the random jumps in two different stages. First, we show that, as expected, basic symmetric splittings of PDMPs are of second order. Then we focus on the Zig-Zag sampler and the Bouncy Particle sampler and discuss the convergence properties of the approximations obtained using different splitting schemes. For this we study both the bias introduced by the discretisation and the rate of convergence. Numerical experiments are given to support our theoretical findings.
%\end{talk}
%
%\begin{talk}
% {A-posteriori numerical methods for random elliptic PDEs}% [1] talk title
% {Cedric Beschle}% [2] speaker name
% {University of Stuttgart}% [3] affiliations
% {cedric.beschle@mathematik.uni-stuttgart.de}% [4] email
% {Andrea Barth}% [5] coauthors
% {Multilevel and Higher-Order Approximations for Stochastic Processes, Random Fields and PDEs}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{16:30}{17:00}{Lecture Hall 4}}% [7] time slot
% {2021}% [8] talk id
% {2020}% [9] session id
%Flow through fractured porous media may be modeled mathematically by partial differential equations (PDEs) with discontinuous coefficients. The spatial discontinuities in the coefficients introduce low regularity in the respective PDE solution, which in turn yields deteriorated convergence rates for standard numerical spatial discretziations.
%Including uncertainties representing measurement errors or unknown geometry into the model results in a random PDE, where we are interested in the efficient approximation of moments of the random PDE solution.
%However, the deteriorated spatial convergence rates are transferred over to the approximation of moments.
%In this talk we consider the application of a-posteriori error estimation techniques yielding improved spatial convergence rates, to the approximation of moments of solutions to a linear random elliptic PDE with discontinuous diffusion coefficient.
%\end{talk}
%
%\begin{talk}
% {Minimality results for the Embedded-atom model}% [1] talk title
% {Laurent B\'etermin}% [2] speaker name
% {Universit\'e Claude Bernard Lyon 1}% [3] affiliations
% {betermin@math.univ-lyon1.fr}% [4] email
% {Manuel Friedrich, Ulisse Stefanelli}% [5] coauthors
% {Periodic Point Configurations and Lattice Point Interactions}% [6] special session
% {\timeslot{Monday, July 18, 2022}{17:00}{17:30}{Lecture Hall 3}}% [7] time slot
% {2072}% [8] talk id
% {2070}% [9] session id
%The Embedded-atom model (EAM) provides a phenomenological description of atomic arrangements in metallic systems and is widely used in molecular simulations. It consists of a configurational energy depending on atomic positions and featuring the interplay of two-body atomic interactions and nonlocal effects due to the corresponding electronic clouds. In this talk, I will present minimality results for this system among lattices in dimensions 2 and 3 as well as other aspects of the problem (dilute system, equilibrium measure, etc., according to progresses made on the problem by the conference). Rigorous results based on variational arguments as well as numerics will be presented.
%\end{talk}
%
%\begin{talk}
% {On the properties of randomized Euler and Runge-Kutta schemes for ODEs}% [1] talk title
% {Tomasz Bochacik}% [2] speaker name
% {AGH University of Science and Technology}% [3] affiliations
% {bochacik@agh.edu.pl}% [4] email
% {}% [5] coauthors
% {Stochastic Computation and Complexity: High Dimensional Approximation, Integration, and PDEs}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{17:30}{18:00}{STC 1012}}% [7] time slot
% {2167}% [8] talk id
% {2160}% [9] session id
%We will report the results concerning error bounds and optimality of randomized explicit and implicit Euler schemes and the randomized two-stage Runge-Kutta scheme under inexact information and mild assumptions about the right-hand side function (including local H\"older and Lipschitz continuity in time and space variables, respectively). This part will be based on papers [2,3] which extend the well-known results for exact information and global assumptions.
%
%Moreover, we will establish an upper bound for the probability of the exceptional set for investigated algorithms, also in the setting of inexact information, cf. [1].
%
%\medskip
%
%[1] T. Bochacik, On the properties of the exceptional set for the randomized Euler and Runge-Kutta schemes (2022), arXiv:2202.01683.
%
%[2] T. Bochacik, M. Go\'{c}win, P. M. Morkisz, P. Przyby\l{}owicz, Randomized Runge-Kutta method -- Stability and convergence under inexact information, {\em J. Complex.} {\bf 65} (2021), 101554.
%
%[3] T. Bochacik, P. Przyby\l{}owicz, On the randomized Euler schemes for ODEs under inexact information (2021), arXiv:2104.15071.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {The $L^2$ discrepancy of lattices revisited}% [1] talk title
% {Bence Borda}% [2] speaker name
% {Graz University of Technology}% [3] affiliations
% {borda@math.tugraz.at}% [4] email
% {}% [5] coauthors
% {What Did You Expect? Equidistribution in Number Theory}% [6] Special session title
% {\timeslot{Wednesday, July 20, 2022}{10:30}{11:00}{Lecture Hall 3}}% [7] time slot
% {2011}% [8] talk id
% {2010}% [9] session id
%The first $N$-element point set in the unit square whose $L^2$ discrepancy is of optimal order $\ll \sqrt{\log N}$ was found by Davenport, who constructed a symmetrized lattice using a badly approximable irrational. Revisiting this classical construction, with or without symmetrization, and using arbitrary irrationals, we established the precise relationship between the $L^2$ discrepancy of such lattices and the continued fraction expansion of the irrational. For instance, Davenport's construction is optimal if and only if the quadratic mean of the partial quotients is bounded; for the same construction without symmetrization to be optimal, we also need at least square root cancellation in the alternating sum of the partial quotients. We find the asymptotics for classical numbers such as quadratic irrationals or Euler's number, and also for typical irrationals by finding the limit distribution of the $L^2$ discrepancy. The case of rational lattices is entirely analogous, and lead to the limit distribution of the $L^2$ discrepancy of a randomly chosen symmetrized rational lattice.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Lattice points to the sphere: towards discrepancy estimates}% [1] talk title
% {Johann S.~Brauchart}% [2] speaker name
% {Graz University of Technology}% [3] affiliations
% {j.brauchart@tugraz.at}% [4] email
% {Josef Dick, Yuan Xu}% [5] coauthors
% {Periodic Point Configurations and Lattice Point Interactions}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{16:30}{17:00}{Lecture Hall 3}}% [7] time slot
% {2071}% [8] talk id
% {2070}% [9] session id
%It is a well-known fact that an $N$-point configuration on the unit sphere in $\mathbb{R}^3$ that maximizes the sum of all mutual Euclidean distances has minimal spherical cap $\mathbb{L}_2$-discrepancy (Stolarsky's Invariance Principle).
%
%Bounds for the maximal sum of distances show that this discrepancy tends to $0$ as $N \to \infty$ with convergence rate $N^{-\frac{3}{4}}$. The precise asymptotic behavior is closely related to unresolved questions about the asymptotic expansion of optimal Riesz $s$-energy and, in turn, universal optimality of planar configuration in the context of best-packing, renormalized energy, and the optimality of the hexagonal lattice.
%
%For constructible point sets on the sphere less is known.
%
%Using the area-preserving Lambert cylindrical equal-area projection, a planar configuration like a (rational) lattice can be mapped to the sphere. %(Rational) lattices in the plane are one such example.
%
%The so far best possible provable bound for the $\mathbb{L}_2$-discrepancy is the same as for the expected value for i.i.d. random points from 2012 for which the rate of convergence is $N^{-\frac{1}{2}}$.
%
%In this talk, we present recent (partial) results for the Fibonacci lattice mapped to the sphere and comment on hyperuniformity of such configurations.
%\end{talk}
%
%
%\newpage
%
%\begin{talk}
% {Spectral analysis of multivariate multilevel Monte Carlo methods}% [1] talk title
% {J\'{e}r\'{e}my Briant}% [2] speaker name
% {IRIT-CNRS, CECI-CNRS, Cerfacs}% [3] affiliations
% {jeremy.briant@irit.fr}% [4] email
% {M. Destouches, S. Gratton, S. G\"{u}rol, P. Mycek, E. Simon, A. Weaver}% [5] coauthors
% {}% [6] special session
% {\timeslot{Wednesday, July 20, 2022}{10:30}{11:00}{Lecture Hall 6}}% [7] time slot
% {4551}% [8] talk id
% {4550}% [9] session id
%Multi-fidelity variance reduction methods are being used increasingly in different fields as an improvement over the simple Monte Carlo method. In most cases, they are used to estimate scalar quantities of interest. However, in some applications, the quantity of interest may be a statistic of a multivariate random variable, for example the expectation of a discretized random field in geosciences. In such cases, a scalar measure of the multivariate error only provides limited information, while a more thorough analysis may give better insight into the underlying error field.\\
%This work focuses on multilevel Monte Carlo (MLMC) methods, which aim to reduce the sampling error of estimators by combining samples of different resolutions. We conduct a Fourier analysis of the error of those MLMC estimators to study the estimation quality at different scales. The conclusions allow us to improve the existing method for multivariate applications. Similar to multigrid techniques, we apply pre- and post-smoothing filters to better preserve the correlation between the different fidelity levels. This leads to a reduction of the overall estimation error along with the possibility of focusing the estimation on specific scales of interest.\\
%The first part of the presentation introduces MLMC methods for the estimation of multivariate quantities of interest. We then present a theoretical spectral analysis for the MLMC estimation of the expectation of a discretized random field, whose conclusions motivate the introduction of filtering. Finally, we test the resulting methodology on the estimation of the diagonal of diffusion-based covariance matrices of 2D random fields.
%
%This project has received financial support from the CNRS through the 80 $\vert$ Prime program.
%This work was supported by the French national program LEFE (Les Enveloppes Fluides et l'Environnement).
%\end{talk}
%
%
%
%
%\newpage
%
%\begin{talk}
% {Approximate manifold sampling via the Hug sampler}% [1] talk title
% {Mauro Camara Escudero}% [2] speaker name
% {University of Bristol}% [3] affiliations
% {m.camaraescudero@bristol.ac.uk}% [4] email
% {Christophe Andrieu, Mark Beaumont}% [5] coauthors
% {Robust Innovations in Gradient-Based MCMC}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{11:00}{11:30}{Lecture Hall 4}}% [7] time slot
% {2272}% [8] talk id
% {2270}% [9] session id
%Sampling from a probability density constrained to a manifold is of importance in numerous applications arising in statistical physics, statistics or machine learning. Sampling from such constrained densities, in particular using an MCMC approach, poses significant challenges and it is only recently that correct solutions have been proposed. The resulting algorithms can however be computationally expensive. We propose a relaxation of the problem where the support constraint is replaced with that of sampling from a small neighbourhood of the manifold. We develop a family of bespoke and efficient algorithms adapted to this problem and demonstrate empirically their computational superiority, which comes at the expense of a modest bias.
%
%\medskip
%
%[1] Ludkin, M. and Sherlock, C. Hug and hop: a discrete-time, non-reversible markov chain monte-carlo algorithm, 2021. \\
%\noindent [2] Au, K. X., Graham, M. M., and Thiery, A. H. Manifold lifting: scaling mcmc to the vanishing noise regime,
%2021. \\
%\noindent [3] Lelievre, T., Rousset, M., and Stoltz, G. Hybrid monte carlo methods for sampling probability measures on
%submanifolds, 2019.
%\end{talk}
%
%\newpage
%
%
%
%\begin{talk}
% {Adaptive stochastic gradient descent for Bayesian optimal experimental design}% [1] talk title
% {Andr\'e Gustavo Carlon}% [2] speaker name
% {King Abdullah University of Science and Technology}% [3] affiliations
% {agcarlon@gmail.com}% [4] email
% {Joakim Beck, Ra\'ul Tempone}% [5] coauthors
% {}% [6] special session
% {\timeslot{Monday, July 18, 2022}{16:00}{16:30}{Lecture Hall 4}}% [7] time slot
% {4312}% [8] talk id
% {4310}% [9] session id
%Experiments play a central role in many fields of science.
%Usually, it is of the interest of the investigators to perform experiments as efficiently as possible.
%However, finding the optimal design for an experiment can be a cumbersome task.
%In the field of Bayesian optimal experimental design, it is usual to use the mutual information between experimental observations and parameters of interest, the Expected Information Gain (EIG), as a measure of the quality of an experiment.
%Thus, in a gradient-based optimization approach to maximize the EIG, one needs to compute the gradient of the EIG every iteration.
%Here, we propose the use of an adaptive Stochastic Gradient Descent (SGD) using a double-loop Monte Carlo (DLMC) estimator of the gradient of the EIG.
%Every optimization iteration, we compute the DLMC sample sizes necessary to keep the relative statistical error and the relative bias uniformly bounded.
%Under the assumption of strong-convexity of the EIG, we prove that our method attains linear convergence iteration-wise in the $L^2$ sense.
%Our error analysis of the DLMC estimator of the gradient of the EIG incorporates discretization errors of the model, thus being suited for cases where the experiment is described by a partial or ordinary differential equation.
%The performance of SGD with our DLMC estimator is validated with numerical results.
%\end{talk}
%
%
%
%\begin{talk}
% {Adaptive reduced order models for rare event simulation}% [1] talk title
% {Fr\'ed\'eric C\'erou}% [2] speaker name
% {Inria, Univ Rennes}% [3] affiliations
% {Frederic.Cerou@inria.fr}% [4] email
% {Patrick H\'eas, Mathias Rousset}% [5] coauthors
% {Approximate Models for Rare Event Simulation and Uncertainty Quantification}% [6] Special session title
% {\timeslot{Wednesday, July 20, 2022}{11:00}{11:30}{Lecture Hall 5}}% [7] time slot
% {2082}% [8] talk id
% {2080}% [9] session id
%We want to compute the probability of a rare event of the form $P(S(X)>L)$, with $X$ a random vector in ${\bf R}^d$, with a computable density (up to a normalization constant), and $S$ a real function that is very expensive to compute. We assume that we have a budget, i.e., a fixed number of complete evaluations of $S$, and that we can also build reduced-order models of $S$, which can be iteratively refined when new values of $S$ are computed. We propose a fully adaptive algorithm to iteratively build an importance sampling distribution and draw from it, the objective being the evaluation of the probability of rare events.
%The importance distribution takes the form of a Gibbs measure based on the current reduced order model, with parameters adjusted to minimize the relative entropy with respect to the target rare event probability distribution. A sequential Monte-Carlo technique generates from this Gibbs measure a swarm of particles, which is used as an empirical approximation of the importance distribution. At each iteration, a sample is drawn from the current empirical measure, the exact value of $S$ calculated, the estimate of the rare event updated, as well as the reduced order model, the Gibbs measure, and the empirical sampling distribution. After the detailed presentation of the algorithm, we will give some heuristics. Some numerical results will also illustrate its relevance.
%\end{talk}
%
%
%\begin{talk}
% {Efficient algorithms for star discrepancy subset selection}% [1] talk title
% {Fran\c{c}ois Cl\'{e}ment}% [2] speaker name
% {Sorbonne Universit\'{e}}% [3] affiliations
% {francois.clement@lip6.fr}% [4] email
% {Carola Doerr, Lu\'{\i}s Paquete}% [5] coauthors
% {Random Points: Generation, Quality Criteria, and Applications}% [6] Special session title
% {\timeslot{Friday, July 22, 2022}{09:00}{09:30}{Lecture Hall 4}}% [7] time slot
% {2141}% [8] talk id
% {2140}% [9] session id
%Low-discrepancy sequences such as Sobol' and Hammersley sequences are designed to have small discrepancy values asymptotically, when the number of points tends to infinity. In practice, applications requiring low-discrepancy points sets will only use a finite, much smaller number of points. In this talk, we introduce the Star Discrepancy Subset Selection Problem [1], which consists in choosing from a set $P$ of $n$ points a subset $P_m$ of size $m \leq n$ such that the $L_{\infty}$-star discrepancy of $P_m$ is minimized. The aim of this approach is to provide point sets better tailored to practical applications. Given that the complexity of calculating the star-discrepancy is $W[1]$-hard [2], it is not surprising that we are able to show that this problem is NP-hard. We provide two algorithms, respectively based on Mixed Integer Linear Programming and Branch-and-Bound, to tackle this problem. For dimensions two and three and $n$ not too large, our algorithms provide point sets of much smaller $L_{\infty}$-star discrepancy than for point sets taken directly from usual low-discrepancy sequences. We also extend this approach to the much easier to compute $L_2$-star discrepancy, where we can find an analogy to an unconstrained binary quadratic programming problem, with a very weak dependency on the dimension of the point set.
%\medskip
%\begin{itemize}
%\item[{[1]:}]François Cl\'{e}ment, Carola Doerr, Lu\'{\i}s Paquete, Star discrepancy subset selection: Problem formulation and efficient approaches for low dimensions, Journal of Complexity, Volume 70, 2022, https://doi.org/10.1016/j.jco.2022.101645.
%\item[{[2]:}]Panos Giannopoulos, Christian Knauer, Magnus Wahlström, Daniel Werner, Hardness of discrepancy computation and $\epsilon$-net verification in high dimension, Journal of Complexity, Volume 28, Issue 2, 2012, Pages 162-176, https://doi.org/10.1016/j.jco.2011.09.001.
%\end{itemize}
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Optimal scaling of proximal MCMC}% [1] talk title
% {Francesca R.~Crucinio}% [2] speaker name
% {University of Warwick}% [3] affiliations
% {francesca.crucinio@warwick.ac.uk}% [4] email
% {Alain Durmus, Pablo Jim\'enez, \'Eric Moulines, Gareth Roberts}% [5] coauthors
% {}% [6] special session
% {\timeslot{Monday, July 18, 2022}{16:00}{16:30}{Lecture Hall 5}}% [7] time slot
% {4412}% [8] talk id
% {4410}% [9] session id
%Proximal MCMC is a recently proposed class of MCMC methods which uses proximity maps instead of gradients to build proposal mechanisms which can be employed for both differentiable and non-differentiable targets [1].
%These methods have been shown to be stable for a wide class of targets, making them a valuable alternative to Metropolis-adjusted Langevin algorithms (MALA); and have found wide application in imaging contexts [1, 2].
%The wider stability properties are obtained by building the Moreau-Yoshida envelope for the target of interest, which depends on a parameter $\lambda$.
%
%In this work we investigate the optimal scaling problem for proximal MCMC, show that MALA is a special case of this class of algorithms and provide practical guidelines for the selection of the scale parameter and the parameter $\lambda$.
%\medskip
%
%[1] M. Pereyra. Proximal Markov chain Monte Carlo algorithms. \emph{Statistics and Computing}, 26(4):745--760, 2016
%
%[2] A. Durmus, E. Moulines, and M. Pereyra. Efficient Bayesian computation by proximal Markov chain
%Monte Carlo: when Langevin meets Moreau. \emph{SIAM Journal on Imaging Sciences}, 11(1):473–506,
%2018.
%\end{talk}
%
%\begin{talk}
% {Numerical approximation of solutions of delay and ordinary differential equations under nonstandard assumptions and noisy information}% [1] talk title
% {Natalia Czy\.zewska}% [2] speaker name
% {AGH University of Science and Technology}% [3] affiliations
% {nczyzew@agh.edu.pl}% [4] email
% {Pawe\l{} Morkisz, Pawe\l{} Przyby\l{}owicz}% [5] coauthors
% {}% [6] special session
% {\timeslot{Monday, July 18, 2022}{16:00}{16:30}{STC 1012}}% [7] time slot
% {4112}% [8] talk id
% {4110}% [9] session id
%The classical literature concerning problem of approximation of ODEs and DDEs solutions assume some regularity of the right-hand side function of the initial value problem, commonly Lipschitz condition. Meanwhile, it turns out that the real world applications are modeled by suitable ODEs and DDEs under nonstandard assumptions. For example, a phase change of metallic materials can be modeled by DDE with a non-Lipschitz right-hand side function, see [5, chapter 3.3] and [4,3].
%
%The talk will be divided into two parts. Firstly, we will consider a DDE case with a multidimensional right-hand side function which is also locally H\"older continuous and fulfills one-side Lipschitz condition [1]. Then, we will sketch an ODE case with a multidimensional right-hand side function where assumptions about it are also nonstandard and we allow a presence of informational noise [2]. In the both cases we show the results concerning the upper bounds on the error of the Euler scheme applied to such ODEs or DDEs. Finally, results of numerical simulations will be presented.
%
%\medskip
%
%\begin{enumerate}
%	\item[[1\kern-6pt]] N. Czy\.zewska, P. Morkisz, P. Przyby\l{}owicz.
%\newblock {\em Approximation of solutions of DDEs under nonstandard assumptions via Euler scheme}.
%\newblock 2021, arXiv:2106.03731.
%
%	\item[[2\kern-6pt]] N. Czy\.zewska, P. Morkisz, P. Przyby\l{}owicz.
%\newblock {\em Approximation of solutions of ODEs with noisy information under nonstandard assumptions via Euler scheme}.
%\newblock In preparation.
%
%	\item[[3\kern-6pt]] N. Czy\.zewska, J. Kusiak. P. Morkisz, P. Oprocha, M. Pietrzyk, P. Przyby\l{}owicz, \L{}. Rauch and D. Szeliga.
%\newblock {\em On mathematical aspects of evolution of dislocation density in metallic materials}.
%\newblock 2020, arXiv:2011.08504.
%
%	\item[[4\kern-6pt]] N. Czy\.zewska, J. Kusiak. P. Morkisz, P. Oprocha, M. Pietrzyk, P. Przyby\l{}owicz, \L{}. Rauch, D. Szeliga.
%\newblock {\em Prediction of Distribution of Microstructural Parameters in Metallic Materials Described by Differential Equations with Recrystallization Term}.
%\newblock International Journal for Multiscale Computational Engineering, \textbf{17}(3) (2019), 361-371.
%
%	\item[[5\kern-6pt]] M. Pietrzyk, \L{}. Madej, \L{}. Rauch, D. Szeliga.
%\newblock {\em Computational Materials Engineering: Achieving high accuracy and efficiency in metals processing simulations}.
%\newblock Butterworth-Heinemann, Elsevier, Amsterdam, 2015.
%\end{enumerate}%
%\end{talk}
%
%\begin{talk}
% {Approximation of stochastic PDEs with measurable reaction term}% [1] talk title
% {Konstantinos Dareiotis}% [2] speaker name
% {University of Leeds}% [3] affiliations
% {k.dareiotis@leeds.ac.uk}% [4] email
% {Oleg Butkovsky, M\'at\'e Gerencs\'er}% [5] coauthors
% {Stochastic Computation and Complexity: Approximation of SDEs with Non-standard Coefficients}% [6] Special session title
% {\timeslot{Wednesday, July 20, 2022}{11:30}{12:00}{STC 1012}}% [7] time slot
% {2293}% [8] talk id
% {2290}% [9] session id
%In this talk we will deal with the approximation of stochastic PDEs, in spatial dimension one, of the form
%\begin{equation}
%\partial_t u = \Delta u + f(u) + \xi, \qquad u(0, x)=u_0(x), \qquad (t, x) \in [0, 1] \times \mathbb{T} \label{eq:SPDE}
%\end{equation}
%where $\xi$ is a space-time white noise on $[0, 1] \times \mathbb{T}$ and $f: \mathbb{R} \to \mathbb{R}$. While the approximation of the solution of \eqref{eq:SPDE} has been extensively studied in the case that $f$ is Lipschitz continuous, or at least one-sided Lipschitz, very few results were available for less regular $f$. In this talk we will show that the rate of convergence of the fully discrete, explicit in time, finite difference scheme is $1/2$ in space and $1/4$ in time, even for merely bounded, measurable $f$. The proof relies on the regularisation effect of the noise. To exploit and quantify this effect we use an infinite dimensional version of the stochastic sewing lemma.
%\end{talk}
%
%\begin{talk}
% {On quantitative Laplace-type convergence results}% [1] talk title
% {Valentin De Bortoli}% [2] speaker name
% {CNRS, ENS Ulm Paris}% [3] affiliations
% {valentin.debortoli@gmail.com}% [4] email
% {Agnes Desolneux}% [5] coauthors
% {Laplace Approximation and Other Model-Based Preconditioning Methods for Monte Carlo Algorithms}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{16:30}{17:00}{Lecture Hall 6}}% [7] time slot
% {2261}% [8] talk id
% {2260}% [9] session id
%Laplace-type results characterize the limit of sequence of measures
%$(\pi_\varepsilon)_{\varepsilon >0}$ with density w.r.t the Lebesgue measure $(\mathrm{d}
%\pi_\varepsilon / \mathrm{d} \mathrm{Leb})(x) \propto \exp[-U(x)/\varepsilon]$ when the temperature
%$\varepsilon>0$ converges to $0$. If a limiting distribution $\pi_0$ exists, it
%concentrates on the minimizers of the potential $U$. Classical results require
%the invertibility of the Hessian of $U$ in order to establish such
%asymptotics. In this work, we study the particular case of norm-like potentials
%$U$ and establish quantitative bounds between $\pi_\varepsilon$ and $\pi_0$
%w.r.t. the Wasserstein distance of order $1$ under an invertibility condition of
%a generalized Jacobian. One key element of our proof is the use of geometric
%measure theory tools such as the coarea formula. We apply our results to the
%study of maximum entropy models (microcanonical/macrocanonical distributions)
%and to the convergence of the iterates of the Stochastic Gradient Langevin
%Dynamics (SGLD) algorithm at low temperatures for non-convex minimization.
%\end{talk}
%
%
%\begin{talk}
% {Optimal shallow networks}% [1] talk title
% {Steffen Dereich}% [2] speaker name
% {Westf\"alische Wilhelms-Universit\"at M\"unster}% [3] affiliations
% {steffen.dereich@wwu.de}% [4] email
% {Arnulf Jentzen, Sebastian Kassing}% [5] coauthors
% {Stochastic Computation and Complexity: Quadrature for SDEs and SPDEs,
% Stochastic Optimization, Neural Networks}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{10:30}{11:00}{STC 1012}}% [7] time slot
% {2231}% [8] talk id
% {2230}% [9] session id
%In machine learning, a neural network architecture is associated to a parametrised family of functions, the set of possible responses. In this talk we discuss existence of minimisers in certain optimisation problems (including regression) in the case where the network consists of one hidden layer equipped with ReLU activation and an additional linear neuron.
%We give sufficient conditions for the existence and illustrate the role of the conditions by providing counter examples.
%\end{talk}
%
%
%\begin{talk}
% {Monte Carlo simulation in the mean-field LIBOR market model}% [1] talk title
% {Sascha Desmettre}% [2] speaker name
% {JKU Linz}% [3] affiliations
% {sascha.desmettre@jku.at}% [4] email
% {Simon Hochgerner, Sanela Omerovic, Stefan Thonhauser}% [5] coauthors
% {}% [6] special session
% {\timeslot{Thursday, July 21, 2022}{15:30}{16:00}{Lecture Hall 5}}% [7] time slot
% {4441}% [8] talk id
% {4440}% [9] session id
%We introduce a mean-field extension of the LIBOR market model (LMM) which preserves the basic features of the original model. This mean-field LIBOR market model (MF-LMM) is designed to reduce the probability of exploding scenarios, arising in particular in the market-consistent Monte Carlo valuation of long-term guarantees. To this end, we prove existence and uniqueness of the corresponding MF-LMM and investigate its practical aspects, including a Black's formula. Moreover, we present an extensive numerical analysis of the MF-LMM. The corresponding Monte Carlo method is based on a suitable interacting particle system which approximates the underlying mean-field equation.
%
%\medskip
%References:
%
%[1] S. Desmettre, S. Hochgerner, S. Omerovic, S. Thonhauser (2022), A Mean-Field Extension of the LIBOR Market Model, \textit{International Journal of Theoretical and Applied Finance}, No. 25, Issue No. 01, Article No. 2250005, \url{https://doi.org/10.1142/S0219024922500054}
%\end{talk}
%
%\begin{talk}
% {Quasi-Monte Carlo methods for stochastic Landau-Lifshitz-Gilbert equations}% [1] talk title
% {Josef Dick}% [2] speaker name
% {University of New South Wales}% [3] affiliations
% {josef.dick@unsw.edu.au}% [4] email
% {Xin An, Michael Feischl, Thanh Tran}% [5] coauthors
% {Quasi-Monte Carlo Methods of High Order and Beyond}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{10:30}{11:00}{Lecture Hall 6}}% [7] time slot
% {2151}% [8] talk id
% {2150}% [9] session id
%Quasi-Monte Carlo methods have been successfully used in applications to partial differential equations with random coefficients. In this talk we discuss the stochastic Landau-Lifshitz Gilbert equation which can be converted to a PDE with normally distributed random coefficients. Current QMC results for log-normal random coefficients only achieve an order up to $1/N$, for uniform random coefficients higher order results are available. In this PDE, the normal random coefficients only enter in a bounded form and hence there may be hope to achieve improved rates of convergence.
%\end{talk}
%
%
%\newpage
%
%\begin{talk}
% {Variance reduction techniques for right-tail probabilities of exchangeable lognormal sums}% [1] talk title
% {Kemal Din\c{c}er Dinge\c{c}}% [2] speaker name
% {Gebze Technical University}% [3] affiliations
% {kdingec@gtu.edu.tr}% [4] email
% {Wolfgang H\"ormann}% [5] coauthors
% {Variance Reduction Techniques for Rare Events}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{17:30}{18:00}{Lecture Hall 5}}% [7] time slot
% {2043}% [8] talk id
% {2040}% [9] session id
%The calculation of extremely small tail probabilities for certain random variables has attracted the attention of researchers in the simulation area. The simulation of tail probabilities of the sum of lognormal random variables is particularly important, since the lognormal distribution has been widely used in diverse application areas such as financial engineering and electrical engineering. Moreover, the fact that the distribution of the sum of lognormals is analytically intractable makes it necessary to use a numerical method for the estimation of tail probabilities of lognormal sums. In this talk, we present new simulation algorithms for right-tail probabilities of the sum of exchangeable lognormals.
%
%The well-known conditional Monte Carlo (CMC) method of Asmussen \& Kroese [1] has an asymptotically vanishing relative error for the right-tail probabilities of the sum of independent and identically distributed (i.i.d.) lognormal random variables. The Asmussen--Kroese (AK) estimator was extended to the more general case of non-independent and non-identical sums by Kortschak \& Hashorva [2]. The extended estimator is called the modified Asmussen--Kroese (MAK) estimator. Although the AK and MAK estimators are efficient in the far tails, they do not perform well in the moderate tails for small values of the standard deviation parameter $\sigma$. Also, the MAK estimator is more complicated and slower than the AK estimator, as it requires a numerical root-finding at each replication. In this talk, we present a new and simpler extension of the AK estimator for exchangeable lognormal sums. Our new estimator is in closed-from, and its combination with importance sampling (or an additional CMC) performs better than the MAK estimator for all exchangeable lognormal vectors with any correlation value and for small and large $\sigma$ values.
%
%
%\medskip
%
%
%[1] Asmussen, S., \& Kroese, D. P. (2006). Improved algorithms for rare event simulation with heavy tails. \textit{Advances in Applied Probability}, 38(2), 545--558.
%
%[2] Kortschak, D., \& Hashorva, E. (2013). Efficient simulation of tail probabilities for sums of log-elliptical risks. \textit{Journal of Computational and Applied Mathematics}, 247, 53--67.
%\end{talk}
%
%\begin{talk}
% {Infinite dimensional piecewise deterministic Markov processes}% [1] talk title
% {Paul Dobson}% [2] speaker name
% {University of Edinburgh}% [3] affiliations
% {pdobson@ed.ac.uk}% [4] email
% {Joris Bierkens}% [5] coauthors
% {Recent Advances in Piecewise Deterministic Monte Carlo Methods}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{10:30}{11:00}{Lecture Hall 6}}% [7] time slot
% {2051}% [8] talk id
% {2050}% [9] session id
%In this talk we will discuss Piecewise Deterministic Markov Processes (PDMP) in infinite dimensional spaces. Recently PDMPs have recieved a lot of attention as a continuous time algorithm for sampling problems. In such problems one of the main concerns is how the algorithm performs for very high dimensional target measures. By determining the properties of PDMP in infinite dimensional settings we gain an insight into how these processes behave as the dimension tends to infinity. In this talk I will concentrate on the Boomerang Sampler and discuss well-posedness, convergence to equilibria and finite dimensional approximation of this process.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Weighted least-squares approximation in expected $L^2$ norm}% [1] talk title
% {Matthieu Dolbeault}% [2] speaker name
% {Sorbonne Universit\'e}% [3] affiliations
% {matthieu.dolbeault@sorbonne-universite.fr}% [4] email
% {Albert Cohen}% [5] coauthors
% {Approximation from Random Data}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{11:30}{12:00}{Lecture Hall 3}}% [7] time slot
% {2183}% [8] talk id
% {2180}% [9] session id
%We investigate the problem of approximating a function $u$ in $L^2$ with a linear space of functions of dimension $n$, using only evaluations of $u$ at $m$ chosen points, with $m$ of the order of $n$. A first approach [2], based on weighted least-squares at i.i.d random points, provides a near-best approximation of $u$, but requires $m$ of order $n \log(n)$. To reduce the sample size while preserving the quality of approximation, we need a result on sums of rank-one matrices from [4], which answers to the Kadison-Singer conjecture. The results presented here, expressed in expected $L^2$ norm of the approximation error, can be found in~[1] and will be compared to alternative approaches [3,5,6].
%
%
%\medskip
%
%[1] A. Cohen and M. Dolbeault. Optimal pointwise sampling for $L^2$ approximation. {\em Journal of Complexity}, 68, 101602, 2022.
%
%[2] A. Cohen and G. Migliorati.
% Optimal weighted least squares methods.
% {\em SMAI Journal of Computational Mathematics}, 3, 181--203, 2017.
%
%[3] D. Krieg and M. Ullrich. Function values are enough for $L^2$-approximation: Part II. {\em Journal of Complexity}, 66, 101569, 2021.
%
%[4] A. Marcus, D. Spielman and N. Srivastava.
% Interlacing families II: Mixed characteristic polynomials and the Kadison-Singer problem.
% {\em Annals of Mathematics} pages 327--350, 2015.
%
%[5] N.~Nagel, M.~Sch\"afer, and T.~Ullrich.
% A new upper bound for sampling numbers.
% {\em Foundations of Computational Mathematics}, 1--24, 2021.
%
%[6] V.~N.~Temlyakov.
% On optimal recovery in $L^2$.
% {\em Journal of Complexity}, 65, 101545, 2020.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {The Kick-Kac teleportation algorithm: boost your favorite Markov Chain Monte Carlo using Kac formula}% [1] talk title
% {Alain Durmus}% [2] speaker name
% {ENS Paris-Saclay}% [3] affiliations
% {alain.durmus@ens-paris-saclay.fr}% [4] email
% {Randal Douc, Aurélien Enfory and Jimmy Olsen}% [5] coauthors
% {Developments in Markov Chain Monte Carlo}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{10:30}{11:00}{Lecture Hall 4}}% [7] time slot
% {2251}% [8] talk id
% {2250}% [9] session id
%In this work, we propose to target a given probability measure $\pi$ by combining two Markov kernels with different invariant probability measures. In its basic form, the mechanism consists in picking up the current position and moving it according to a $\pi$-invariant Markov kernel as soon as the proposed move does not fall into a predefined region. If this is the case, then we resort to the last position in this region and move it according to another auxiliary Markov kernel before starting another excursion outside the region with the first kernel. These state dependent interactions allow to combine smoothly different dynamics that can be taylored to each region while the resulting process still targets the probability measure $\pi$ thanks to an argument based on the Kac formula. Under weak conditions, we obtain the Law of Large numbers starting from any point of the state space, as a byproduct of the same property for the different implied kernels. Geometric ergodicity and Central Limit theorem are also established. Generalisations where the indicator function on the region target is replaced by an arbitrary acceptance probability are also given and allow to consider any Metropolis Hastings algorithm as a particular case of this general framework. Numerical examples, including mixture of Gaussian distributions are also provided and discussed.
%\end{talk}
%
%\begin{talk}
% {Randomized operator splitting schemes for abstract evolution equations}% [1] talk title
% {Monika Eisenmann}% [2] speaker name
% {Lund University}% [3] affiliations
% {monika.eisenmann@math.lth.se}% [4] email
% {Tony Stillfjord}% [5] coauthors
% {Stochastic Computation and Complexity: Quadrature for SDEs and SPDEs, Stochastic
% Optimization, Neural Networks}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{11:00}{11:30}{STC 1012}}% [7] time slot
% {2232}% [8] talk id
% {2230}% [9] session id
%Abstract evolution equations are an important building block for modeling processes in
%physics, biology and social sciences. Moreover, optimization problems can be
%reformulated into evolution equations. Their applications such as machine learning,
%benefit from randomized optimization methods like the stochastic gradient descent
%method. Such a stochastic optimizer can be interpreted as a randomized operator splitting
%scheme. While deterministic operator splitting methods are a powerful tool in the
%approximation of evolution equations, a randomized version has not been studied before.
%
%In this talk, we propose a randomized operator splitting scheme in an abstract setting and
%exemplify the theory by considering a randomized domain decomposition scheme.%
%\end{talk}
%
%
%
%\begin{talk}
% {Primitive rational points on expanding horospheres: effective joint equidistribution}% [1] talk title
% {Daniel El-Baz}% [2] speaker name
% {Graz University of Technology}% [3] affiliations
% {el-baz@math.tugraz.at}% [4] email
% {Min Lee, Andreas Str\"ombergsson}% [5] coauthors
% {What Did You Expect? Equidistribution in Number Theory.}% [6] Special session title
% {\timeslot{Wednesday, July 20, 2022}{11:00}{11:30}{Lecture Hall 3}}% [7] time slot
% {2012}% [8] talk id
% {2010}% [9] session id
%Using techniques from analytic number theory, spectral
%theory, geometry of numbers as well as a healthy dose of linear algebra
%and building on a previous work by Bingrong Huang, Min Lee and myself, wefurnish a new proof of a 2016 theorem by Einsiedler, Mozes, Shah and
%Shapira. That theorem concerns the equidistribution of primitive rationalpoints on certain manifolds and our proof has the added benefit of
%yielding a rate of convergence.
%It turns out to have (perhaps surprising)
%applications to the theory of random graphs, which I shall also discuss.
%\end{talk}
%
%
%\begin{talk}
% {Numerical methods for risk functionals}% [1] talk title
% {Lea Enzi}% [2] speaker name
% {Graz University of Technology}% [3] affiliations
% {lea.enzi@tugraz.at}% [4] email
% {Stefan Thonhauser}% [5] coauthors
% {}% [6] special session.
% {\timeslot{Thursday, July 21, 2022}{16:00}{16:30}{Lecture Hall 5}}% [7] time slot
% {4442}% [8] talk id
% {4440}% [9] session id
%In this talk we consider numerical methods for a broad class of risk models and the computation of related risk functionals. The risk models are based on piecewise deterministic Markov processes (PDMPs), which generalize most of the classically available modeling approaches. On one hand, Feynman-Kac type representations of functionals lead to a study of partial integro-differential equations, and on the other hand, the particular Markovian structure allows for a characterization by means of integral equations. Consequently, numerical schemata based on finite-differences or QMC integration can be applied. We present some first analysis on the applicability of the respective methods and consider numerical examples. In addition, we do a comparison with the quantization technique, which is somehow established for PDMPs.
%\end{talk}
%
%
%\begin{talk}
% {A combined use of fibrations and determinantal point processes}% [1] talk title
% {Uju\'e Etayo}% [2] speaker name
% {Universidad de Cantabria}% [3] affiliations
% {etayomu@unican.es}% [4] email
% {Carlos Beltr\'an, Pablo Garc\'ia-Arce.}% [5] coauthors
% {Random Points: Generation, Quality Criteria, and Applications}% [6] Special session title
% {\timeslot{Friday, July 22, 2022}{09:30}{10:00}{Lecture Hall 4}}% [7] time slot
% {2142}% [8] talk id
% {2140}% [9] session id
%During this talk we will explain how to make use of the internal geometric structure of the spheres of odd dimension to fairy distribute points in them.
%
%Getting into the details: we will say that a set of points $\omega_N = \{x_1,\ldots,x_N \} \subset \mathbb{S}^{d}$ is well distributed if its associated discrete logarithmic or Riesz s-energy defined by
%\begin{equation}
%\mathcal{E}_{\log} (\omega_N) = -\sum_{i=1}^{N} \log ||x_i - x_j||,
%\qquad
%\mathcal{E}_{s} (\omega_N) = \sum_{i=1}^{N} \frac{1}{||x_i - x_j||^s}\end{equation}
% is small.
%We will use well distributed points in $\mathbb{S}^{2}$ and $\mathbb{P}\mathbb{C}^{d}$ and the generalized Hopf fibration $\mathbb{S}^{1} \hookrightarrow \mathbb{S}^{2d+1} \rightarrow \mathbb{P}\mathbb{C}^{d}$ to fairy distribute points in $\mathbb{S}^{2d+1}$.
%We use this technique with random point processes (determinantal point processes), see [1], for odd dimensional spheres.
%\begin{enumerate}
%\item[{[1]}]
%Carlos Beltr\'{a}n and Uju\'{e} Etayo.
%\newblock The Projective Ensemble and Distribution of Points in Odd-Dimensional Spheres.
%\newblock {\em Constructive Approximation}, 48(1):163--182, 2018.
%\end{enumerate}
%\end{talk}
%
%\begin{talk}
% {Stochastic filtering for multiscale stochastic reaction networks based on hybrid approximations}% [1] talk title
% {Zhou Fang}% [2] speaker name
% {ETH Z\"{u}rich}% [3] affiliations
% {zhou.fang@bsse.ethz.ch}% [4] email
% {Ankit Gupta, Mustafa Khammash}% [5] coauthors
% {Monte Carlo Methods and Variance Reduction Techniques for Stochastic Reaction Networks}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{11:00}{11:30}{Lecture Hall 5}}% [7] time slot
% {2032}% [8] talk id
% {2030}% [9] session id
%In the past few decades, the development of fluorescent technologies and microscopic techniques has greatly improved scientists' ability to observe real-time single-cell activities.
%In this talk, we consider the filtering problem associate with these advanced technologies, i.e., how to estimate latent dynamic states of an intracellular multiscale stochastic reaction network from time-course measurements of fluorescent reporters.
%A good solution to this problem can further improve scientists' ability to extract information about intracellular systems from time-course experiments.
%
%A straightforward approach to this filtering problem is to use a particle filter where particles are generated by simulation of the full model and weighted according to observations.
%However, the exact simulation of the full dynamic model usually takes an impractical amount of computational time and prevents this type of particle filters from being used for real-time applications, such as transcription regulation networks.
%Inspired by the recent development of hybrid approximations to multiscale chemical reaction networks, we approach the filtering problem in an alternative way.
%We first prove that accurate solutions to the filtering problem can be constructed by solving the filtering problem for a reduced model that represents the dynamics as a hybrid process.
%The model reduction is based on exploiting the time-scale separations in the original network and, therefore, can greatly reduce the computational effort required to simulate the dynamics.
%As a result, we are able to develop efficient particle filters to solve the filtering problem for the original model by applying particle filters to the reduced model.
%We illustrate the accuracy and the computational efficiency of our approach using several numerical examples.
%\end{talk}
%
%
%\begin{talk}
% {Optimal sampling strategies in time-frequency analysis}% [1] talk title
% {Markus Faulhuber}% [2] speaker name
% {University of Vienna}% [3] affiliations
% {markus.faulhuber@univie.ac.at}% [4] email
% {Laurent B\'etermin, Stefan Steinerberger}% [5] coauthors
% {Periodic Point Configurations and Lattice Point Interactions}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{17:30}{18:00}{Lecture Hall 3}}% [7] time slot
% {2073}% [8] talk id
% {2070}% [9] session id
%Time-frequency analysis lies at the intersection of harmonic analysis, functional analysis and complex analysis, but reaches into other areas, such as analytic number theory, as well. We are concerned with optimizing spectral bounds of certain self-adjoint operators on the Hilbert space of square-integrable functions on the line. These arise from Fourier transforms which are localized using a Gaussian function. D.\ Gabor studied these transforms already in his pioneering work on communication theory in 1946 [4]. Similar to Shannon's work on band-limited functions, we may reconstruct a function only from its samples of the localized Fourier transforms. This leads to sampling patterns (which we always assume to be a lattice) in the plane (not on the line as in Shannon's case) as we need to consider translations (time-shifts) and modulations (frequency-shifts) of the function (signal). The optimal sampling pattern turns out to be the hexagonal lattice, which had been an open conjecture for more than 20 years. In collaboration with L.\ B\'etermin and S.\ Steinerberger the author was recently able to solve the problem [1]. It turns out that the sampling problem is (more than) closely related to the problem of universal optimality [2] [3] and sphere packing and covering problems.
%
%\medskip
%
%[1] L.\ B\'{e}termin, M.\ Faulhuber and S.\ Steinerberger. A variational principle for Gaussian lattice sums. arXiv preprint: 2110.06008, (2021)
%
%[2] H.\ Cohn and A.\ Kumar. Universally optimal distribution of points on spheres. \textit{Journal of the American Mathematical Society} 20(1):99--148, (2007)
%
%[3] H.\ Cohn, A.\ Kumar, S.\ D.\ Miller, D.\ Radchenko and M.\ Viazovska. Universal optimality of the $\mathsf{E}_8$ and Leech lattices and interpolation formulas. \textit{Annals of Mathematics} (to appear)
%
%[4] D.\ Gabor. Theory of communication. \textit{Journal of the Institution of Electrical Engineers-Part III: Radio and Communication Engineering} 93(26): 429-441, (1946)
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Spherical cap discrepancy of perturbed lattices under the Lambert projection}% [1] talk title
% {Damir Ferizovi\'{c}}% [2] speaker name
% {KU Leuven}% [3] affiliations
% {damir.ferizovic@kuleuven.be}% [4] email
% {}% [5] coauthors
% {Energy-Minimizing Point Configurations and Measures I}% [6] special session
% {\timeslot{Tuesday, July 19, 2022}{10:30}{11:00}{Lecture Hall 3}}% [7] time slot
% {2061}% [8] talk id
% {2060}% [9] session id
%Given any full rank lattice $\Lambda$ and a natural number $N$, we regard the point set $\Lambda/N\cap(0,1)^2$ under the Lambert map to the unit sphere, and show that its spherical cap discrepancy is at most of order $N$, with leading coefficient given explicitly and depending on $\Lambda$ only. The proof is established using a lemma that bounds the amount of intersections of certain curves with fundamental domains that tile $\mathbb{R}^2$, and even allows for local perturbations of $\Lambda$ without affecting the bound, proving to be stable for numerical applications. A special case yields the smallest constant for the leading term of the cap discrepancy for deterministic algorithms up to date. The talk is based on my recent paper [1].
%
%\medskip
%[1] D. Ferizovi\'{c}: \emph{Spherical cap discrepancy of perturbed lattices under the Lambert projection}, https://arxiv.org/abs/2202.13894 (2022).
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Probabilistic discrepancy bounds for negatively dependent sequences}% [1] talk title
% {Manuel Fiedler}% [2] speaker name
% {Ruhr West University of Applied Sciences}% [3] affiliations
% {manuel.fiedler@hs-ruhrwest.de}% [4] email
% {Michael Gnewuch, Christian Wei\ss{}}% [5] coauthors
% {}% [6] special session
% {\timeslot{Wednesday, July 20, 2022}{14:00}{14:30}{Lecture Hall 3}}% [7] time slot
% {4231}% [8] talk id
% {4230}% [9] session id
%In [1], Aistleitner and Weimar discussed the discrepancy of infinite-dimensional infinite u.i.d. sequences. They proved probabilistic upper bounds for the discrepancy in the form of $c\sqrt{\frac{d}{N}}$, where $d$ is the dimension and $N$ is the sample size.
%This talk aims to take a closer look at how to generalize this result to sequences which are not independent, but negatively dependent instead. In order to do this, a version of the maximal Bernstein inequality for negatively dependent sequences is proven.
%Moreover, bounds for bracketing numbers established by Gnewuch, Pasing and Weiss in [2] are utilized to obtain a better bound for the discrepancy.From our results numerical values for $c$ are calculated and compared with known results for different dimensions and sample sizes.
%Furthermore, the theoretical results are compared to numerical boundaries obtained from Monte Carlo simulation. This is work in progress and will be accompanied by a preprint in the near future.\\
%
%[1] Christoph Aistleitner and Markus Weimar. Probabilistic star discrepancy bounds for double
%infinite random matrices. In: J. Dick, F. Y. Kuo, G. W. Peters, I.H. Sloan (Eds.), Monte Carlo and Quasi-Monte Carlo Methods 2012, volume 65
%of Springer Proceedings in Mathematics and Statistics, pages 271–287. Springer, 2012. \\
%~[2] Michael Gnewuch, Hendrik Pasing and Christian Wei\ss{}. A generalized Faulhaber
%inequality, improved bracketing covers, and applications to discrepancy. Mathematics of Computation, 90:2873–2898, 2021.
%\end{talk}
%
%
%
%\begin{talk}
% {Lugsail lag windows for estimating time-average covariance matrices}% [1] talk title
% {James M.~Flegal}% [2] speaker name
% {University of California, Riverside}% [3] affiliations
% {jflegal@ucr.edu}% [4] email
% {Dootika Vats}% [5] coauthors
% {Developments in Markov Chain Monte Carlo}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{11:00}{11:30}{Lecture Hall 4}}% [7] time slot
% {2252}% [8] talk id
% {2250}% [9] session id
%Lag windows are commonly used in time series, econometrics, steady-state simulation, and Markov chain Monte Carlo to estimate time-average covariance matrices. In the presence of positive correlation of the underlying process, estimators of this matrix almost always exhibit significant negative bias, leading to undesirable finite-sample properties. We propose a new family of lag windows specifically designed to improve finite-sample performance by offsetting this negative bias. Any existing lag window can be adapted into a lugsail equivalent with no additional assumptions. We use these lag windows within spectral variance estimators and demonstrate its advantages in a linear regression model with autocorrelated and heteroskedastic residuals. We further employ the lugsail lag windows in weighted batch means estimators due to their computational efficiency on large simulation output. We obtain bias and variance results for these multivariate estimators and significantly weaken the mixing condition on the process. Superior finite-sample properties are illustrated in a vector autoregressive process and a Bayesian logistic regression model.
%\end{talk}
%
%
%\begin{talk}
% {Approximation of L\'evy-driven SDEs}% [1] talk title
% {M\'at\'e Gerencs\'er}% [2] speaker name
% {TU Wien}% [3] affiliations
% {mate.gerencser@tuwien.ac.at}% [4] email
% {Oleg Butkovsky, Konstantinos Dareiotis}% [5] coauthors
% {Stochastic Computation and Complexity: Approximation of SDEs with Non-Standard Coefficients}% [6] Special session title
% {\timeslot{Wednesday, July 20, 2022}{11:00}{11:30}{STC 1012}}% [7] time slot
% {2292}% [8] talk id
% {2290}% [9] session id
%We study the strong convergence rate of the Euler scheme for SDEs driven by an additive L\'evy process with exponent $\alpha\in(0,2]$. If the coefficient is regular (say, Lipschitz), then elementary arguments show $L_p$ convergence for any $p$, but with rate limited by $1/p$. Somewhat surprisingly, this defect can be overcome by techniques developed for \emph{irregular} coefficients. With these methods we are able go well beyond the Lipschitz case and cover the optimal range of H\"older continuous coefficients for all $\alpha\in[2/3,2]$. The rate of convergence is somewhat convoluted, but is always at least $1/2$ for all moments, L\'evy exponents, and admissible H\"older regularity of coefficients.
%\end{talk}
%
%
%\newpage
%
%\begin{talk}
% {Theory and construction of lattice rules after preintegration for pricing Asian options}% [1] talk title
% {Alexander D.~Gilbert}% [2] speaker name
% {University of New South Wales}% [3] affiliations
% {alexander.gilbert@unsw.edu.au}% [4] email
% {Frances Y.~Kuo, Ian H.~Sloan}% [5] coauthors
% {Smoothing and Adaptive Methods}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{16:30}{17:00}{STC 1012}}% [7] time slot
% {2131}% [8] talk id
% {2130}% [9] session id
%Since the 1990's it has been known that quasi-Monte Carlo (QMC) methods are extremely
%effective at computing the integrals required for pricing Asian options,
%despite the fact that the kink in the payoff function means that such problems
%are not smooth enough for the QMC theory to apply.
%A popular remedy is to first smooth the payoff by preintegration, which is a specific case
%of the more general method of conditional sampling. Here one first integrates the
%non-smooth payoff with respect a specially chosen variable (or equivalently conditions on partial information),
%with the result being a smooth function, but now in one dimension less.
%In this talk we look at pricing an Asian option in $d$ dimensions by performing preintegration
%and then applying a randomly shifted lattice rule on $\mathbb{R}^{d-1}$ to the result,
%using the weighted space setting of Nichols \& Kuo.
%The benefit of this approach is that it allows to choose the optimal weights
%for a specific Asian option problem, which in turn allows tailored randomly shifted
%lattice rules to be constructed using the component-by-component algorithm.
%We give rigorous error bounds with first-order convergence and which are explicit in the
%dependence on dimension.
%Along the way we will take a detour to highlight two interesting features of the preintegration theory.
%First, an equivalence between the Sobolev spaces used to analyse
%preintegration and the weighted spaces used to analyse randomly shifted lattice rules on $\mathbb{R}^d$.
%Second, the necessity of the condition that the underlying function be strictly monotone
%with respect to the preintegration variable.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Progress on MATLAB and C/C++ implementations of an MLMC package}% [1] talk title
% {Mike Giles}% [2] speaker name
% {University of Oxford}% [3] affiliations
% {mike.giles@maths.ox.ac.uk}% [4] email
% {}% [5] coauthors
% {Developments in and Applications of MCQMC Software}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{10:30}{11:00}{Lecture Hall 5}}% [7] time slot
% {2171}% [8] talk id
% {2170}% [9] session id
%In this talk I will outline progress in the development of MATLAB
%and C/C++ versions of MLMC software packages [1] implementing the algorithms
%and example applications described elsewhere (see [2] for example).
%
% Due to the pandemic, progress has not been as rapid as I had hoped but
% I will discuss
% \vspace{-0.15in}
% \begin{itemize}\setlength{\itemsep}{0in}
% \item the range of new example applications, including an example
% involving the rapid generation of Poisson random variables
% \item a highly efficient multithreaded OpenMP C++ implementation using
% Intel's MKL/VSL vectorised random number generators
% \end{itemize}
% \vspace{-0.15in}
%as well as plans for
% \vspace{-0.15in}
% \begin{itemize}\setlength{\itemsep}{0in}
% \item an asynchronous GPU implementation
% \item extensions to MIMC and nested MLMC
% \end{itemize}
% \vspace{-0.15in}
% with the hope of stimulating interest from others in joint development, either of the main package(s) or example applications, during the next year
% while I am on sabbatical.
%
%\medskip
%
%[1] M.B. Giles. 'Multilevel Monte Carlo methods'. {\it Acta Numerica},
% 24:259-328, 2015.
%
%[2] https://people.maths.ox.ac.uk/gilesm/mlmc/
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Optimal spherical measures approximating the uniform distribution}% [1] talk title
% {Alexey Glazyrin}% [2] speaker name
% {University of Texas Rio Grande Valley}% [3] affiliations
% {alexey.glazyrin@utrgv.edu}% [4] email
% {Dmitriy Bilyk, Damir Ferizovi\'{c}, Ryan W.~Matzke, Josiah Park, Oleksandr Vlasiuk}% [5] coauthors
% {Energy-Minimizing Point Configurations and Measures I}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{11:00}{11:30}{Lecture Hall 3}}% [7] time slot
% {2062}% [8] talk id
% {2060}% [9] session id
%Let $\mathcal{B}_t$ be the set of Borel probability measures over a unit sphere $\mathbb{S}^{d-1}$ such that for each $\mu\in\mathcal{B}_t$,
%
%$$\int_{\mathbb{S}^{d-1}} f(x)\, d\mu(x) = \int_{\mathbb{S}^{d-1}} f(x)\, d\sigma(x),$$
%
%for every polynomial $f$ of degree $\leq t$, where $\sigma$ is the uniform probability distribution over $\mathbb{S}^{d-1}$. In other words, measure $\mu$ approximates $\sigma$ for all polynomials of degree $t$. Measures in $\mathcal{B}_t$ with finite support correspond to quadrature formulas of degree $t$. If such measures are uniform distributions over their support, they correspond to spherical $t$-designs.
%
%The natural problem is, given $t$ and $d$, to find the "smallest" measure in $\mathcal{B}_t$. If measures are compared by the cardinality of their support, this problem becomes the classical problem of finding minimal quadrature formulas and minimal spherical designs. In this work, we study optimal measures in $\mathcal{B}_t$ with respect to other potentials. In particular, we are interested in approximating measures $\mu$ with the minimal possible diameter of their support.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Hermite spaces: properties, $L^2$-approximation, and integration}% [1] talk title
% {Michael Gnewuch}% [2] speaker name
% {University of Osnabr\"uck}% [3] affiliations
% {michael.gnewuch@uni-osnabrueck.de}% [4] email
% {Mario Hefter, Aicke Hinrichs, Klaus Ritter, Robin R\"u{\ss}mann}% [5] coauthors
% {}% [6] special session
% {\timeslot{Thursday, July 21, 2022}{15:30}{16:00}{Lecture Hall 3}}% [7] time slot
% {4241}% [8] talk id
% {4240}% [9] session id
%We consider spaces of functions of infinetely many variables that are defined with the help of the orthonormal basis of univariate Hermite polynomials of $L^2(\mathbb{R}, \mu_0)$, where $\mu_0$ is the standard normal distribution on $\mathbb{R}$. Those spaces belong to the class of reproducing kernel Hilbert spaces of increasing smoothness and their elements are defined on proper subsets of the sequence space $\mathbb{R}^{\mathbb{N}}$. Their norms are induced by an underlying function space decomposition, namely the infinite-dimensional ANOVA decomposition. We discuss further properties of those spaces and present results on $L^2$-approximation and integration.\\
%Part of the talk is based on the paper
%
%\medskip
%
%\begin{itemize}
%\item[{[}1{]}] M.~Gnewuch, M.~Hefter, A.~Hinrichs, K.~Ritter, {\sl Countable tensor products of Hermite spaces and spaces of Gaussian kernels}, Preprint, arXiv:2110.05778v2, to appear in Journal of Complexity.
%\end{itemize}.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Construction-free median lattice rules}% [1] talk title
% {Takashi Goda}% [2] speaker name
% {The University of Tokyo}% [3] affiliations
% {goda@frcer.t.u-tokyo.ac.jp}% [4] email
% {Pierre L'Ecuyer}% [5] coauthors
% {Quasi-Monte Carlo Methods of High order and Beyond}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{11:00}{11:30}{Lecture Hall 6}}% [7] time slot
% {2152}% [8] talk id
% {2150}% [9] session id
%In this talk, we consider approximating the integral of periodic functions in weighted Korobov spaces by rank-1 lattice rules. It has been well-known that good rank-1 lattice rules achieve almost the optimal rate of convergence, which is of $O(N^{-\alpha+\varepsilon})$ for arbitrarily small $\varepsilon>0$ with $\alpha>1/2$ being a smoothness parameter, and that such rules can be often constructed efficiently by a fast component-by-component (CBC) algorithm. However, the standard fast CBC algorithm requires appropriate $\alpha$ and appropriate (special forms of) weights of Korobov space as inputs, which are generally very difficult to find for a given application. We tackle with this problem by introducing \emph{construction-free median rank-1 lattice rules}. Our approach is inspired by [1] and works as follows:
%\begin{enumerate}
%\item draw a sample of $r$ independent generating vectors of rank-1 lattice rules,
%\item compute the integral estimate for each, and
%\item approximate the integral by the median of these $r$ estimates.
%\end{enumerate}
%Here taking the median plays a role in filtering bad generating vectors out adaptively without any knowledge on $\alpha$ and weights. We can prove that our median lattice rules achieve almost the optimal order of the worst-case error with a probability that converges to 1 exponentially fast as $r$ increases. Numerical experiments illustrate and support our theoretical findings.
%
%\medskip
%
%[1] Z. Pan and A. B. Owen. Super-polynomial accuracy of one dimensional randomized nets using the median-of-means, November 2021. arXiv:2111.12676.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Generating pseudorandom number sequences with Gaussian distribution} % [1] talk title
% {Domingo G\'{o}mez-P\'{e}rez}% [2] speaker name
% {Universidad de Cantabria}% [3] affiliations
% {domingo.gomez@unican.es}% [4] email
% {}% [5] coauthors
% {Pseudo-Random Number Generation.}% [6] special session
% {\timeslot{Friday, July 22, 2022}{09:30}{10:00}{Lecture Hall 5}}% [7] time slot
% {2222}% [8] talk id
% {2220}% [9] session id
%Generating random noise is necessary for calibrating instruments. The properties of
%the noise source are critical for the performance of the instrument and the physical noise sources which
%are all custom made for a given frequency are usually expensive, unreliable, have short lifetimes
%and require stabilization. A reliable noise source which can be produced by a hardware accelerator
%like a FPGA (Field Programmable Gate Array) is a preferable solution in most cases, therefore
%random sequences coming from a random number generator are an obvious choice to use. Unfortunately,
%most researchers have focused in generation of uniform pseudorandom sequences, while Gaussian random number generators have received less attention than deserved [2].
%In this talk, we investigate modifications of classical pseudorandom number generators for generating pseudorandom number sequences with Gaussian distribution and their application for calibrating instruments in a satellite [1].
%
%
%\medskip
%
%[1] Buch, K. D., Gupta, Y., Ajith Kumar, B. (2014). Variable Correlation Digital Noise Source on FPGA - A Versatile Tool for Debugging Radio Telescope Backends. {\it Journal of Astronomical Instrumentation, 3} (3–4). https://doi.org/10.1142/S225117171450007X
%
%
%[2] Malik, J. S., Hemani, A. (2016). Gaussian random number generation: A survey on hardware architectures. {\it ACM Computing Surveys, 49}. https://doi.org/10.1145/2980052
%\end{talk}
%
%%\newpage
%
%\begin{talk}
% {PDMP samplers for constrained spaces and discontinuous targets}% [1] talk title
% {Sebastiano Grazzi}% [2] speaker name
% {Delft University of Technology}% [3] affiliations
% {s.grazzi@tudelft.nl}% [4] email
% {Joris Bierkens, Frank van der Meulen, Moritz Schauer}% [5] coauthors
% {Recent Advances in Piecewise Deterministic Monte Carlo Methods}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{11:00}{11:30}{Lecture Hall 6}}% [7] time slot
% {2052}% [8] talk id
% {2050}% [9] session id
%During this talk, I will formally introduce piecewise deterministic Markov processes (PDMPs) endowed with
%`sticky floors', `soft walls' and `hard walls' which can be used for Monte Carlo simulation and allow to target efficiently a rich class of measures arising in Bayesian inference. I will motivate and illustrate the framework with several statistical applications. The class of processes presented here extends the sticky PDMP samplers introduced in [1]. \medskip
%
%[1] J. Bierkens, S. Grazzi, F. van der Meulen, and M. Schauer. “Sticky PDMP
%samplers for sparse and local inference problems”. In: \emph{arXiv preprint arXiv:2103.08478}
%(2021).
%\end{talk}
%
%
%\begin{talk}
% {A Quasi-Monte Carlo method for estimation of eigenvalues using error balancing}% [1] talk title
% {Silvi-Maria Gurova}% [2] speaker name
% {Bulgarian Academy of Sciences}% [3] affiliations
% {smgurova@parallel.bas.bg}% [4] email
% {E. Atanassov, T. Gurov, A. Karaivanova}% [5] coauthors
% {}% [6] special session
% {\timeslot{Monday, July 18, 2022}{10:30}{11:00}{Lecture Hall 6}}% [7] time slot
% {4511}% [8] talk id
% {4510}% [9] session id
%Iterative Monte Carlo methods are successfully applied for estimation of the extreme eigenvalues of large sparse matrices. Recent developments in quasi-random sequences motivated us to revisit quasi-Monte Carlo approach to eigenvalue estimation. We propose a new algorithm which combines Monte Carlo power iterations with resolvent matrix, balancing of systematic and stochastic error and new variants of randomized low discrepancy sequences. Numerical tests are presented.
%\end{talk}
%
%
%\begin{talk}
% {Quasi-Monte Carlo methods for optimal control problems subject to parabolic PDE constraints under uncertainty}% [1] talk title
% {Philipp Guth}% [2] speaker name
% {University of Mannheim}% [3] affiliations
% {pguth@uni-mannheim.de}% [4] email
% {Vesa Kaarnioja, Claudia Schillings, Frances Y.~Kuo, Ian H.~Sloan}% [5] coauthors without affiliations
% {}% [6] special session
% {\timeslot{Monday, July 18, 2022}{16:30}{17:00}{Lecture Hall 6}}% [7] time slot
% {4531}% [8] talk id
% {4530}% [9] session id
%We study the application of a tailored quasi-Monte Carlo (QMC) method to a class of optimal control problems subject to parabolic partial differential equation (PDE) constraints under uncertainty: the state in our setting is the solution of a parabolic PDE with a random thermal diffusion coefficient, steered by a control function. To account for the presence of uncertainty in the optimal control problem, the objective function is composed with a risk measure. We focus on two risk measures, both involving high-dimensional integrals with respect to the stochastic variables: the expected value and the (nonlinear) entropic risk measure. The high-dimensional integrals are computed numerically using specially designed QMC methods, and under moderate assumptions on the input random field, the error rate is shown to be essentially linear independently of the stochastic dimension of the problem -- and thereby superior to ordinary Monte Carlo methods. Numerical results are presented to assess the effectiveness of our method.
%\end{talk}
%
%
%\begin{talk}
% {Recursive estimation of a failure probability for a Lipschitz function}% [1] talk title
% {Arnaud Guyader}% [2] speaker name
% {Sorbonne Universit\'e}% [3] affiliations
% {arnaud.guyader@upmc.fr}% [4] email
% {Lucie Bernard, Albert Cohen, Florent Malrieu}% [5] coauthors
% {Approximate Models for Rare Event Simulation and Uncertainty Quantification}% [6] special session
% {\timeslot{Wednesday, July 20, 2022}{10:30}{11:00}{Lecture Hall 5}}% [7] time slot
% {2081}% [8] talk id
% {2080}% [9] session id
%Let $g:\Omega=[0,1]^d\to\mathbb{R}$ denote a Lipschitz function that can be evaluated at each point, but at the price of a heavy computational time. Let $X$ stand for a random variable with values in $\Omega$ such that one is able to simulate, at least approximately, according to the restriction of the law of $X$ to any subset of $\Omega$. For example, thanks to Markov chain Monte Carlo techniques, this is always possible when $X$ admits a density that is known up to a normalizing constant. In this context, given a deterministic threshold $T$ such that the failure probability $p:=\mathbb{P}(g(X)>T)$ may be very low, our goal is to estimate the latter with a minimal number of calls to $g$. In this aim, building on [1], we propose a recursive and (in a certain sens) optimal algorithm that selects on the fly areas of interest and estimates their respective probabilities.
%
%\medskip
%
%[1] A. Cohen, R. Devore, G. Petrova, and P. Wojtaszczyk. Finding the minimum of a function. Methods Appl. Anal., 20(4):365-381, 2013.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Multilevel path branching for digital options}% [1] talk title
% {Abdul-Lateef Haji-Ali}% [2] speaker name
% {Heriot-Watt University}% [3] affiliations
% {a.hajiali@hw.ac.uk}% [4] email
% {Mike Giles}% [5] coauthors
% {Smoothing and Adaptive Methods}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{17:00}{17:30}{STC 1012}}% [7] time slot
% {2132}% [8] talk id
% {2130}% [9] session id
%We propose a novel Monte Carlo-based estimator for digital options with
%assets modelled by a stochastic differential equation (SDE) that are solved
%approximately using a time-stepping scheme like Euler-Maruyama or Milstein.
%The new estimator is based on repeated, hierarchical path splitting [1].
%Using the fact that paths of an SDE solution sharing parts of a Brownian
%path are conditionally independent, we show that the new estimator has animproved strong convergence rate as the size of the time-step decreases. We
%also show that the computational complexity of Multilevel Monte Carlo (MLMC)
% using the new estimator is similar to the complexity of a classical MLMC
% estimator when applied to smoother options. In particular, when using the
% Euler-Maruyama scheme, we show that the computational complexity to
% approximate the value of a digital option with root-mean-square error,
% \(\varepsilon\), is \(\mathcal O(\varepsilon^{-2-\nu})\) for any \(\nu>0\). This is an improvement
% over the computational complexity of a classical Monte Carlo estimator, \(\mathcal O(\varepsilon^{-3})\), and a classical MLMC estimator, \(\mathcal
% O(\varepsilon^{-5/2})\), when approximating the value of a digital option. Using the
% Milstein scheme or combining with an antithetic estimator [2] reduces the
% computational complexity further to the canonical complexity \(\mathcal O(\varepsilon^{-2})\).
%
% \medskip
%
% [1] S{\o}ren Asmussen and Peter~W. Glynn. {\em Stochastic Simulation:
% {Algorithms} and Analysis}, volume~57. Springer New York, 2007.\\{}%
% [2] Michael~B. Giles and Lukasz Szpruch. {Antithetic multilevel {Monte} {Carlo} estimation for multi-dimensional {SDEs} without L\'evy area
% simulation}. {\em The Annals of Applied Probability}, 24(4):1585--1620,
% August 2014.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Multilevel algorithms for $L^2$-approximation}% [1] talk title
% {Kumar Harsha}% [2] speaker name
% {University of Osnabr\"uck}% [3] affiliations
% {kumar.harsha@uni-osnabrueck.de}% [4] email
% {Michael Gnewuch, Marcin Wnuk}% [5] coauthors
% {}% [6] special session
% {\timeslot{Wednesday, July 20, 2022}{11:00}{11:30}{Lecture Hall 6}}% [7] time slot
% {4552}% [8] talk id
% {4550}% [9] session id
%We consider $L^2$-approximation on reproducing kernel Hilbert spaces of functions depending on infinitely many variables. This problem has been studied in [1],[2] and [3], where the upper error bounds have been achieved by using multivariate decomposition methods (fka changing dimension algorithms). We analyze the problem for a different cost model which turns out to be favourable for multilevel algorithms.
% The focus of the talk will be on unrestricted linear information, where we admit the evaluations of arbitrary linear functionals. Interestingly, the analysis reveals that there is a performance gap between ANOVA and non-ANOVA spaces .
%
%\medskip
%
%References:
%
%[1] Wasilkowski, Grzegorz W., and H. Woźniakowski. "Liberating the dimension for function approximation." \textit{Journal of Complexity} 27 (2011): 86-110.
%
%[2] Wasilkowski, Grzegorz W., and H. Woźniakowski. "Liberating the dimension for function approximation: standard information." \textit{Journal of Complexity} 27 (2011): 417-440.
%
%[3] Wasilkowski, Grzegorz W. "Liberating the dimension for $L_2$-approximation." \textit{Journal of Complexity} 28 (2012): 304-319.
%\end{talk}
%
%
%\begin{talk}
% {Geodesic slice sampling on the sphere}% [1] talk title
% {Mareike Hasenpflug}% [2] speaker name
% {University of Passau}% [3] affiliations
% {mareike.hasenpflug@uni-passau.de}% [4] email
% {Michael Habeck, Shantanu Kodgirwar, Daniel Rudolf}% [5] coauthors
% {Recent Advances in MCMC Sampling Techniques}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{16:30}{17:00}{Lecture Hall 4}}% [7] time slot
% {2211}% [8] talk id
% {2210}% [9] session id
%We introduce a geodesic slice sampler on the Euclidean sphere (in arbitrary but fixed dimension)
%that can be used for approximate sampling from distributions that have a density with respect to the corresponding surface measure.
%Such distributions occur e.g. in the modelling of directional data or shapes.
%Under some mild conditions we show that the corresponding transition kernel is well-defined, in particular,
%that it is reversible with respect to the distribution of interest.
%Moreover, if the density is bounded away from zero and infinity, then we obtain a uniform ergodicity convergence result.
%Finally, we illustrate the performance of the geodesic slice sampler on the sphere with numerical experiments.
%\end{talk}
%
%%\newpage
%
%\begin{talk}
% {Analysis of a localized non-linear ensemble Kalman--Bucy filter with sparse observations}% [1] talk title
% {Gottfried Hastermann}% [2] speaker name
% {University of Potsdam}% [3] affiliations
% {gottfried.hastermann@uni-potsdam.de}% [4] email
% {Jana de Wiljes}% [5] coauthors
% {Advanced Particle Methods for Bayesian Inference}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{10:30}{11:00}{Lecture Hall 4}}% [7] time slot
% {2091}% [8] talk id
% {2090}% [9] session id
%With large scale availability of precise real time data, their incorporation
%into physically based predictive models, became increasingly important. This
%procedure of combining the prediction and observation is called data
%assimilation. One especially popular algorithm of the class of Bayesian
%sequential data assimilation methods is the ensemble Kalman filter which
%successfully extends the ideas of the Kalman filter to the non-linear
%situation. However, in case of spatio-temporal models one regularly relies on
%some version of localization, to avoid spurious oscillations.
%
% In this work we develop a-priori error estimates for a time continuous variant of the ensemble Kalman filter, known
% as localized ensemble Kalman--Bucy filter. More specifically we aim for the
% scenario of sparse observations applied to models from fluid dynamics.
%\end{talk}
%
%%\newpage
%
%\begin{talk}
% {On the metric theory of approximations by reduced fractions: Quantifying the Duffin-Schaeffer conjecture}% [1] talk title
% {Manuel Hauke}% [2] speaker name
% {Graz University of Technology}% [3] affiliations
% {hauke@math.tugraz.at}% [4] email
% {}% [5] coauthors
% {What Did You Expect? Equidistribution in Number Theory}% [6] Special session title
% {\timeslot{Wednesday, July 20, 2022}{11:30}{12:00}{Lecture Hall 3}}% [7] time slot
% {2013}% [8] talk id
% {2010}% [9] session id
%Let $\psi: \mathbb{N} \to [0,1/2]$ be given. Koukoulopoulos and Maynard (2020) proved the Duffin--Schaeffer conjecture: for almost all reals $\alpha$ there are infinitely many coprime solutions $(p,q)$ to the inequality $|\alpha - p/q| < \psi(q)/q$, if and only if the series $\sum_{q=1}^\infty \varphi(q) \psi(q) / q$ is divergent. In a recent joint work with Christoph Aistleitner and Bence Borda, we established a quantitative version of this result in the following sense: for almost all $\alpha$, the number of coprime solutions $(p,q)$, subject to $q \leq Q$, is of asymptotic order $\Psi(Q) = \sum_{q=1}^Q 2\varphi(q) \psi(q) / q$.
%
%In this talk, I will give an overview of the original proof of Koukoulopoulos and Maynard and the additional ideas we used to obtain
%this quantification.\\
%\end{talk}
%
%
%\begin{talk}
% {A stochastic discretization method and some applications in IBC}% [1] talk title
% {Stefan Heinrich}% [2] speaker name
% {TU Kaiserslautern}% [3] affiliations
% {heinrich@informatik.uni-kl.de}% [4] email
% {}% [5] coauthors
% {Stochastic Computation and Complexity: High Dimensional Approximation, Integration, and PDEs}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{18:00}{18:30}{STC 1012}}% [7] time slot
% {2168}% [8] talk id
% {2160}% [9] session id
%We study the complexity of problems defined on Sobolev spaces which do not satisfy the embedding condition (that is, the space is not embedded into the space of continuous functions on the corresponding domain).
%We consider standard information, that is, function values.
%Using a stochastic discretization technique, we derive new results on the complexity of integration, approximation and parametric integration in the restricted randomized setting (only random bits can be used) and in the quantum setting. For these problems the case of spaces not satisfying the embedding condition has not been considered previously in either settings. Our results also allow new comparisons between the randomized and quantum setting.
%\end{talk}
%
%
%\begin{talk}
% {Challenges in developing great MCQMC software}% [1] talk title
% {Fred J.~Hickernell}% [2] speaker name
% {Illinois Institute of Technology}% [3] affiliations
% {hickernell@iit.edu}% [4] email
% {}% [5] coauthors
% {Developments in and Applications of MCQMC Software}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{11:30}{12:00}{Lecture Hall 5}}% [7] time slot
% {2173}% [8] talk id
% {2170}% [9] session id
%The process of translating new Monte Carlo and Quasi-Monte Carlo (MCQMC) algorithms into software libraries faces several challenges. Great software should be easy to use with reasonable default options for the novice and advanced features for the developer or experienced user. The library architecture must allow for growth. Ensuring connectivity with other software libraries will facilitate a larger user base of the MCQMC library. Coding algorithms the right way may significantly improve their runtime or portability. Since development team members will come and go, the shared wisdom of the development team must be documented and transmitted to succeeding generations. Software developers must keep abreast of the newest computing environments to ensure peak performance. This talk will highlight some of these challenges and ways to address them.
%\end{talk}
%
%\begin{talk}
% {An efficient estimator of nested expectations without conditional sampling}% [1] talk title
% {Tomohiko Hironaka}% [2] speaker name
% {The University of Tokyo}% [3] affiliations
% {hironaka-tomohiko@g.ecc.u-tokyo.ac.jp}% [4] email
% {Takashi Goda}% [5] coauthors
% {}% [6] special session
% {\timeslot{Thursday, July 21, 2022}{16:00}{16:30}{Lecture Hall 6}}% [7] time slot
% {4572}% [8] talk id
% {4570}% [9] session id
%Estimating nested expectations is an important task
%in computational mathematics and statistics.
%In our study we propose a new Monte Carlo method
%to estimate nested expectations efficiently
%without taking samples of the inner random variable
%from the conditional distribution given the outer random variable.
%This property provides the advantage over many existing methods
%that it enables us to estimate nested expectations
%only with a dataset on the pair of the inner and outer variables
%drawn from the joint distribution.
%We show an upper bound on the mean squared error
%of the proposed method under some assumptions.
%Numerical experiments are conducted to compare our proposed method
%with several existing methods
%and we see that our proposed method is superior to the compared methods
%in terms of efficiency and applicability.
%\end{talk}
%
%\begin{talk}
% {Consistency of randomized integration points}% [1] talk title
% {Julian Hofstadler}% [2] speaker name
% {University of Passau}% [3] affiliations
% {julian.hofstadler@uni-passau.de}% [4] email
% {Daniel Rudolf}% [5] coauthors
% {Random Points: Generation, Quality Criteria, and Applications}% [6] Special session title
% {\timeslot{Friday, July 22, 2022}{10:00}{10:30}{Lecture Hall 4}}% [7] time slot
% {2143}% [8] talk id
% {2140}% [9] session id
%For integrable functions we present a weak law of large numbers for structured Monte Carlo methods, such as estimators based on randomized digital nets, Latin hypercube sampling, randomized Frolov point sets as well as Cranley-Patterson rotations. Moreover, median modified methods are discussed and we show that for integrands in $L^p$ with $p>1$ a strong law of large numbers holds.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Wavelet frames with grid-like time-frequency sampling and quasi-random delays}% [1] talk title
% {Nicki Holighaus}% [2] speaker name
% {Austrian Academy of Sciences}% [3] affiliations
% {nicki.holighaus@oeaw.ac.at}% [4] email
% {G\"{u}nther Koliander, Clara Hollomey, Friedrich Pillichshammer}% [5] coauthors
% {}% [6] special session
% {\timeslot{Monday, July 18, 2022}{16:30}{17:00}{Lecture Hall 4}}% [7] time slot
% {4313}% [8] talk id
% {4310}% [9] session id
%A wavelet frame consists of countably many dilated and translated copies $\psi_{a,x} = \mathbf{D}_a \mathbf{T_x} \psi$ of a \emph{mother wavelet} $\psi$.
%A \emph{frame} is characterized by the distinctive property that any square-integrable function can be represented as a linear combination of its elements with coefficients of equivalent norm.
%
%The study of collections $(\psi_{a_j,x_j})_{j\in J}$ which form a frame popularized frame theory in the 1980s and has remained a topic of notable interest ever since, for wavelet transforms and various constructive or abstract generalizations thereof.
%We revisit the original problem of finding wavelet frames for functions on the real line,
%and propose a new selection scheme, considering sequences $(\psi_{ak^{-1},bl+\delta_k})_{k\in\mathbb{N},l\in\mathbb{Z}}$, where $a,b>0$, and, crucially, $\delta_k\in [0,b)$ is a quasi-random sequence. We demonstrate that, up to technicalities at very large scales, this selection scheme yields wavelet frames, provided that $a,b$ are sufficiently small. When a digital sequence, such as the \emph{van der Corput sequence}, is chosen for $\{\delta_k\}_{k\in\mathbb{N}}$, our proof is particularly simple. In contrast, choosing all $\delta_k$ from a fixed finite subset of $[0,b)$ will never yield a frame, independent of $a,b$.
%
%Interpreting the mother wavelet as a band-pass filter, and recalling the commutation relations of dilation operators and the Fourier transform $\mathcal{F}\mathbf{D}_a =\mathbf{D}_{1/a} \mathcal{F}$,
%the proposed selection scheme corresponds to a regular time-frequency grid, up to the introduction of the quasi-random \emph{delays} $\delta_k$.
%In particular, if the delays $\delta_k$ are chosen according to a Kronecker sequence, then the resulting point set
%is a lattice. While wavelet frames with scale-dependent translation spacing must be considered in the abstract framework of generalized shift-invariant systems, our construction can draw on the rich theory of (standard) shift-invariant systems. In particular, the theoretical analysis of shift-invariant frames and the related operators is significantly easier and their implementation can rely on highly efficient algorithms.
%
%I will present the current state of our work-in-progress investigation of shift-invariant wavelet systems with quasi-random delays on the real line, in both theoretical results and numerical studies.
%Finally, some indication that the proposed construction extends to an (almost) universal sampling scheme for general time-frequency systems of arbitrary dimensionality will be presented.
%\end{talk}
%
%
%\begin{talk}
% {Improved Bernoulli mean estimation for Monte Carlo data}% [1] talk title
% {Mark Huber}% [2] speaker name
% {Claremont McKenna College}% [3] affiliations
% {mhuber@cmc.edu}% [4] email
% {Siki Wang}% [5] coauthors
% {}% [6] special session
% {\timeslot{Monday, July 18, 2022}{11:00}{11:30}{Lecture Hall 6}}% [7] time slot
% {4512}% [8] talk id
% {4510}% [9] session id
%Consider the problem of estimating the mean \( p \) of a 0-1 (Bernoulli) random variable.
%The Gamma Bernoulli Approximation Scheme (GBAS) is an estimate with a user specified
%relative error distribution, that is, the distribution of the relative error is independent
%of \( p \). This allows for very precise targeting of the run time to achieve any desired relative loss. GBAS
%operates by smoothing geometric random variables of mean \( 1 / p \) into exponential random variables of mean \( 1 / p \).
%While the benefits of using scalable exponentials versus geometric random variables are clear, this does result in the
%elimination of a factor of \( 1 - p \) in the variance. This can become significant for problems where \( p \) is large.
%This work considers several different methods for addressing this problem. First, modifications to GBAS are considered,
%including the use of multiple intervals created by using antithetic and uniform shifted lattice points for turning the geometric into exponential random variables.
%Second, improvements to tail bounds of negative binomial random variables are considered. The result is that a significant portion of the \( 1 - p \) factor can
%be retrieved while maintaining exact confidence intervals.
%\end{talk}
%
%
%\begin{talk}
% {On unbiased score estimation for partially observed diffusions}% [1] talk title
% {Miguel \'{A} Alvarez B.}% [2] speaker name
% {King Abdullah University of Science and Technology}% [3] affiliations
% {miguelangel.alvarezballesteros@kaust.edu.sa}% [4] email
% {Ajay Jasra, Jeremy Heng, Jeremie Houssineau}% [5] coauthors
% {Recent Advances in Unbiased Estimation Techniques}% [6] Special session title
% {\timeslot{Wednesday, July 20, 2022}{10:30}{11:00}{Lecture Hall 4}}% [7] time slot
% {2121}% [8] talk id
% {2120}% [9] session id
%We consider the problem of statistical inference for a class of partially observed diffusion processes, with discretely-observed data and finite-dimensional parameters. We construct unbiased estimators of the score function, i.e. the gradient of the log-likelihood function with respect to parameters, with no time-discretization bias. These estimators can be straightforwardly employed within stochastic gradient methods to perform maximum likelihood estimation or Bayesian inference. As our proposed methodology only requires access to a time-discretization scheme such as the Euler-Maruyama method, it is applicable to a wide class of diffusion processes and observation models. Our approach is based on a representation of the score as a smoothing expectation using Girsanov theorem, and a novel adaptation of the randomization schemes developed in [1], [2] and [3]. This allows one to remove the time-discretization bias and burn-in bias when computing smoothing expectations using the conditional particle filter of [4]. Central to our approach is the development of new couplings of multiple conditional particle filters. We prove under assumptions that our estimators are unbiased and have finite variance. The methodology is illustrated on several challenging applications from population ecology and neuroscience.
%
%\medskip
%
%[1] D. Mcleish. A general method for debiasing a Monte Carlo. \textit{Monte Carlo Methods and Applications}, 17:301–315, 2011.
%
%[2] C.-H. Rhee and P. W. Glynn. Unbiased estimation with square root convergence for SDE models. \textit{Operations
%Research}, 63(5):1026–1043, 2015.
%
%[3] P. E. Jacob, F. Lindsten, and T. B. Schön. Smoothing with couplings of conditional particle filters. \textit{Journal
%of the American Statistical Association}, 115(530):721–729, 2020.
%[4] C. Andrieu, A. Doucet, and R. Holenstein. Particle Markov chain Monte Carlo methods. \textit{Journal of the
%Royal Statistical Society: Series B (Statistical Methodology)}, 72(3):269–342, 2010.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Revisiting the dimension truncation error of parametric elliptic PDEs}% [1] talk title
% {Vesa Kaarnioja}% [2] speaker name
% {Freie Universit\"at Berlin}% [3] affiliations
% {vesa.kaarnioja@fu-berlin.de}% [4] email
% {Philipp Guth}% [5] coauthors
% {}% [6] special session
% {\timeslot{Monday, July 18, 2022}{17:00}{17:30}{Lecture Hall 6}}% [7] time slot
% {4532}% [8] talk id
% {4530}% [9] session id
%Elliptic PDEs with uncertain or random inputs have been considered in many studies of uncertainty quantification. In forward uncertainty quantification, one is interested in analyzing the stochastic response of the PDE subject to input uncertainty, which usually involves solving high-dimensional integrals of the PDE output over a sequence of stochastic variables. In practical computations, one typically needs to discretize the problem in several ways: approximating an infinite-dimensional input random field with a finite-dimensional random field, spatial discretization of the PDE using, e.g., finite elements, and approximating high-dimensional integrals using cubatures such as the quasi-Monte Carlo method.
%
%\medskip
%
%In this talk, we focus on the error resulting from dimension truncation of the input random field. In particular, we demonstrate in high-dimensional problems which do not conform to the ordinary affine-parametric operator equation setting how Taylor series can be used to derive theoretical dimension truncation rates---and, in some cases, improve existing rates. Numerical examples support our theoretical findings.
%\end{talk}
%
%\begin{talk}
% {Direct simulation Monte Carlo and oscillations in aggregation-fragmentation kinetics}% [1] talk title
% {Aleksei Kalinov}% [2] speaker name
% {Institute of Science and Technology Austria}% [3] affiliations
% {aleksei.kalinov@ist.ac.at}% [4] email
% {S.~A.~Matveev, A.~I.~Osinskiy}% [5] coauthors
% {}% [6] special session
% {\timeslot{Monday, July 18, 2022}{17:00}{17:30}{Lecture Hall 4}}% [7] time slot
% {4314}% [8] talk id
% {4310}% [9] session id
%Aggregation kinetics describes the interaction of colliding particle clusters that form larger agglomerates
%as time goes on. The evolution of cluster size densities in such systems can be efficiently computed via Monte Carlo methods.
%However, these algorithms experience a significant slowdown during fragmentation events due to the volume of updates for a non-constant number of new particles.
%In our talk we discuss how to extend two popular Direct Simulation Monte Carlo methods to aggregation
%processes with collisional fragmentation while preserving their efficiency~[1]. We adapt underlying data structures to efficiently handle many updates at once.
%
%To demonstrate the applicability of the approaches, we compare their performance and accuracy with efficient deterministic finite-difference method applied to the same model~[2]. Additionally, we use these methods to verify the existence of oscillating regimes in the aggregation-fragmentation kinetics recently detected in deterministic simulations. We confirm that steady oscillations of densities are stable with respect to fluctuations and noise.
%
%
%\medskip
%
%S. M. was supported by Russian Science Foundation (project 21-71-10072).
%
%
%[1] Kalinov A., Osinsky A. I., Matveev S. A., Otieno W., \& Brilliantov N. V. (2021). Direct simulation Monte Carlo for new regimes in aggregation-fragmentation kinetics. arXiv preprint arXiv:2103.09481.
%
%[2] Matveev S. A., Krapivsky P. L., Smirnov A. P., Tyrtyshnikov E. E., \& Brilliantov N. V. (2017). Oscillations in aggregation-shattering processes. Physical review letters, 119(26), 260601.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Density estimation in RKHS with application to Korobov spaces in high dimensions}% [1] talk title
% {Yoshihito Kazashi}% [2] speaker name
% {Heidelberg University}% [3] affiliations
% {y.kazashi@uni-heidelberg.de}% [4] email
% {Fabio Nobile}% [5] coauthors
% {Quasi-Monte Carlo Methods of High Order and Beyond}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{11:30}{12:00}{Lecture Hall 6}}% [7] time slot
% {2153}% [8] talk id
% {2150}% [9] session id
%In this talk, we will consider a kernel method for estimating a probability density function (pdf) from an i.i.d.~sample drawn from such density. Our estimator is a linear combination of kernel functions, the coefficients of which are determined by a linear equation.
%We will present an error analysis for the mean integrated squared error in a general reproducing kernel Hilbert space setting.
%Then, we will discuss how this theory can be applied to estimate pdfs for circular data. Under a suitable smoothness assumption, our method attains a rate arbitrarily close to the optimal rate.
%\end{talk}
%
%\begin{talk}
% {Quasi-Monte Carlo algorithms (not only) for graphics software}% [1] talk title
% {Alexander Keller}% [2] speaker name
% {NVIDIA}% [3] affiliations
% {akeller@nvidia.com}% [4] email
% {Carsten W\"achter, Nikolaus Binder, and Pascal Gautron}% [5] coauthors
% {Algorithmic Advancements in MCQMC Software}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{12:00}{12:30}{Lecture Hall 5}}% [7] time slot
% {2244}% [8] talk id
% {2240}% [9] session id
%
%%Your abstract goes here. Please do not use your own commands or macros.
%
%Quasi-Monte Carlo methods are industry standard in computer graphics.
%We discuss fast algorithms for low discrepancy sequences and
%numerical traps that may be encountered in practice. We take a
%fresh look at massively parallel quasi-Monte
%Carlo integro-approximation for the purpose of image synthesis by light transport simulation.
%While being of superior uniformity, low discrepancy points
%may be optimized with respect to additional criteria, such as
%noise characteristics at low sampling rates or behavior
%of low-dimensional projections. Several such approaches
%including dimension reordering and optimization by scrambling
%are reviewed.
%\end{talk}
%
%
%\begin{talk}
% {Stratified and jittered sampling in discrepancy theory}% [1] talk title
% {Markus Kiderlen}% [2] speaker name
% {Aarhus University}% [3] affiliations
% {kiderlen@math.au.dk}% [4] email
% {Florian Pausinger}% [5] coauthors
% {Random Points: Generation, Quality Criteria, and Applications}% [6] Special session title
% {\timeslot{Friday, July 22, 2022}{10:30}{11:00}{Lecture Hall 4}}% [7] time slot
% {2144}% [8] talk id
% {2140}% [9] session id
%We discuss properties and discrepancies of
%stratified samples $\mathcal P$ of the unit cube. More specifically,
%let $N\in \mathbb N$ be given, assume that $\Omega_1,\ldots,\Omega_N$ is a partition of $[0,1]^d\subset {\mathbb R}^d$, and let the $i$th random point in $\mathcal P$
%be chosen uniformly in the $i$th set of the partition (and stochastically independent of the other points), $i = 1, \ldots, N$.
%
%
%The first part of the talk is devoted to the question whether a partition into $N$ sets exists such that the expected discrepancy of $\mathcal P$ becomes minimal.
%Geometric arguments reveal that this indeed is the case when the sets $\Omega_1,\ldots,\Omega_N$ are equivolume and have a reach that is bounded away from zero by a positive constant. For instance, convex sets of given volume satisfy this condition. The assumptions on the underlying discrepancy are rather weak, so the result holds in particular for the mean
%${\mathcal L}_p$-discrepancy and for the star discrepancy.
%
%
%In the second part, we compare mean ${\mathcal L}_p$-discrepancies for $1\le p<\infty$ of stratified samples with one another and with
%the ground model of i.i.d.~random points in the unit square.
%Generalizing a result by Pausinger \& Steinerberger we show the \emph{strong partition principle}, stating that the mean ${\mathcal L}_p$-discrepancy of a stratified sample from $N$ equivolume sets
%is always strictly smaller that the mean ${\mathcal L}_p$-discrepancy of equally many i.i.d.~points (`\emph{stratification is better}'). A prominent example is jittered sampling --which can be used when $N=m^d$, $m\in \mathbb N$-- where the sets $\Omega_i$ are all translations of $[0,1/m]^d$. It will be shown that jittered sampling is in general not the above mentioned minimizer (`\emph{jitter is not best}'). We will construct a partition of the unit cube into
%$m^d$ convex sets of equal volume, such that the corresponding sample has a better
%mean ${\mathcal L}_2$-discrepancy than jittered sampling with equally many points.
%\end{talk}
%
%
%\begin{talk}
% {Stability of MAP estimation via $\boldsymbol{\mathsf{\Gamma}}$-convergence of Onsager--Machlup functionals}% [1] talk title
% {Ilja Klebanov}% [2] speaker name
% {Freie Universit\"at Berlin}% [3] affiliations
% {klebanov@zedat.fu-berlin.de}% [4] email
% {Birzhan~Ayanbayev, Han Cheng Lie, Tim~Sullivan}% [5] coauthors
% {Laplace Approximation and Other Model-Based Preconditioning Methods for Monte Carlo Algorithms}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{17:00}{17:30}{Lecture Hall 6}}% [7] time slot
% {2262}% [8] talk id
% {2260}% [9] session id
%The Bayesian solution to a statistical inverse problem can be summarised by a mode of the posterior distribution, i.e.\ a maximum a posteriori (MAP) estimator.
%The MAP estimator essentially coincides with the (regularised) variational solution to the inverse problem, seen as minimisation of the Onsager--Machlup (OM) functional of the posterior measure.
%An open problem in the stability analysis of inverse problems is to establish a relationship between the convergence properties of solutions obtained by the variational approach and by the Bayesian approach.
%To address this problem, we propose a general convergence theory for modes in [1,2] that is based on the $\Gamma$-convergence of Onsager--Machlup functionals, and apply this theory to a large class of prior distributions.
%
%\medskip
%
%[1] B. Ayanbayev, I. Klebanov, H. C. Lie, T. J. Sullivan, $\Gamma$-convergence of Onsager-Machlup functionals: I. With applications to maximum a posteriori estimation in Bayesian inverse problems. Inverse Problems 38 (2022), no. 2, Paper No. 025005
%\newline
%[2] B. Ayanbayev, I. Klebanov, H. C. Lie, T. J. Sullivan, $\Gamma$-convergence of Onsager-Machlup functionals: II. Infinite product measures on Banach spaces. Inverse Problems 38 (2022), no. 2, Paper No. 025006
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Lower bounds for integration and recovery in $L_2$}% [1] talk title
% {David Krieg}% [2] speaker name
% {JKU Linz}% [3] affiliations
% {david.krieg@jku.at}% [4] email
% {Aicke Hinrichs, Erich Novak, Jan Vyb\'iral}% [5] coauthors
% {Stochastic Computation and Complexity: High Dimensional Approximation, Integration, and PDEs}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{11:00}{11:30}{STC 1012}}% [7] time slot
% {2162}% [8] talk id
% {2160}% [9] session id
%Function values are, in some sense,
%``almost as good'' as general linear
%information for $L_2$-approximation
%(optimal recovery, data assimilation) of functions from a reproducing kernel Hilbert space.
%This was recently proved by new
%\emph{upper bounds} on the sampling numbers
%under the assumption that the singular values of the embedding of this Hilbert space into $L_2$ are square-summable,
%see [2,3].
%Here we mainly prove new \emph{lower bounds}.
%In particular we prove that the sampling numbers
%behave worse than the approximation numbers
%for Sobolev spaces with small smoothness.
%Hence there can be a logarithmic gap also
%in the case where the singular numbers of the embedding
%are square-summable.
%We first prove new lower bounds
%for the integration problem, again for rather classical Sobolev spaces
%of periodic univariate functions.
%
%\medskip
%
%[1] A.~Hinrichs, E.~Novak, D.~Krieg, and J.~Vyb\'iral,
%Lower bounds for integration and recovery in $L_2$,
%arXiv preprint, 2021.
%
%[2] D.~Krieg and M.~Ullrich,
%Function values are enough for $L_2$-approximation,
%{\em Foundations of Computational Mathematics}, 2021.
%
%[3] N.~Nagel, M.~Sch\"afer, and T.~Ullrich.
% A new upper bound for sampling numbers.
% {\em Foundations of Computational Mathematics}, 2021.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Adaptive stratified sampling for non-smooth problems}% [1] talk title
% {Sebastian Krumscheid}% [2] speaker name
% {RWTH Aachen University}% [3] affiliations
% {krumscheid@uq.rwth-aachen.de}% [4] email
% {Per Pettersson}% [5] coauthors
% {Smoothing and Adaptive Methods}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{17:30}{18:00}{STC 1012}}% [7] time slot
% {2133}% [8] talk id
% {2130}% [9] session id
%Various sampling methods, including the multilevel Monte Carlo
%method, have been established as general-purpose procedures for
% efficiently quantifying uncertainties in computational models. The
% improved computational efficiency of these sampling methods compared
% to vanilla Monte Carlo sampling is usually obtained by suitable
% variance reduction techniques. It is known, however, that these
% techniques may not provide performance gains when there is a
% non-smooth, in particular discontinuous, parameter
% dependence. Moreover, in many applications some key variance
% reduction ideas cannot be fully exploited, such as those of
% multilevel Monte Carlo, for example, when a hierarchy of
% computational models cannot be easily constructed. An alternative
% means to obtain variance reduction in these cases is offered by
% stratified sampling methods. In this talk, we will discuss various
% ideas on adaptive stratified sampling methods tailored to
% applications with a discontinuous parameter dependence. Examples
% exhibiting discontinuous solutions include hyperbolic PDEs under
% uncertainty, such as the Euler equations describing a high-speed
% flow, and the shallow water equations modeling dam breaks, flooding
% and atmospheric flow. For such discontinuous problems, the
% stochastic domain is adaptively stratified using local variance
% estimates, and the samples are sequentially allocated to the strata
% for asymptotically optimal variance reduction. The proposed
% methodology is demonstrated on discontinuous test cases from
% computational fluid mechanics and CO2 storage in subsurface
% reservoirs.
%\end{talk}
%
%
%
%\begin{talk}
% {Approximation in periodic Gevrey spaces}% [1] talk title
% {Thomas K\"uhn}% [2] speaker name
% {Universit\"at Leipzig}% [3] affiliations
% {kuehn@math.uni-leipzig.de}% [4] email
% {Martin Petersen}% [5] coauthors
% {Stochastic Computation and Complexity: High Dimensional Approximation, Integration, and PDEs}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{12:00}{12:30}{STC 1012}}% [7] time slot
% {2164}% [8] talk id
% {2160}% [9] session id
%In my talk I will first introduce periodic Gevrey spaces $G^{s,c}(\mathbb{T}^d)$, a family of Hilbert spaces closely related to
%Gevrey classes. More than 100 years ago these by now famous classes were defined by Maurice Gevrey, motivated by applications to PDEs.
%
%Then the approximation numbers $a_n$ of the embeddings $G^{s,c}(\mathbb{T}^d)\hookrightarrow L_2(\mathbb{T}^d)$ will be studied,
%not only the asymptotic rate, but also the behaviour in the preasymptotic range $n\le 2^d$. Clearly, for computational
%aspects of high-dimensional approximation problems, it is
%more important to have good bounds in this range rather than to know 'only' the excat asymptotics as $n$ tends to infinity.
%
%If time allows I will also give an interpretation of these results in terms of
%tractability notions from Information-Based Complexity. Finally I will compare our new results for Gevrey embeddings with the corresponding
%known ones for mixed-order Sobolev embeddings.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Severity modeling of extreme insurance claims for tariffication}% [1] talk title
% {Christian Laudag\'{e}}% [2] speaker name
% {JKU Linz}% [3] affiliations
% {christian.laudage@jku.at}% [4] email
% {Sascha Desmettre, J\"{o}rg Wenzel}% [5] coauthors
% {Simulation and Monte Carlo Methods in Quantitative Finance and Insurance}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{18:00}{18:30}{Lecture Hall 5}}% [7] time slot
% {2104}% [8] talk id
% {2100}% [9] session id
%Generalized linear models (GLMs) are common instruments for the pricing of non-life insurance contracts. They are used to estimate the expected severity of insurance claims. We develop the threshold severity model (see [1]) that splits the claim size distribution in areas below and above a given threshold. More specifically, the extreme insurance claims above the threshold are modeled in the sense of the peaks-over-threshold (POT) methodology from extreme value theory using the generalized Pareto distribution for the excess distribution, and the claims below the threshold are captured by a GLM based on the
%truncated gamma distribution. To the best of our knowledge, the threshold
%severity model for the first time combines the POT modeling for extreme claim sizes with GLMs based on the truncated gamma distribution. We develop the corresponding log-likelihood function with respect to right-censored claim sizes, which is a typical issue that arises for instance in private or car liability insurance contracts. Finally, we demonstrate the behavior of the threshold severity model compared to the commonly used GLM based on the gamma distribution in the presence of simulated extreme claim sizes following a log-normal as well as Burr Type XII distribution.
%
%\medskip
%
%$\left[1\right]$ C. Laudag\'{e}, S. Desmettre \& J. Wenzel (2019). Severity Modeling of Extreme Insurance Claims for Tariffication. \textit{Insurance: Mathematics and Economics, 88}, 77-92. doi:\url{10.1016/j.insmatheco.2019.06.002}
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Stratified sampling for simulating multi-dimensional Markov chains}% [1] talk title
% {Christian L\'ecot}% [2] speaker name
% {Universit\'e Grenoble Alpes, Universit\'e Savoie Mont Blanc}% [3] affiliations
% {christian.lecot@univ-smb.fr}% [4] email
% {Rami El Haddad}% [5] coauthors
% {}% [6] special session
% {\timeslot{Tuesday, July 19, 2022}{15:30}{16:00}{Lecture Hall 4}}% [7] time slot
% {4321}% [8] talk id
% {4320}% [9] session id
%Monte Carlo (MC) is widely used for the simulation of discrete time Markov chains. Here, $N$ copies of the chain are simulated in parallel, using pseudorandom numbers and we extend the analysis of [1]: we consider the case of a $d$-dimensional continuous state space and
%we restrict ourselves to chains whose $d$ components are advanced independently from each other.
%We replace pseudorandom numbers on $I^d := [0,1)^d$ with stratified random points over $I^{2d}$: for each point, the first $d$ components are used to select a state and the last $d$ components are used to advance the chain by one step. We use the simple stratification technique: for $N=p^{2d}$ samples, the unit hypercube is dissected into $p^{2d}$ hypercubes and there is one sample in each of them. The strategy outperforms usual MC if a well-chosen multivariate sort of the states is employed to order the chains at each step. We prove that the variance of the stratified sampling estimator is bounded by $\mathcal{O}(N^{-(1+1/2d)})$, while it is bounded by $\mathcal{O}(N^{-1})$ for MC. We compare these results with those of numerical experiments.
%
%\medskip
%
%[1] El Haddad, R., El Maalouf, J., L\'ecot, C., L'Ecuyer,P.: Sudoku Latin square sampling for Markov chain simulation. In: B. Tuffin, P. L'Ecuyer (eds.), Monte Carlo and Quasi-Monte Carlo Methods, pp. 207--230. Springer, Cham (2020)
%\end{talk}
%
%\newpage
%
%
%\begin{talk}
% {An update on Lattice Tester, LatMRG, and Lattice Builder}% [1] talk title
% {Pierre L'Ecuyer}% [2] speaker name
% {Universit\'e de Montr\'eal}% [3] affiliations
% {lecuyer@iro.umontreal.ca}% [4] email
% {}% [5] coauthors
% {Developments in and Applications of MCQMC Software}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{11:00}{11:30}{Lecture Hall 5}}% [7] time slot
% {2172}% [8] talk id
% {2170}% [9] session id
%Lattice Tester, LatMRG, and LatNet Builder [1] are a trio of C++ libraries and programs
%connected to each other, whose purpose is to measure the quality of lattices in general,
%study the lattice structure of random number generators and search for generators
%with good structures, and construct good point sets and sequences for quasi-Monte Carlo.
%The three tools are available on GitHub and can already be used,
%although all three are still evolving.
%LatMRG and Lattice Tester were originally written in the Modula-2 language [2, 3]
%and have been rewritten in C++, although not yet completely.
%Both LatMRG and LatNet Builder use Lattice Tester.
%
%In this talk, we will provide a summary of what these tools are doing,
%an update of their status, and what they should offer in the near future.
%For the latter, we will also be happy to receive suggestions from the session participants.
%
%\medskip
%
%[1] P. L'Ecuyer, P. Marion, M. Godin, and F. Puchhammer,
%``A Tool for Custom Construction of QMC and RQMC Point Sets,''
%Monte Carlo and Quasi-Monte Carlo Methods 2020, A. Keller, Ed., Springer-Verlag, to appear, 2022.
%
%[2] P. L'Ecuyer and R. Couture, ``An Implementation of the Lattice and Spectral Tests
%for Multiple Recursive Linear Random Number Generators'',
%INFORMS Journal on Computing, 9, 2 (1997), 206--217.
%
%[3] P. L'Ecuyer and R. Couture, ``LatMRG User’s Guide: A Modula-2 software for the
% theoretical analysis of linear congruential and multiple recursive random number generators'',
%{\tt https://www-labs.iro.umontreal.ca/$\sim$lecuyer/myftp/papers/guide-latmrg-m2.pdf}, 2000.
%
%[4] The three GitHub pages can be found at {\tt https://github.com/umontreal-simul}.
%\end{talk}
%
%%\newpage
%
%\begin{talk}
% {Orthogonal projection on manifolds and numerical schemes for SDEs}% [1] talk title
% {Gunther Leobacher}% [2] speaker name
% {University of Graz}% [3] affiliations
% {gunther.leobacher@uni-graz.at}% [4] email
% {Alexander Steinicke}% [5] coauthors
% {Analysis and Simulation of SDEs in Non-Standard Settings}% [6] special session
% {\timeslot{Friday, July 22, 2022}{09:00}{09:30}{Lecture Hall 3}}% [7] time slot
% {2191}% [8] talk id
% {2190}% [9] session id
%In [2] and [3], numerical schemes for multidimensional stochastic differential equations (SDEs) with discontinuous drift terms and degenerate diffusions have been studies. The points of discontinuity of the drift coefficient were required to be a smooth ($C^4$) manifold $\Theta\subseteq\mathbb{R}^d $.
%On the complement of this manifold, the drift was assumed to be smooth
%and thus locally Lipschitz continuous.
%
%In [3], a transform was constructed, which transforms the SDE with discontinuous drift into one with Lipschitz
%continuous drift, thus allowing the application of classical results.
%This transform requires the so called unique nearest point property of the manifold $\Theta$ as well
%as the function which assigns the nearest point $p(x)$, i.e.~the projection, to an ambient point $x\in \mathbb{R}^d\setminus \Theta$. In [1] we study for which classes of manifolds this function $p$ exists and which regularity properties it has.
%This opens the way for the study of tighter conditions under which the transform method may still be applied.
%
%\medskip
%
%[1] G.~Leobacher and A.~Steinicke.
%\newblock {Exception sets of intrinsic and piecewise Lipschitz functions}.
%\newblock {\em Journal of Geometric Analysis}, 32, 2022.
%
%[2]
%G.~Leobacher and M.~Sz\"olgyenyi.
%\newblock A strong order $1/2$ method for multidimensional {SDE}s with
% discontinuous drift.
%\newblock {\em Ann. Appl. Probab.}, 27(4):2383--2418, 2017.
%
%[3]
%G.~Leobacher and M.~Sz\"olgyenyi.
%\newblock {Convergence of the Euler-Maruyama method for multidimensional SDEs
% with discontinuous drift and degenerate diffusion coefficient}.
%\newblock {\em Numerische Mathematik}, 138(1):219--239, 2018.
%\end{talk}
%
%\newpage
%
%
%\begin{talk}
% {Taming singular SDEs: A numerical method}% [1] talk title
% {Chengcheng Ling}% [2] speaker name
% {TU Berlin}% [3] affiliations
% {ling@math.tu-berlin.de}% [4] email
% {Khoa L\^e}% [5] coauthors
% {Stochastic Computation and Complexity: Approximation of SDEs with Non-Standard Coefficients}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{11:00}{11:30}{STC 1012}}% [7] time slot
% {2296}% [8] talk id
% {2290}% [9] session id
%We consider a generic and explicit tamed Euler--Maruyama scheme for multidimensional time-inhomogeneous stochastic differential equations with multiplicative Brownian noise. The diffusive coefficient is uniformly elliptic, H\"older continuous and weakly differentiable in the spatial variables while the drift satisfies the
%Ladyzhenskaya-Prodi-Serrin condition, as considered by Krylov and R\"ockner (2005).
%In the discrete scheme, the drift is tamed by replacing it by an approximation.
%A strong rate of convergence of the scheme is provided in terms of the approximation error of the drift in a suitable and possibly very weak topology.
%A few examples of approximating drifts are discussed in detail. The parameters of the approximating drifts can vary and---under suitable conditions---be fine-tuned to achieve the standard $1/2$-strong convergence rate with a logarithmic factor.
%\end{talk}
%
%\begin{talk}
% {Pre-integration via active subspaces}% [1] talk title
% {Sifan Liu}% [2] speaker name
% {Stanford University}% [3] affiliations
% {sfliu@stanford.edu}% [4] email
% {Art B.~Owen}% [5] coauthors
% {Smoothing and Adaptive Methods}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{18:00}{18:30}{STC 1012}}% [7] time slot
% {2134}% [8] talk id
% {2130}% [9] session id
%Pre-integration is an extension of conditional Monte Carlo to quasi-Monte Carlo and randomized quasi-Monte Carlo. It can reduce but not increase the variance in Monte Carlo. For quasi-Monte Carlo it can bring about improved regularity of the integrand with potentially greatly improved accuracy. Pre-integration is ordinarily done by integrating out one of $d$ input variables to a function. In the common case of a Gaussian integral one can also pre-integrate over any linear combination of variables. We propose to do that and we choose the first eigenvector in an active subspace decomposition to be the pre-integrated linear combination. We find in numerical examples that this active subspace pre-integration strategy is competitive with pre-integrating the first variable in the principal components construction on the Asian option where principal components are known to be very effective. It outperforms other pre-integration methods on some basket options where there is no well established default. We show theoretically that, just as in Monte Carlo, pre-integration can reduce but not increase the variance when one uses scrambled net integration. We show that the lead eigenvector in an active subspace decomposition is closely related to the vector that maximizes a less computationally tractable criterion using a Sobol' index to find the most important linear combination of Gaussian variables. They optimize similar expectations involving the gradient. We show that the Sobol' index criterion for the leading eigenvector is invariant to the way that one chooses the remaining $d-1$ eigenvectors with which to sample the Gaussian vector.
%\end{talk}
%
%
%
%\begin{talk}
% {Lower bounds for the logarithmic energy on $\mathbb{S}^2$ and for the Green energy on $\mathbb{S}^n$}% [1] talk title
% {F\'atima Lizarte}% [2] speaker name
% {Universidad de Cantabria}% [3] affiliations
% {fatima.lizarte@unican.es}% [4] email
% {Carlos Beltr\'{a}n}% [5] coauthors
% {Quantifying Notions of Equidistribution on the Sphere}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{10:30}{11:00}{Lecture Hall 3}}% [7] time slot
% {2111}% [8] talk id
% {2110}% [9] session id
%Smale's problems are a list of 18 challenging problems for the twenty-first century proposed by Field's medallist Steve Smale. The 7th problem is to give a simple and efficient description, or alternatively describe an algorithm, to place $N$ points in the sphere such that their logarithmic potential is very close to the minimum. A major difficulty in this problem is that the value of the minimal logarithmic energy on the sphere is not fully known. The current knowledge is:
%$$
%\kappa N^2-\frac{1}{2}N\ln N +C_{\log} N+o(N),
%$$
%where $\kappa$ is the continuous energy and $C_{\log}$ is a constant such that
%$$
%-0.0568\ldots=\ln 2- \frac34\leqslant C_{\log} \leqslant 2\ln 2+\frac12\ln\frac23+3\ln\frac{\sqrt{\pi}}{\Gamma(1/3)}=-0.0556\ldots,
%$$
%where the lower bound $-0.0568\ldots$ was proved by Lauritsen building upon previous results by Sandier, Serfaty and Betermin. In fact, the upper bound has been conjectured to be an equality and it is one of the most important open problems in the area. In the talk I will show an alternative proof of Lauritsen's lower bound for the constant $C_{\log}$. This new approach generalizes to new lower bounds for the Green energy of $\mathbb{S}^n$.
%
%\medskip
%
%\textbf{References}
%
%\begin{enumerate}
%\item Beltr\'{a}n, C., Corral, N. and G. Criado del Rey, J. (2019) \textit{Discrete and continuous green energy on compact manifolds}. J. Approx. Theory, 237, 160--185.
%\item Lauritsen, A. B. (2021) \textit{Floating Wigner crystal and periodic jellium configurations}. J. Math. Phys., 62, 083305.
%\item Lizarte, F. (2022) \textit{Lower bounds for the logarithmic energy on $\mathbb{S}^2$ and for the Green energy on $\mathbb{S}^n$}. Work in progress.
%\end{enumerate}
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Reversible random number generators and adjoint Monte Carlo simulation for tokamak divertor design}% [1] talk title
% {Emil L{\o}vbak}% [2] speaker name
% {KU Leuven}% [3] affiliations
% {emil.loevbak@kuleuven.be}% [4] email
% {Giovanni Samaey, Stefan Vandewalle}% [5] coauthors
% {Developments in and Applications of MCQMC Software}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{16:30}{17:00}{Lecture Hall 5}}% [7] time slot
% {2175}% [8] talk id
% {2170}% [9] session id
%Nuclear fusion is an exciting potential source of clean, reliable energy for the future. However, significant challenges still remain in developing a reactor capable of supplying the power grid. One such challenge is designing the divertor, a component that removes waste particles from the reactor. The divertor comes into contact with a dense plasma, modeled as a fluid, as well as lower density neutral particles, modeled as a kinetic process.
%
%Research codes for divertor design, such as B2-EIRENE [1], simulate the coupled plasma-neutral model through a combination of finite volume and Monte Carlo particle methods. The design is iteratively refined in an adjoint based optimization routine, i.e., gradients are computed by simulating the adjoint model with a similar discretization. The current Monte Carlo simulations are unfortunately too expensive for feasible in silico divertor design.
%
%At KU Leuven we have developed a variety of techniques for accelerating the Monte Carlo component of these codes. We have developed a new class of asymptotic-preserving Multilevel Monte Carlo schemes [2,3] for accelerating both the forward and adjoint simulations. We have also developed a discrete adjoint approach, based on reversible random number generators. This approach simulates the same stochastic paths for the forward and adjoint Monte Carlo simulation, with the goal of reducing the number of iterations required in the optimization routine. In this talk, I will introduce these techniques, as well as our current work on challenges remaining on the path towards valorization in the B2-EIRENE code.
%
%
%\begin{itemize}
%	\item [{[1]}] D. Reiter, M. Baelmans, and P. B\"{o}rner, \emph{The EIRENE and B2-EIRENE Codes}, Fusion Science and Technology, 47(2), pp. 172--186, Feb. 2005
%	\item [{[2]}] E. L{\o}vbak, G. Samaey, and S. Vandewalle, \emph{A multilevel Monte Carlo method for asymptotic-preserving particle schemes in the diffusive limit}, Numerische Mathematik, 148(1), pp. 141–186, May 2021
%	\item [{[3]}] E. L{\o}vbak, B. Mortier, G. Samaey, and S. Vandewalle, \emph{Multilevel Monte Carlo with Improved Correlation for Kinetic Equations in the Diffusive Scaling}, Computational Science – ICCS 2020, Springer Lecture Notes in Computer Science 12142, pp. 374–388, Jun. 2020
%\end{itemize}
%\end{talk}
%
%\begin{talk}
% {Rate-optimality of an adaptive quasi-Monte Carlo finite element method}% [1] talk title
% {Marcello Longo}% [2] speaker name
% {ETH Z\"{u}rich}% [3] affiliations
% {marcello.longo@sam.math.ethz.ch}% [4] email
% {}% [5] coauthors
% {Quasi-Monte Carlo Methods of High Order and Beyond}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{12:00}{12:30}{Lecture Hall 6}}% [7] time slot
% {2154}% [8] talk id
% {2150}% [9] session id
%We study the Adaptive Finite Element Method for the solution of
%Partial Differential Equations (PDEs) governed by random coefficients, where the randomness is modeled by countably many parameters.
%In this talk, we show that extrapolated polynomial lattice rules allow to recover moments of the solution of a PDE, within a given error tolerance.
%Based on [1], we compare two approaches for adaptivity, which are non-intrusive, easily parallelizable and break the curse of dimensionality, if suitable parametric regularity assumptions are verified.
%Moreover, we show novel results achieving rate-optimal convergence of the finite element error, under assumptions comparable to the deterministic setting, also for certain non-linear PDEs.
%
%
%\medskip
%[1] M. Longo.\ (in press).\ Adaptive Quasi-Monte Carlo Finite Element Methods for parametric elliptic PDEs. \emph{J.\ Sci.\ Comput.}
%\end{talk}
%
%%\newpage
%
%\begin{talk}
% {A multilevel stochastic approximation algorithm for unbiased value-at-risk and expected shortfall estimation}% [1] talk title
% {Azar Louzi}% [2] speaker name
% {Universit{\'e} de Paris, CNRS}% [3] affiliations
% {louzy@lpsm.paris}% [4] email
% {Noufel Frikha, St{\'e}phane Cr{\'e}pey}% [5] coauthors
% {}% [6] special session
% {\timeslot{Wednesday, July 20, 2022}{14:30}{15:00}{Lecture Hall 5}}% [7] time slot
% {4432}% [8] talk id
% {4430}% [9] session id
%We propose a multilevel stochastic approximation scheme~[1] for the computation of the value-at-risk and the expected shortfall of a given financial loss.
%The financial loss can only be computed via simulations that are conditional to the realization of future risk factors.
%Thus, the problem at hand of estimating its value-at-risk and expected shortfall is nested in nature and can in addition be viewed as an instance of stochastic approximation problems \textit{with a bias} as per~[2].
%In this framework, for a prescribed precision $\varepsilon$, the optimal complexity of the standard stochastic approximation algorithm is of order $\varepsilon^{-3}$.
%Thanks to the multilevel approach, we prove that the optimal complexity of our multilevel stochastic approximation algorithm is of order $\varepsilon^{-2-\delta}$, where $\delta<1$ is a small number that depends on the integrability level of the loss.
%%as in the unbiased case.
%We provide some numerical results to validate our analysis.
%
%\medskip
%
%
%\begin{enumerate}
% \item\label{[1]}
%Noufel Frikha. \emph{Multi-level stochastic approximation algorithms}. Annals of Applied Probability 26.2 (2016), pp. 933–985.
% \item\label{[2]}
%David Barrera, St{\'e}phane Cr{\'e}pey, Babacar Diallo, Gersende Fort, Emmanuel Gobet and Uladzislau Stazhynski.
%\emph{Stochastic Approximation Schemes for Economic Capital and Risk Margin Computations}. ESAIM: Proceedings and Surveys (2019).
%\end{enumerate}
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Multilevel delayed acceptance: ergodic MCMC for model hierarchies}% [1] talk title
% {Mikkel Bue Lykkegaard}% [2] speaker name
% {University of Exeter}% [3] affiliations
% {m.lykkegaard@exeter.ac.uk}% [4] email
% {Tim Dodwell, Colin Fox, Grigorios Mingas, Robert Scheichl}% [5] coauthors
% {Recent Advances in MCMC Sampling Techniques}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{17:00}{17:30}{Lecture Hall 4}}% [7] time slot
% {2212}% [8] talk id
% {2210}% [9] session id
%We present a novel MCMC algorithm, titled Multilevel Delayed Acceptance (MLDA). The algorithm is capable of sampling from the exact target distribution using a hierarchy of distributions of increasing complexity and computational cost and can be considered as an amalgam of two existing methods, namely the Delayed Acceptance (DA) MCMC of Christen and Fox [1] and the Multilevel MCMC (MLMCMC) of Dodwell \textit{et al.} [2].
%
%The original DA algorithm was designed to use a single coarse distribution to filter MCMC proposals before computing the fine density. We extend this approach in two ways. \textit{Vertically}, by allowing any number of coarse distributions to underpin the target and \textit{horizontally}, by allowing the coarse level samplers to generate extended subchains of either fixed or random lengths. The resulting algorithm is in detailed balance with the exact target distribution. We show that MLDA can be exploited for variance reduction, similarly to MLMCMC, and construct a multilevel error model that adaptively aligns the coarse distributions to the target with little additional computational cost.
%
%\medskip
%
%[1] Christen J. A. and Fox C. (2005), Markov chain Monte Carlo Using an Approximation. \textit{J. Comput. Graph. Stat.}
%
%[2] Dodwell T. J., Ketelsen C., Scheichl R., and Teckentrup A. L. (2015), A Hierarchical Multi-level Markov Chain Monte Carlo Algorithm with Applications to Uncertainty Quantification in Subsurface Flow. \textit{SIAM/ASA J. Uncertain. Quantif.}
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {High-dimension simulating hyperplane-truncated multivariate normal distributions}% [1] talk title
% {Hassan Maatouk}% [2] speaker name
% {CY Tech Cergy Paris University}% [3] affiliations
% {hmk@cy-tech.fr}% [4] email
% {Xavier Bay, Didier Rulli\`ere}% [5] coauthors
% {}% [6] special session
% {\timeslot{Monday, July 18, 2022}{15:30}{16:00}{STC 1012}}% [7] time slot
% {4111}% [8] talk id
% {4110}% [9] session id
%Generating multivariate normal distributions is widely used in many fields (such as science and engineering).
%In this paper, simulating high-dimensional multivariate normal distributions truncated on the intersection of a set of hyperplanes is investigated.
%The proposed methodology is based on combining Karhunen-Lo\`eve expansions (KLE) and Matheron's update rules (MUR).
%The KLE requires the computation of the decomposition of the covariance matrix of the random variables.
%This step becomes expensive when the data dimension is high.
%To deal with this issue, the domain is split in smallest sub-domains where the eigen decomposition can be computed.
%In the first step, the KLE coefficients are conditioned in order to guarantee the correlation structure on the entire domain.
%In the second one, the assembled vectors are mapped on the intersection of a set of hyperplanes using the MUR.
%This technique can also be parallelized and then reduces the computational complexity.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Hybrid deterministic/MC methods in SOLPS-ITER}% [1] talk title
% {Vince Maes}% [2] speaker name
% {KU Leuven}% [3] affiliations
% {vince.maes@kuleuven.be}% [4] email
% {Wouter Dekeyser, Julian Koellermeier, Tine Baelmans, Giovanni Samaey}% [5] coauthors
% {Developments in and Applications of MCQMC Software}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{17:30}{18:00}{Lecture Hall 5}}% [7] time slot
% {2177}% [8] talk id
% {2170}% [9] session id
%One of today’s biggest challenges is to meet the growing worldwide demand of energy in a sustainable way. One of the most promising solutions is nuclear fusion energy. The realization of a profitable fusion reactor, unfortunately, comes with many technical complications. To avoid the cost of building many prototypes, computer simulations are used during the optimization phase of the reactor design.
%
%Neutral particles play an important role in shielding the reactor walls from the hot plasma in which the fusion reactions take place. The zone where neutral particles interact with the incoming plasma and the reactor walls is called the plasma edge. The neutral particles can be described by a kinetic equation, which is difficult
%to solve due to the high dimensionality of the phase space and the high collisionality
%between the neutral particles and the plasma background, especially in the working regimes anticipated for future reactors.
%
%SOLPS-ITER [1] is one of the few codes that is used worldwide for modeling the plasma edge. The code uses a Monte Carlo solver, called EIRENE [2], to treat the neutral particles. In the high collisional regimes a pure Monte Carlo solver becomes very expensive. To alleviate the computational cost, hybrid deterministic/MC methods that exploit the high-collisionality of the system are being introduced in EIRENE [3]. This is a challenging task as the solver was initially intended to be a pure Monte Carlo code. In this talk we will shed light on what EIRENE is, on the different deterministic/MC methods that are being implemented in EIRENE, and on how the code has to be changed to perform well with these hybrid methods, with special focus on one type of hybrid deterministic/MC method: the micro-macro hybrid approach [4].
%
%\medskip
%
%[1] S. Wiesen et al., The new SOLPS-ITER code package, Journal of Nuclear Materials, 463, p. 480, 2015.
%
%[2] D. Reiter, M. Baelmans and P. B\"{o}rner, The EIRENE and B2-EIRENE codes, Fusion Science and Technology, 47 (2), p. 172, 2005.
%
%[3] D.V. Borodin et al., Fluid, kinetic and hybrid approaches for neutral and trace ion edge
%transport modelling in fusion devices, accepted by Nuclear Fusion.
%
%[4] N. Horsten, G. Samaey and M. Baelmans, A hybrid fluid-kinetic model for hydrogenic atoms
%in the plasma edge of tokamaks based on a micro-macro decomposition of the kinetic equation,
%Journal of Computational Physics, 409, ARTN 109308, 2020.
%\end{talk}
%
%
%\begin{talk}
% {QMC designs and random point configurations}% [1] talk title
% {Jordi Marzo}% [2] speaker name
% {Universitat de Barcelona, Centre de Recerca Matem\`{a}tica}% [3] affiliations
% {jmarzo@ub.edu}% [4] email
% {V\'ictor de la Torre}% [5] coauthors
% {Quantifying Notions of Equidistribution on the Sphere}% [6] special session
% {\timeslot{Monday, July 18, 2022}{11:00}{11:30}{Lecture Hall 3}}% [7] time slot
% {2112}% [8] talk id
% {2110}% [9] session id
%Sequences of QMC designs, introduced in [1], provide optimal order of equal weight integration for Sobolev spaces. In this talk I will discuss the behaviour of different random configurations on the sphere as QMC designs.
%
%\medskip
%
%[1] J. S. Brauchart, E. B. Saff, I. H. Sloan, and R. S. Womersley. QMC designs: optimal order quasi Monte Carlo integration schemes on the sphere. Math. Comput., 83(290):2821–2851, 2014.
%\end{talk}
%
%
%\begin{talk}
% {The spherical cap discrepancy of HEALPix points}% [1] talk title
% {Michelle Mastrianni}% [2] speaker name
% {University of Minnesota}% [3] affiliations
% {michmast@umn.edu}% [4] email
% {Damir Ferizovi{\'c}, Julian Hofstadler}% [5] coauthors
% {Quantifying Notions of Equidistribution on the Sphere}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{11:30}{12:00}{Lecture Hall 3}}% [7] time slot
% {2113}% [8] talk id
% {2110}% [9] session id
%We shall consider questions regarding the spherical cap discrepancy of deterministic point sets on the unit $2$-sphere. In particular, we study the point set given by centers of pixels in the HEALPix tessellation (short for Hierarchical, Equal Area and iso-Latitude Pixelation) and show that for such a point set with $N$ points, the spherical cap discrepancy is lower and upper bounded by order $N^{-1/2}$. This adds to the known collection of explicitly constructed sets whose discrepancy converges with order $N^{-1/2}$, matching the asymptotic order for i.i.d. random point sets. The proof of the upper bound (with explicit constant) is based on a classical approach akin to the Gauss circle problem. We also briefly discuss a jittered sampling technique that works in the HEALPix framework and yields the best-known bound $N^{-3/4}\log N$ for randomly generated point sets.
%\end{talk}
%
%\begin{talk}
% {AdaSmooth: a fast and stable SMC algorithm for online additive smoothing}% [1] talk title
% {Alessandro Mastrototaro}% [2] speaker name
% {KTH Royal Institute of Technology}% [3] affiliations
% {alemas@kth.se}% [4] email
% {Jimmy Olsson, Johan Alenl\"{o}v}% [5] coauthors
% {}% [6] special session
% {\timeslot{Friday, July 22, 2022}{10:00}{10:30}{Lecture Hall 6}}% [7] time slot
% {4583}% [8] talk id
% {4580}% [9] session id
%This talk will deal with a novel sequential Monte Carlo (SMC) approach to online smoothing of additive functionals in a very general class of path-space models. Hitherto, the solutions proposed in the literature suffer from either long-term numerical instability due to particle-path degeneracy or, in the case that degeneracy is remedied by particle approximation of the so-called backward kernel, high computational demands. I will present a new, function-specific additive smoothing algorithm, AdaSmooth, which is computationally fast, numerically stable and easy to implement. In order to balance optimally computational speed against numerical stability, AdaSmooth combines a (fast) naive particle smoother, propagating recursively a sample of particles and associated smoothing statistics, with an adaptive backward-sampling-based updating rule which allows the number of (costly) backward samples to be kept at a minimum. Rigorous theoretical results guaranteeing the consistency, asymptotic normality and long-term stability of the algorithm will be presented, as well as numerical results demonstrating empirically the clear superiority of AdaSmooth to existing algorithms.
%\begin{itemize}
%	\item Mastrototaro, A., Olsson, J., \& Alenl\"{o}v, J. (2021). Fast and numerically stable particle-based online additive smoothing: the AdaSmooth algorithm. arXiv preprint arXiv:2108.00432.
%\end{itemize}
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Optimality of harmonic ensembles on two-point homogeneous spaces}% [1] talk title
% {Ryan W.~Matzke}% [2] speaker name
% {Graz University of Technology}% [3] affiliations
% {matzke@math.tugraz.at}% [4] email
% {Austin Anderson, Bence Borda, Maria Dostert, Peter Grabner, Tetiana Stepaniuk}% [5] coauthors
% {Energy-Minimizing Point Configurations and Measures II}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{17:00}{17:30}{Lecture Hall 3}}% [7] time slot
% {2282}% [8] talk id
% {2280}% [9] session id
%In many areas of mathematics, one is interested in finding point sets on manifolds that are well-distributed, in some sense. Often, finding explicit, computable examples of well-distributed point configurations can be difficult, so one may instead samples random point configurations. Taking i.i.d. uniformly distributed points proves to be too coarse of a method, as the sampled points may clump together. This issue can be avoided by creating repulsion between our random points if we generate them via determinantal point processes.
%
%In this talk, we shall discuss random point sets on the sphere and projective spaces generated by harmonic ensembles, determinantal point processes induced by a projection kernel built from the harmonics on those spaces. On average, the resulting sampled point sets are uniformly distributed, and in fact optimal in terms of certain energies, discrepancies, and Wasserstein distance from the uniform measure.
%\end{talk}
%
%\begin{talk}
% {Subordinated random fields and elliptic PDEs}% [1] talk title
% {Robin Merkle}% [2] speaker name
% {University of Stuttgart}% [3] affiliations
% {robin.merkle@mathematik.uni-stuttgart.de}% [4] email
% {Andrea Barth}% [5] coauthors
% {Multilevel and Higher-Order Approximations for Stochastic Processes, Random Fields and PDEs}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{17:00}{17:30}{Lecture Hall 4}}% [7] time slot
% {2022}% [8] talk id
% {2020}% [9] session id
%We present a subordination approach to generate Lévy-type discontinuous random fields on a higher dimensional spatial parameter domain. Theoretical results on the pointwise distribution, the covariance structure and the numerical approximation of these random fields are discussed. Further, we consider elliptic partial differential equations (PDEs) where the constructed fields appear in the diffusion coefficient of the equation and present numerical examples for the approximation of the solution to the corresponding random PDE using finite element methods.
%\end{talk}
%
%\begin{talk}
% {Sharp $L^1$-approximation of the log-Heston SDE by Euler-type methods}% [1] talk title
% {Annalena Mickel}% [2] speaker name
% {University of Mannheim}% [3] affiliations
% {amickel@mail.uni-mannheim.de}% [4] email
% {Andreas Neuenkirch}% [5] coauthors
% {Stochastic Computation and Complexity: Quadrature for SDEs and SPDEs, Stochastic Optimization, Neural Networks}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{16:30}{17:00}{STC 1012}}% [7] time slot
% {2235}% [8] talk id
% {2230}% [9] session id
%We study the $L^1$-approximation of the log-Heston SDE
%\begin{equation*}
%	\begin{aligned}
%		dX_t &= \left(\mu-\frac12 V_t\right) dt + \sqrt{V_t} \left(\rho d W_t + \sqrt{1-\rho^2} d B_t\right), \\
%		dV_t &= \kappa (\theta-V_t) dt + \sigma \sqrt{V_t} dW_t, \label{hes-log}
%	\end{aligned}\qquad t\in[0,T],
%\end{equation*}
%at discrete time points by equidistant explicit Euler-type methods. We establish the convergence order $1/2-\varepsilon$ for $\varepsilon>0$ arbitrarily small, if the Feller index $\frac{2\kappa\theta}{\sigma^2}$ of the underlying CIR process is larger than 1. Moreover, we discuss the case of a Feller index smaller than 1 and illustrate our findings by several numerical examples. Finally, we give an outlook on the generalization of our results.
%\end{talk}
%
%\begin{talk}
% {Constructing lattice-based algorithms for multivariate function approximation with a composite number of points}% [1] talk title
% {Weiwen Mo}% [2] speaker name
% {KU Leuven}% [3] affiliations
% {weiwen.mo@kuleuven.be}% [4] email
% {Frances Y.~Kuo, Dirk Nuyens}% [5] coauthors
% {Approximation from Random Data}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{16:30}{17:00}{Lecture Hall 3}}% [7] time slot
% {2185}% [8] talk id
% {2180}% [9] session id
%Rank-$1$ lattice rules, a main family of QMC rules, are characterised by generating vectors,
% and the component-by-component (CBC) construction is an efficient way to construct the generating vector.
%In this talk, we introduce some new results in approximating multivariate
%one-periodic functions using function values at
% rank-$1$ lattice points. The number of points is not limited to a prime number as in currently available literature, but can take any composite value.
% One benefit of the generalisation to the general number of points used in approximation is that allow embedded lattice sequences in applications. The new results cannot be trivially generalised from existing results for prime number and a new proof technique is required.
% With some modifications, the search criterion in the CBC construction under $L_2$ norm can also be applied to $L_{\infty}$ norm, which allows fast CBC implementations.
%\end{talk}
%
%\begin{talk}
% {Importance sampling methods for McKean-Vlasov type stochastic differential equations}% [1] talk title
% {Shyam Mohan}% [2] speaker name
% {RWTH Aachen University}% [3] affiliations
% {s.mohan@rwth-aachen.de}% [4] email
% {Nadhir Ben Rached, Abdul-Lateef Haji-Ali, Ra\'ul Tempone}% [5] coauthors
% {Variance Reduction Techniques for Rare Events}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{17:00}{17:30}{Lecture Hall 5}}% [7] time slot
% {2042}% [8] talk id
% {2040}% [9] session id
%We are interested in Monte Carlo methods for estimating probabilities of rare events associated with solutions to the McKean-Vlasov stochastic differential equation (MV-SDE), whose drift and diffusion coefficients depend on the law of the solution itself. The MV-SDE is approximated using the stochastic N-particle interacting system, which is a set of N coupled stochastic differential equations. Importance sampling is used to reduce high variance in Monte Carlo estimators of rare event probabilities. Optimal change of measure is methodically derived from variance minimization, yielding an N-dimensional partial differential control equation which is cumbersome to solve. This problem is circumvented by using the decoupling approach, introduced in [1], resulting in a lower dimensional control PDE. The decoupling approach necessitates the use of a double loop Monte Carlo estimator. In this context, we formulate an adaptive double loop Monte Carlo method for estimating rare event probabilities. Significant variance reduction is observed and the computational runtime for estimating rare event probabilities up to a given relative tolerance, $TOL$, is reduced by multiple orders, when compared to standard Monte Carlo estimators. We also formulate a novel multilevel double loop Monte Carlo (MLDLMC) method combined with importance sampling, to estimate rare events in the MV-SDE context. This reduces the order of optimal work complexity from O($TOL^{-4}$) to O($TOL^{-3}$). Our numerical experiments are carried out on the Kuramoto model from statistical physics, which models a system of coupled oscillators.
%
%\medskip
%
%[1] Greig Smith, Goncalo dos Reis, Peter Tankov: \textit{Importance Sampling for McKean-Vlasov SDEs}. arXiv preprint arXiv:1803.09320, 2018
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Benchmark of active learning methods for structural reliability analysis}% [1] talk title
% {Maliki Moustapha}% [2] speaker name
% {ETH Z\"{u}rich}% [3] affiliations
% {moustapha@ibk.baug.ethz.ch}% [4] email
% {S. Marelli, B. Sudret}% [5] coauthors
% {Approximate Models for Rare Event Simulation and Uncertainty Quantification}% [6] Special session title
% {\timeslot{Wednesday, July 20, 2022}{11:30}{12:00}{Lecture Hall 5}}% [7] time slot
% {2083}% [8] talk id
% {2080}% [9] session id
%Structural reliability analysis aims at assessing the safety of structures which often operate under
%uncertain conditions. While simulation methods have been traditionally used to accurately estimate the failure probability of the structure, they are computationally inefficient. Surrogate-based methods have been introduced as an alternative in the past decade. They consist in building a cheaper-to-evaluate proxy of the original limit-state function which is then used within a reliability estimation algorithm. Active learning pushes this concept further by constraining the surrogate limit-state function to be accurate only in some regions of interest and hence reducing the computational cost. A learning function is generally used to find such regions of interest and enrich the design of experiments (used to build the surrogate) adaptively.
%
%In this contribution, we first carry out a survey of recent active learning reliability methods and identify an underlying and recurring scheme. We specifically show that most of the proposed methods can fit under a consistent framework, which can be defined using four ingredients: i. a surrogate model, ii. a reliability estimation algorithm, iii. a learning function and iv. a stopping criterion. By combining non-intrusively methods selected within each of these ingredients, most of the existing active learning methods can be reconstructed.
%
%On this basis, we constructed 39 active learning strategies and performed an extensive benchmark considering a set of 20 selected reliability problems. This lead to a total of circa 12,000 problems solved. The results were analysed to identify patterns in the performance and generalization capability of different methods. Then they were synthetized into a set of recommendations for practitioners. Finally, this benchmark has allowed us to highlight the importance of surrogate models, which should be used to fully harness the potential of sophisticated reliability estimation algorithms.
%
%
%\medskip
%
%\textbf{References:} \\
%Moustapha, M., S. Marelli and B. Sudret (2022). Active learning for structural reliability: Survey, general framework and benchmark. Structural Safety, 96, pp. 102174.
%\end{talk}
%
%\begin{talk}
% {Achieving efficiency in black-box simulation of distribution tails with self-structuring importance samplers}% [1] talk title
% {Karthyek Murthy}% [2] speaker name
% {Singapore University of Technology and Design}% [3] affiliations
% {karthyek_murthy@sutd.edu.sg}% [4] email
% {Anand Deo}% [5] coauthors
% {Variance Reduction Techniques for Rare Events}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{18:00}{18:30}{Lecture Hall 5}}% [7] time slot
% {2044}% [8] talk id
% {2040}% [9] session id
%Motivated by the increasing adoption of models which utilize contextual information in risk management and decision-making, this paper presents a novel Importance Sampling (IS) scheme for measuring distribution tails of objectives modeled with enabling tools such as feature-based decision rules, mixed integer linear programs, deep neural networks, etc. Conventional efficient IS approaches suffer from feasibility and scalability concerns due to the need to intricately tailor the sampler to the underlying probability distribution and the objective. This challenge is overcome in the proposed black-box scheme by automating the selection of an effective IS distribution with a transformation that implicitly learns and replicates the concentration properties observed in less rare samples. This novel approach is guided by a large deviations principle that brings out the phenomenon of self-similarity of optimal IS distributions. The proposed sampler is the first to attain asymptotically optimal variance reduction across a spectrum of multivariate distributions despite being oblivious to the underlying structure. The large deviations principle additionally results in new distribution tail asymptotics capable of yielding operational insights. The applicability is illustrated by considering contextual routing and portfolio credit risk models informed by neural networks as examples.
%\end{talk}
%
%\begin{talk}
% {Exact simulation of multidimensional reflected Brownian motion}% [1] talk title
% {Karthyek Murthy}% [2] speaker name
% {Singapore University of Technology and Design}% [3] affiliations
% {karthyek_murthy@sutd.edu.sg}% [4] email
% {Jos\'{e} Blanchet}% [5] coauthors
% {Recent Advances in Unbiased Estimation Techniques}% [6] Special session title
% {\timeslot{Wednesday, July 20, 2022}{11:00}{11:30}{Lecture Hall 4}}% [7] time slot
% {2122}% [8] talk id
% {2120}% [9] session id
%We present an exact simulation method for multidimensional reflected Brownian motion (RBM). Exact simulation in this setting is challenging because of the presence of correlated local-time-like terms in the definition of RBM. We apply recently developed so-called $\varepsilon$-strong simulation techniques (also known as Tolerance-Enforced Simulation) which allow us to provide a piece-wise linear approximation to RBM with $\varepsilon$ (deterministic) error in uniform norm. A novel conditional acceptance / rejection step is then used to eliminate the error. In particular, we condition on a suitably designed information structure so that a feasible proposal distribution can be applied. If time permits, we present additional extensions.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Optimal approximation of stochastic volatility models at a single point}% [1] talk title
% {Andreas Neuenkirch}% [2] speaker name
% {University of Mannheim}% [3] affiliations
% {neuenkirch@math.uni-mannheim.de}% [4] email
% {Annalena Mickel}% [5] coauthors
% {Stochastic Computation and Complexity: Approximation of SDEs with Non-Standard Coefficients}% [6] Special session title
% {\timeslot{Wednesday, July 20, 2022}{10:30}{11:00}{STC 1012}}% [7] time slot
% {2291}% [8] talk id
% {2290}% [9] session id
%We study the strong approximation of the stochastic volatility model
%	\begin{equation} \label{gen}
%		\begin{aligned}
%			dX_t &= \big(r-\tfrac{1}{2}f^2\left(V_t\right) \big) dt + f\left(V_t\right) \big(\rho dW_t + \sqrt{1-\rho^2} dB_t \big), \\
%			dV_t &= b \left(V_t \right) dt + \sigma\left(V_t\right) dW_t,
%		\end{aligned}\qquad t\in[0,T],
%	\end{equation}
%	where $V=(V_t)_{t\in [0,T]}$ takes values in an open set $D \subseteq \mathbb{R}$, $f,b,\sigma: D \rightarrow \mathbb{R}$ are appropriate functions, $\rho \in [-1,1]$, $ r\in \mathbb{R}$ and $W=(W_t)_{t \in [0,T]}$, $B=(B_t)_{t \in [0,T]}$ are independent Brownian motions.
%The initial values of SDE \eqref{gen} are assumed to be deterministic, i.e. $X_0=x_0 \in \mathbb{R}$, $V_0=v_0\in D$.
%
%
%	We analyze the minimal $L^2$-error for the approximation of $X_T$ that can be obtained by arbitrary methods that use $N$ evaluations of each Brownian motion, that is
%
%	\begin{displaymath}
%		e(N)\, = \, \inf_{(s_i,t_i)_{i=1, \ldots,N} \in \Pi(N)} \, \, \inf_{u \in \mathcal{U}(N)}	\quad \left[ \mathbb{E} \big| u( W_{s_1},W_{s_2}, \ldots, W_{s_N}, B_{t_1},B_{t_2}, \ldots, B_{t_N})-X_T \big|^2\right]^{1/2},
%	\end{displaymath}
%	where 	$\mathcal{U}(N)$ is the set of measurable functions $u: \mathbb{R}^{2N} \rightarrow \mathbb{R}$ and
%	$$ \Pi(N)= \left \{(s_i,t_i)_{i=1, \ldots,N}: \, \, (s_i,t_i) \in [0,T]^2, i=1, \ldots, N, \, s_N=t_N=T \right\}.$$
%	Under mild assumptions on SDE \eqref{gen} we show that
%	\begin{equation} \label{low-bound-proof}
%		\liminf_{N\rightarrow \infty} \, \sqrt{N} \, e(N) \geq \sqrt{\frac{1-\rho^2}{6}} \int_{0}^{T} \big[ \mathbb{E}(f'\sigma)^2(V_{t})\big]^{1/2}dt.
%	\end{equation}
%We establish also under suitable assumptions the matching upper bound (up to the factor $\sqrt{3/2} \approx 1.2247\ldots $)
%	\begin{equation} \label{up-bound-proof}
%		\limsup_{N\rightarrow \infty} \, \sqrt{N} \, e(N) \leq \sqrt{\frac{1-\rho^2}{4}}
%		\int_{0}^{T} \big[ \mathbb{E}(f'\sigma)^2(V_{t})\big]^{1/2}dt.
%	\end{equation}
%
%	Since the coefficients of SDE (1) are in particular not required to be globally Lipschitz continuous, these results extend the classical results of Clark and Cameron (1980) and M\"uller-Gronbach (2002).
%
%	The prototype example for SDE $\eqref{gen}$ is the generalized Heston model. Here
%	\eqref{low-bound-proof} and \eqref{up-bound-proof} hold for the CEV process as volatility process $V$ or (under additional assumptions on the Feller index) for the CIR process, respectively, as volatility process.
%\end{talk}
%
%\begin{talk}
% {An adaptive algorithm for integration on $\mathbb{R}^d$ using lattice rules}% [1] talk title
% {Dirk Nuyens}% [2] speaker name
% {KU Leuven}% [3] affiliations
% {dirk.nuyens@kuleuven.be}% [4] email
% {Philippe Blondeel, Yuya Suzuki}% [5] coauthors
% {Algorithmic Advancements in MCQMC Software}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{10:30}{11:00}{Lecture Hall 5}}% [7] time slot
% {2241}% [8] talk id
% {2240}% [9] session id
%In a recent result [1] we developed and analysed an
%algorithm that uses scaled lattice rules to
%approximate integrals $\int_{\mathbb{R}^d} f(\boldsymbol{x}) \,
%\mathrm{d}\boldsymbol{x}$.
%The convergence rate depends on the non-periodicity of the integrand
% function towards increasing boxes. Depending on the decay of the
% function and its partial mixed derivatives we can achieve a
% convergence of $O(n^{-\alpha+\epsilon})$, for $\epsilon > 0$ where
% $\alpha \in \mathbb{N}$ is the dominating mixed smoothness of $f$, by using
% a lattice sequence. For each number of points $n$ we calculate the
% appropriate box $[-a(n),a(n)]^d$ with $a(n)$ governed by the decay
% properties of the integrand function.
%
% In the analysis we balance three contributions to the error: the
% truncation error, the projection error and the lattice rule error of
% the projection.
% In the practical algorithm we need to balance two terms: the
% truncation error and the lattice rule error of the original
% non-periodic function.
% We introduce an adaptive algorithm which estimates these errors and
% then balances them.
%
%\medskip
%
%\begin{itemize}
%\item[{[1]}] D.\ Nuyens, Y.\ Suzuki. Scaled lattice rules for integration on
%$\mathbb{R}^d$ achieving higher-order convergence with error analysis in
%terms of orthogonal projections onto periodic spaces.
%\url{https://arxiv.org/abs/2108.12639}, 2021.
%\end{itemize}
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Construction methods for rank-1 lattice rules and polynomial lattice rules}% [1] talk title
% {Onyekachi Osisiogu}% [2] speaker name
% {Austrian Academy of Sciences}% [3] affiliations
% {onyekachi.osisiogu@oeaw.ac.at}% [4] email
% {Adrian Ebert, Peter Kritzer, Dirk Nuyens, Tetiana Stepaniuk}% [5] coauthors
% {}% [6] special session
% {\timeslot{Wednesday, July 20, 2022}{14:00}{14:30}{Lecture Hall 6}}% [7] time slot
% {4561}% [8] talk id
% {4560}% [9] session id
%We develop efficient algorithms for constructing point sets of high-quality quasi-Monte Carlo (QMC) methods which can be used for approximating high-dimensional integrals of multivariate functions. In particular, we study the construction of rank-1 lattice rules and polynomial lattice rules, where they are both specified by a generating vector for numerical integration in weighted function spaces such as Korobov and Walsh spaces. These construction schemes generate QMC point sets that achieve almost optimal error convergence rates in the respective function spaces. We show that the obtained error estimates become independent of the dimension under certain conditions on the weights, which are incorporated in the definitions of the considered function spaces. Consequently, the integration problem becomes tractable. Furthermore, we derive fast implementations of the construction algorithms and confirm our theoretical findings with numerical results and experiments.
%
%
%\medskip
%[1] A. Ebert, P. Kritzer, O. Osisiogu, T. Stepaniuk. Construction of good polynomial lattice rules in weighted Walsh spaces by an alternative component-by-component construction. Mathematics and Computers in Simulation, 192(2022), pp. 399-419.
%
%[2] A. Ebert, P. Kritzer, O. Osisiogu, T. Stepaniuk. Component-by-component digit-by-digit construction of good polynomial lattice rules in weighted Walsh Spaces. Constructive Approximation, (2021), pp. 1-45.
%
%[3] A. Ebert, P. Kritzer, D. Nuyens, O. Osisiogu. Digit-by-digit and component-by-component construction of lattice rules for periodic functions with unknown smoothness. Journal of Complexity, 66(2021), 101555.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {NuZZ: numerical Zig-Zag for general models}% [1] talk title
% {Filippo Pagani}% [2] speaker name
% {University of Cambridge}% [3] affiliations
% {filippo.pagani@mrc-bsu.cam.ac.uk}% [4] email
% {Augustin Chevallier, Sam Power, Thomas House, Simon Cotter}% [5] coauthors
% {}% [6] special session
% {\timeslot{Wednesday, July 20, 2022}{14:00}{14:30}{Lecture Hall 4}}% [7] time slot
% {4331}% [8] talk id
% {4330}% [9] session id
%Markov chain Monte Carlo (MCMC) is a key algorithm in computational statistics, and as datasets grow larger and models grow more complex, many popular MCMC algorithms become too computationally expensive to be practical. Recent progress has been made on this problem through development of MCMC algorithms based on Piecewise Deterministic Markov Processes (PDMPs), irreversible processes that can be engineered to converge at a rate which is independent of the size of data. While there has understandably been a surge of theoretical studies following these results, PDMPs have so far only been implemented for models where certain gradients can be bounded, which is not possible in many statistical contexts. Focusing on the Zig-Zag process, we present the Numerical Zig-Zag (NuZZ) algorithm, which is applicable to general statistical models without the need for bounds on the gradient of the log posterior. This allows us to perform numerical experiments on: (i) how the Zig-Zag dynamics behaves on some test problems with common challenging features; and (ii) how the error between the target and sampled distributions evolves as a function of computational effort for different MCMC algorithms including NuZZ. Moreover, due to the specifics of the NuZZ algorithms, we are able to give an explicit bound on the Wasserstein distance between the exact posterior and its numerically perturbed counterpart in terms of the user-specified numerical tolerances of NuZZ.
%\end{talk}
%
%\begin{talk}
% {Super-polynomial accuracy of median-of-means}% [1] talk title
% {Art B.~Owen}% [2] speaker name
% {Stanford University}% [3] affiliations
% {owen@stanford.edu}% [4] email
% {Zexin Pan}% [5] coauthors
% {Quasi-Monte Carlo Methods of High Order and Beyond}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{16:30}{17:00}{Lecture Hall 6}}% [7] time slot
% {2155}% [8] talk id
% {2150}% [9] session id
%Digital net is an important class of Quasi-Monte Carlo methods used for numerical integration. In the talk, I am going to show digital net randomized by linear scrambling and digital shift exhibits surprising concentration behavior. Taking the median of several digital net averages can exclude outliers and boost the convergence rate from cubic to super-polynomial when the integrand is smooth. The proof is an interesting application of the Hardy-Ramanujan asymptotic formula for partition of integers.
%\end{talk}
%
%
%
%\begin{talk}
% {Bounds on Wasserstein distances using independent samples}% [1] talk title
% {Tam\'as Papp}% [2] speaker name
% {Lancaster University}% [3] affiliations
% {t.papp@lancaster.ac.uk}% [4] email
% {Chris Sherlock}% [5] coauthors
% {}% [6] special session
% {\timeslot{Wednesday, July 20, 2022}{14:00}{14:30}{STC 1012}}% [7] time slot
% {4131}% [8] talk id
% {4130}% [9] session id
%Given independent samples from two distributions, the Wasserstein distance between the samples provides a natural conservative plug-in estimator of the distance between the distributions. When these distributions are similar, the usefulness of this estimator is severely limited by its bias, which does not decay to zero with the true Wasserstein distance. We propose a linear combination of plug-in estimators for the squared 2-Wasserstein distance that reduces the bias and decays to zero with the true distance. The new estimator remains conservative provided one distribution is appropriately overdispersed with respect the other, and is unbiased when the distributions are equal. We apply it to approximately bound from above the 2-Wasserstein distance between the target and current distribution in Markov chain Monte Carlo, running multiple identically distributed chains which start, and remain, overdispersed with respect to the target. When the chains have converged, the bound asymptotes at zero in expectation. Simulations show our bound consistently outperforming the current state-of-the-art 2-Wasserstein bound for MCMC algorithms, obtaining mixing time bounds up to an order of magnitude tighter.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Extremal distributions of discrepancy functions}% [1] talk title
% {Markus Passenbrunner}% [2] speaker name
% {JKU Linz}% [3] affiliations
% {markus.passenbrunner@jku.at}% [4] email
% {Ralph Kritzinger}% [5] coauthors
% {}% [6] special session
% {\timeslot{Monday, July 18, 2022}{15:30}{16:00}{Lecture Hall 5}}% [7] time slot
% {4411}% [8] talk id
% {4410}% [9] session id
%The irregularities of a distribution of $N$ points in the unit interval are often measured with various notions of discrepancy.
%The discrepancy function can be defined with respect to intervals of the form $[0,t)\subset [0,1)$ or arbitrary subintervals of the unit interval.In the former case, it is a well known fact in discrepancy theory that the $N$-element point set in the unit interval with the lowest $L_2$ or
%$L_{\infty}$ norm of the discrepancy function is the centered regular
%grid
%$$ \Gamma_N:=\left\{\frac{2n+1}{2N}: n=0,1,\dots,N-1\right\}. $$
%We show a stronger result on the distribution of discrepancy functions of point sets in $[0,1]$, which
%basically says that the distribution of the discrepancy function of $\Gamma_N$ is in some sense minimal among all $N$-element
%point sets. As a consequence, we can extend the above result to
%rearrangement-invariant norms,
%including $L_p$, Orlicz and Lorentz norms.
%We study the same problem also for the discrepancy notions with respect to arbitrary subintervals. In this case, we will observe that
%we have to deal with integrals of convolutions of functions. To this
%end, we present a general upper bound on such expressions, which
%might be of independent interest as well.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Theoretical insights on a class of control based particle filters and their approximations}% [1] talk title
% {Sahani Pathiraja}% [2] speaker name
% {University of New South Wales}% [3] affiliations
% {s.pathiraja@unsw.edu.au}% [4] email
% {Sebastian Reich, Wilhelm Stannat, Jana de Wiljes}% [5] coauthors
% {Advanced Particle Methods for Bayesian Inference}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{11:00}{11:30}{Lecture Hall 4}}% [7] time slot
% {2092}% [8] talk id
% {2090}% [9] session id
%In particle based filtering, ensemble Kalman type methods have in large part been the method of choice for high dimensional non-linear applications due to their desirable stability properties. This is despite the fact that they are known to be sub-optimal as they are not consistent with Bayes theorem even as the ensemble size goes to infinity. Over the last few decades, a range of so-called particle flow or control type filters have been developed which at least theoretically show strong potential over importance sampling based techniques for providing consistent estimates in high dimensional nonlinear applications.
%
%We develop a unifying framework through which to derive and understand the links between these filters, with the aim of elucidating how alternative formulations with desirable computational properties could be designed. We show how different assumptions on the form of the control or ``gain function'' lead to different filters proposed in the literature. Recent work relating to accuracy, mean field limits and well-posedness of a diffusion map based approximation and its connections to other particle based methods will also be discussed.
%\end{talk}
%
%
%\begin{talk}
% {Generator matrices by solving integer linear programs}% [1] talk title
% {Lo\"is Paulin}% [2] speaker name
% {Univ Lyon, CNRS, LIRIS}% [3] affiliations
% {lois.paulin@liris.cnrs.fr}% [4] email
% {David Coeurjoly, Nicolas Bonneel, Jean-Claude Iehl, Alexander Keller, Victor Ostromoukhov}% [5] coauthors
% {Developments in and Applications of MCQMC Software}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{12:00}{12:30}{Lecture Hall 5}}% [7] time slot
% {2174}% [8] talk id
% {2170}% [9] session id
%In quasi Monte-Carlo methods, generating high-dimensional low discrepancy sequences by generator matrices is a popular and efficient approach.
%The low discrepancy is often enforced by the $(t,m,s)$-net property.
%Often, numerical problems have some intrinsic structure that benefits from a specific profile of discrepancy imposed on subsets of dimensions.
%Finding generator matrices that match such a profile is a historically hard problem.
%Many low discrepancy sequences, such as Sobol’, Halton, and others, use specific matrix construction rules to achieve provably strong properties.
%However, these construction rules highly constrain which sort of matrices can be constructed and thus hinder efforts to match a targeted profile.
%The work by Joe and Kuo on optimizing the uniformity of all pairs of dimensions shows that these matrices cannot reach a satisfying 2D uniformity.Recently methods for optimizing general matrices have been devised, however they often rely on random generation and filtering of generator matrices.
%This approach fails when the constraints are sufficiently restrictive so that only few matrices among the search space can satisfy them.
%We devise a greedy algorithm allowing us to translate desirable net properties into linear constraints on the generator matrix entries.
%We then use these constraints in an integer linear program solver in order to directly construct matrices satisfying a desired set of net properties.
%We show that our method finds matrices in difficult settings, thus offering low discrepancy sequences beyond the limitations of classic matrix constructions.
%Some sets of constraints are provably infeasible in lower prime basis such as 2.
%Our method works in higher prime bases, too, offering another degree of freedom to satisfy a specific set of projective net properties.
%\end{talk}
%
%\begin{talk}
% {Strong invariance principles for ergodic Markov processes}% [1] talk title
% {Ardjen Pengel}% [2] speaker name
% {Delft University of Technology}% [3] affiliations
% {a.l.pengel@tudelft.nl}% [4] email
% {Joris Bierkens}% [5] coauthors
% {}% [6] special session
% {\timeslot{Tuesday, July 19, 2022}{15:30}{16:00}{Lecture Hall 6}}% [7] time slot
% {4541}% [8] talk id
% {4540}% [9] session id
%Strong invariance principles describe the error term of a Brownian approximation of the partial sums of a stochastic process. While these strong approximation results have many applications, the results for continuous-time settings have been limited. In this paper, we obtain strong invariance principles for a broad class of ergodic Markov processes. The main results rely on ergodicity requirements and an application of Nummelin splitting for continuous-time processes. Strong invariance principles provide a unified framework for analysing commonly used estimators of the asymptotic variance in settings with a dependence structure. We demonstrate how this can be used to analyse the batch means method for simulation output of Piecewise Deterministic Monte Carlo samplers.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Adaptive methods for numerical approximation: an asymptotic analysis}% [1] talk title
% {Leszek Plaskota}% [2] speaker name
% {University of Warsaw}% [3] affiliations
% {leszekp@mimuw.edu.pl}% [4] email
% {Pawe{\l} Przyby{\l}owicz, {\L}ukasz St{\c e}pie{\'n}}% [5] coauthors
% {}% [6] special session
% {\timeslot{Wednesday, July 20, 2022}{14:30}{15:00}{Lecture Hall 6}}% [7] time slot
% {4562}% [8] talk id
% {4560}% [9] session id
%The crude Monte Carlo algorithm approximates the integral $$S(f)=\int_a^b f(x)\,\mathrm dx$$
%with expected error (deviation) $\sigma(f)N^{-1/2},$ where $\sigma(f)^2=S(f^2)-(Sf)^2$ is
%the variance of $f$ and $N$ is the number of function evaluations. If $f\in C^r$ then special
%variance reduction techniques can lower this error to the level $N^{-(r+1/2)};$ however,
%the asymptotic constants crucially depend on the chosen technique. In this talk, we consider
%methods of the form $$\overline M_N(f)=S(L_mf)+M_n(f-L_mf),$$ where $L_m$ is the piecewise
%polynomial interpolation of $f$ of degree $r-1$ using a partition of the interval $[a,b]$ into $m$
%subintervals, $M_n$ is a Monte Carlo type algorithm using $n$ samples of $f,$ and $N$ is the total
%number of function evaluations used. We derive asymptotic error formulas for the methods
%$\overline M_N$ that use nonadaptive as well as adaptive partitions. Although the convergence rate
%$N^{-(r+1/2)}$ cannot be beaten, the asymptotic constants make a huge difference, especially for
%functions $f$ with dramatically changing $r$th derivative. For example, for
%$\int_0^1(x+d)^{-1}\mathrm dx$ and $r=4$ the best adaptive methods overcome the nonadaptive
%ones roughly $10^{12}$ times if $d=10^{-4},$ and $10^{29}$ times if $d=10^{-8}.$
%In addition, the adaptive methods are easily implementable and can be well used for
%automatic integration.
%
%We believe that the obtained results can be generalized to multivariate integration.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Maximum order complexity for some automatic and morphic sequences along polynomial values} % [1] talk title
% {Pierre Popoli}% [2] speaker name
% {Universit\'{e} de Lorraine, IECL}% [3] affiliations
% {pierre.popoli@univ-lorraine.fr}% [4] email
% {Damien Jamet, Thomas Stoll}% [5] coauthors
% {Pseudo-Random Number Generation}% [6] special session
% {\timeslot{Friday, July 22, 2022}{10:00}{10:30}{Lecture Hall 5}}% [7] time slot
% {2223}% [8] talk id
% {2220}% [9] session id
%Automatic sequences are not pseudo-random sequences since both their subword complexity and their expansion complexity are small, and their correlation measures of order 2 is large. These sequences are indeed highly predictable despite having a large maximum order complexity. However, recent results show that polynomial subsequences of automatic sequences, such as the Thue--Morse sequence, are better candidates for pseudo-random sequences. A natural generalization of automatic sequences are morphic sequences, given by a fixed point of a prolongeable morphism that is not necessarily uniform. In this talk, I will present my results on lowers bounds for the maximum order complexity of the Thue--Morse sequence, the Rudin--Shapiro sequence and the Zeckendorf sequence which is based on the sum of digits function in Fibonacci base. Theses are examples of automatic, respectively, morphic sequences.
%
%\medskip
%
%\begin{enumerate}
%\item Michael Drmota, Christian Mauduit, and Jo\"{e}l Rivat, \textit{Normality along squares}, J. Eur. Math. Soc. (JEMS) \textbf{21} (2019), no. 2, 507–548.
%\item Damien Jamet, Pierre Popoli, and Thomas Stoll, \textit{Maximum order complexity of the sum of digits function in zeckendorf base and polynomial subsequences}, Cryptography and Communications \textbf{13} (2021).
%\item L\'{a}szl\'{o} M\'{e}rai and Arne Winterhof, \textit{Pseudorandom sequences derived from automatic sequences}, 2021, \url{https://arxiv.org/abs/2105.03086}.
%\item Pierre Popoli, \textit{On the maximum order complexity of Thue-Morse and Rudin- Shapiro sequences along polynomial values}, Uniform Distribution Theory \textbf{15} (2020), no. 2, 9–22.
%\item Zhimin Sun and Arne Winterhof, \textit{On the maximum order complexity of sub- sequences of the Thue-Morse and Rudin-Shapiro sequence along squares}, Int. J. Comput. Math. Comput. Syst. Theory \textbf{4} (2019), no. 1, 30–36.
%\end{enumerate}
%\end{talk}
%
%\newpage
%
%
%\begin{talk}
% {Operator norms of random matrices with structured variance profile} % [1] talk title
% {Joscha Prochno}% [2] speaker name
% {University of Passau}% [3] affiliations
% {joscha.prochno@uni-passau.de}% [4] email
% {}% [5] coauthors
% {Approximation from Random Data}% [6] special session
% {\timeslot{Thursday, July 21, 2022}{12:00}{12:30}{Lecture Hall 3}}% [7] time slot
% {2184}% [8] talk id
% {2180}% [9] session id
%Random matrices play a fundamental role in several areas of mathematics and understanding their spectral statistics has attracted considerable attention. Gaussian random matrices have played a fundamental role ever since. In this talk we present some results on the order of the expected operator norm of Gaussian random matrices with non-trivial variance profile, where the random Gaussian operator acts between finite-dimensional $\ell_p$ spaces. The goal is to understand the influence of the variance structure on the magnitude of expected norm and we present results which are optimal up to logarithmic factors in the dimension. The case of the spectral norm has been resolved by Lata{\l}a, van Handel, and Youssef [Inventiones mathematicae 214(3) (2018)].
%\end{talk}
%
%%\newpage
%
%\begin{talk}
% {Randomized Milstein algorithm for pointwise approximation of SDEs under inexact information}% [1] talk title
% {Pawe\l{} Przyby\l{}owicz}% [2] speaker name
% {AGH University of Science and Technology}% [3] affiliations
% {pprzybyl@agh.edu.pl}% [4] email
% {Pawe\l{} Morkisz}% [5] coauthors
% {Stochastic Computation and Complexity: High Dimensional Approximation, Integration, and PDEs}% [6] special session
% {\timeslot{Tuesday, July 19, 2022}{17:00}{17:30}{STC 1012}}% [7] time slot
% {2166}% [8] talk id
% {2160}% [9] session id
%We deal with pointwise approximation of solutions of scalar stochastic differential equations in the presence of informational noise about underlying drift and diffusion coefficients. We define randomized and derivative-free version of Milstein algorithm $\mathcal{\bar A}^{df-RM}_n$, and investigate its error. We also study lower bounds on the worst-case error of an arbitrary algorithm. It turns out that in some case the scheme $\mathcal{\bar A}^{df-RM}_n$ is the optimal one. Finally, in order to test the algorithm $\mathcal{\bar A}^{df-RM}_n$ in practice, we report performed numerical experiments.
%
%\medskip
%
%\begin{enumerate}
%	\item[[1\kern-6pt]] P. Morkisz, P. Przyby\l{}owicz.
%\newblock {\em Randomized derivative-free Milstein algorithm for efficient approximation of solutions of SDEs under noisy information}.
%\newblock Journal of Computational and Applied Mathematics, \textbf{383} (2021), 1-22.
%\end{enumerate}
%\end{talk}
%
%
%\begin{talk}
% {Strong and weak approximation of solutions of SDEs under noisy information about coefficients and driving Wiener process}% [1] talk title
% {Pawe\l \ Przyby\l owicz}% [2] speaker name
% {AGH University of Science and Technology}% [3] affiliations
% {pprzybyl@agh.edu.pl}% [4] email
% {Marcin Baranek, Andrzej Ka\l u\.za, Pawe{\l} M. Morkisz, Micha{\l} Sobieraj}% [5] coauthors
% {Stochastic Computation and Complexity: Approximation of SDEs with Non-Standard Coefficients}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{11:30}{12:00}{STC 1012}}% [7] time slot
% {2297}% [8] talk id
% {2290}% [9] session id
%We investigate approximation, in strong and weak sense, of solutions of the following stochastic differential equations (SDEs)
%\begin{equation}
%\label{main_equation}
%	\left\{\begin{array}{ll}
%	\displaystyle{
%	 X(t) = a(t,X(t))dt + b(t,X(t)) dW(t), \ t\in [0,T]},\\
%	X(0)=\eta,
%	\end{array} \right.
%\end{equation}
%where $T >0$, and $W$ is a $m$-dimensional Wiener process. We assume that only standard noisy information about the coefficients $a,b$ and driving Wiener process $W$ is available. In the case of strong approximation, we show the upper bound $O(n^{-\min\{1/2,\varrho\}}+\delta_1+\delta_2+\delta_3)$ on the $L^p(\Omega)$-error for the randomized Euler algorithm, where $n$ is the discretization parameter, $\varrho\in (0,1]$ is the H\"older exponent wrt to the time variable $t$ for $b=b(t,x)$, and $\delta_1,\delta_2,\delta_3$ are precision parameters for $a,b,W$, respectively. We also show some lower bounds. Next, we construct a suitable Monte Carlo algorithm that approximates $\mathbb{E}(F(X(T)))$. In this case we also assume that we have available standard noisy information about the pay-off function $F$. We apply the obtained results to the problem of approximation of solutions of PDEs under noisy information about their coefficients. Results of some numerical experiments performed on GPUs are going to be reported.
%\end{talk}
%
%\newpage
%
%
%
%\begin{talk}
% {On the Fourier sign uncertainty principle}% [1] talk title
% {Emily Quesada-Herrera}% [2] speaker name
% {Graz University of Technology}% [3] affiliations
% {quesada@math.tugraz.at}% [4] email
% {Emanuel Carneiro}% [5] coauthors
% {What Did You Expect? Equidistribution in Number Theory}% [6] Special session title
% {\timeslot{Wednesday, July 20, 2022}{12:00}{12:30}{Lecture Hall 3}}% [7] time slot
% {2014}% [8] talk id
% {2010}% [9] session id
%There has been recent progress in studying point distributions via harmonic analysis tools. In 2003, Cohn and Elkies introduced new upper bounds for sphere packings via a Fourier optimization problem. It was solved exactly in the special dimensions 8 and 24, in a recent breakthrough by Viazovska and Cohn, Kumar, Miller, Radchenko and Viazovska. As later pointed out by Cohn and Gonçalves, this is deeply related to the classical topic of Fourier uncertainty, and specifically to an uncertainty principle regarding the signs of a function and its Fourier transform.
%
%We discuss a generalized version of the Fourier sign uncertainty principle in Euclidean space, based on joint work with Emanuel Carneiro.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Higher-order adaptive numerical methods for computing the exit times of stochastic processes}% [1] talk title
% {Sankarasubramanian Ragunathan}% [2] speaker name
% {RWTH Aachen University}% [3] affiliations
% {ragunathan@uq.rwth-aachen.de}% [4] email
% {H{\aa}kon Hoel}% [5] coauthors
% {Multilevel and Higher-Order Approximations for Stochastic Processes, Random Fields and PDEs}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{17:30}{18:00}{Lecture Hall 4}}% [7] time slot
% {2023}% [8] talk id
% {2020}% [9] session id
%The task of computing the time taken by a stochastic process to exit a domain or reach a certain value is of great interest and has applications in the fields of science and finance. In physics, one might be interested in computing the time taken by a particle in a potential well to cross over a potential barrier. In finance, an investor would be interested in knowing the time when the stock/option exceeds a certain threshold value in order to sell the stock/option and maximize profit. Computing the mean exit time of a stochastic process relates to solving a deterministic PDE, but solving the PDE is oftentimes neither feasible analytically nor tractable numerically. So we resort to Monte Carlo techniques using sample paths of the stochastic process in order to estimate the mean exit time. By sampling the trajectories of the stochastic process at discrete times, we run the risk of missing the exit in-between timesteps.
%
%We propose an alternative method to compute the mean exit time of a stochastic process that aims at minimizing the probability of missing the exit by refining the timestep size as the stochastic process gets closer to the boundary. As a consequence, we are able to achieve higher-order convergence rates while keeping the expected computational cost low. In this talk we will explain the structure of our adaptive method and compare its performance to the state of the art by looking at some numerical examples. As our method currently is a single-level Monte Carlo method, we will also discuss the potential of our method when extended to the multilevel Monte Carlo setting.
%\end{talk}
%
%\begin{talk}
% {State and parameter estimation from partial state observations in stochastic reaction networks}% [1] talk title
% {Muruhan Rathinam}% [2] speaker name
% {University of Maryland Baltimore County}% [3] affiliations
% {muruhan@umbc.edu}% [4] email
% {Mingkai Yu}% [5] coauthors
% {Monte Carlo Methods and Variance Reduction Techniques for Stochastic Reaction Networks}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{10:30}{11:00}{Lecture Hall 5}}% [7] time slot
% {2031}% [8] talk id
% {2030}% [9] session id
%We describe new Monte Carlo methods for the accurate and efficient estimation of unobserved states and parameters of a stochastic reaction network based on exact partial state observations. We consider two scenarios, one in which the observations are made continuously in time over a window and the other in which observations are made in snapshots of time. We provide particle filter algorithms for the estimation of the conditional probability distribution of the states and parameters. We provide derivations of our methods as well as as numerical examples that illustrate the applicability of our approach.
%
%\medskip
%
%[1] ``State and parameter estimation from exact partial state observation in stochastic reaction networks'' Muruhan Rathinam and Mingkai Yu,
%J. Chem. Phys. 154, 034103 (2021).
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {On the performance of the Euler-Maruyama scheme for multidimensional SDEs with discontinuous drift coefficient}% [1] talk title
% {Christopher Rauh\"{o}gger}% [2] speaker name
% {University of Passau}% [3] affiliations
% {christopher.rauhoegger@uni-passau.de}% [4] email
% {Thomas M\"{u}ller-Gronbach, Larisa Yaroslavtseva}% [5] coauthors
% {Stochastic Computation and Complexity: Approximation of SDEs with Non-Standard Coefficients}% [6] Special session title
% {\timeslot{Wednesday, July 20, 2022}{12:00}{12:30}{STC 1012}}% [7] time slot
% {2294}% [8] talk id
% {2290}% [9] session id
%We study the performance of the Euler-Maruyama scheme for systems of SDEs with a piecewise Lipschitz drift coefficient and a Lipschitz diffusion coefficient. We show that an $L_{p}$-error rate
%of at least $1/2-$ is achieved, which generalizes a recent result from [2] for scalar SDEs and improves the known $L_2$-error rate of at least $1/4$ from [1] for the multi-dimensional setting.
%
%
%\medskip
%
%
%[1]\,\, Leobacher, G. and Sz\"olgyenyi, M. (2018), {\it Convergence of the Euler-Maruyama method for multidimensional SDEs with discontinuous drift
%	and degenerate diffusion coefficient}, Numerische Mathematik {\bf 138}, 219--239.
%\smallskip
%
%\noindent
%[2]\,\, M\"uller-Gronbach, T. and Yaroslavtseva, L. (2020), {\it On the performance of the Euler–Maruyama scheme for SDEs with discontinuous drift coefficient}, Ann. Inst. H. Poincar\'{e} Probab. Statist. {\bf 56}, 1162--1178.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Multi-fidelity no-U-turn sampling}% [1] talk title
% {Kislaya Ravi}% [2] speaker name
% {Technical University of Munich}% [3] affiliations
% {kislayaravi@tum.de}% [4] email
% {Tobias Neckel, Hans-Joachim Bungartz}% [5] coauthors
% {}% [6] special session.
% {\timeslot{Tuesday, July 19, 2022}{16:00}{16:30}{Lecture Hall 4}}% [7] time slot
% {4322}% [8] talk id
% {4320}% [9] session id
%Many Markov Chain Monte Carlo (MCMC) methods often take many iterations to converge for highly correlated or high-dimensional target density functions. Methods such as Hamiltonian Monte Carlo (HMC) [1] or No-U-Turn Sampling (NUTS) [2] use the first-order derivative of the density function to tackle the aforementioned issues. However, the calculation of the derivative represents a bottleneck for computationally expensive models. We propose to first build a multi-fidelity Gaussian Process (GP)[3, 4, 5] surrogate. The building block of the multi-fidelity surrogate is a hierarchy of models of decreasing approximation error and increasing computational cost. Then the generated multi-fidelity surrogate is used to approximate the derivative. The majority of the computation is assigned to the cheap models thereby reducing the overall computational cost. The derivative from the multi-fidelity method is used to explore the target density function and generate proposals. We select or reject the proposals using the Metropolis Hasting criterion using the highest fidelity model which ensures that the proposed method is ergodic with respect to the highest fidelity density function.
%We apply the proposed method to some test cases and compare it with existing methods.
%% We use the Dual Averaging step size [6] and stop the fictitious time stepping based on No-U-Turn criterion [2].
%
%\medskip
%
%\textbf{References}
%
%\begin{enumerate}
% \item R. Neal. ``Handbook of Markov Chain Monte Carlo'', chapter 5: MCMC Using Hamiltonian Dynamics. CRC Press, 2011.
% \item Hoffman, Matthew D., and Andrew Gelman. ``The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.'' J. Mach. Learn. Res. 15.1 (2014): 1593-1623.
% \item Rasmussen, Carl Edward. ``Gaussian processes in machine learning.'' Summer school on machine learning. Springer, Berlin, Heidelberg, 2003. \item Perdikaris, Paris, et al. ``Nonlinear information fusion algorithms for data-efficient multi-fidelity modelling.'' Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences 473.2198 (2017): 20160751.
% \item Lee, Seungjoon, et al. ``Linking Gaussian process regression with data-driven manifold embeddings for nonlinear data fusion.'' Interface focus 9.3 (2019): 20180083.
%\end{enumerate}
%\end{talk}
%
%\begin{talk}
% {A posteriori error estimates for fully coupled McKean-Vlasov FBSDEs}% [1] talk title
% {Christoph Reisinger}% [2] speaker name
% {University of Oxford}% [3] affiliations
% {christoph.reisinger@maths.ox.ac.uk}% [4] email
% {Wolfgang Stockinger, Yufei Zhang}% [5] coauthors
% {Stochastic Computation and Complexity: Quadrature for SDEs and SPDEs, Stochastic Optimization, Neural Networks}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{17:00}{17:30}{STC 1012}}% [7] time slot
% {2236}% [8] talk id
% {2230}% [9] session id
%McKean-Vlasov forward-backward stochastic differential equations (MV-FBSDEs) with full coupling arise naturally from large population optimization problems. Judging the quality of given numerical solutions for MV-FBSDEs, which usually require Picard iterations and approximations of nested conditional expectations, is typically difficult. This talk proposes an a posteriori error estimator to quantify the $L^2$-approximation error of an arbitrarily generated approximation on a time grid. We establish that the error estimator is equivalent to the global approximation error between the given numerical solution and the solution of a forward Euler discretized MV-FBSDE. A crucial and challenging step in the analysis is the proof of stability of this Euler approximation to the MV-FBSDE, which is of independent interest. We further demonstrate that, for sufficiently fine time grids, the accuracy of numerical solutions for solving the continuous MV-FBSDE can also be measured by the error estimator. In particular, the a posteriori error estimates justify the usage of the Deep BSDE Solver for solving MV-FBSDEs. Numerical experiments on an extended mean field game are presented to illustrate the theoretical results and to demonstrate the practical applicability of the error estimator.
%\end{talk}
%
%\begin{talk}
% {Convergence of a time-stepping scheme to the free boundary in the supercooled Stefan problem}% [1] talk title
% {Christoph Reisinger}% [2] speaker name
% {University of Oxford}% [3] affiliations
% {christoph.reisinger@maths.ox.ac.uk}% [4] email
% {Vadim Kaushansky, Mykhaylo Shkolnikov, Zhuo Qun Song}% [5] coauthors
% {Analysis and Simulation of SDEs in Non-standard Settings}% [6] Special session title
% {\timeslot{Friday, July 22, 2022}{10:00}{10:30}{Lecture Hall 3}}% [7] time slot
% {2193}% [8] talk id
% {2190}% [9] session id
%The supercooled Stefan problem and its variants describe the freezing of a supercooled liquid in physics, as well as the large system limits of systemic risk models in finance and of integrate-and-fire models in neuroscience. Adopting the physics terminology, the supercooled Stefan problem is known to feature a finite-time blow-up of the freezing rate for a wide range of initial temperature distributions in the liquid. Such a blow-up can result in a discontinuity of the liquid-solid boundary. In this paper, we prove that the natural Euler time-stepping scheme applied to a probabilistic formulation of the supercooled Stefan problem converges to the liquid-solid boundary of its physical solution globally in time, in the Skorokhod M1 topology. In the course of the proof, we give an explicit bound on the rate of local convergence for the time-stepping scheme. We also run numerical tests to compare our theoretical results to the practically observed convergence behavior.
%\end{talk}
%
%%\newpage
%
%\begin{talk}
% {Eliminating sharp minima from SGD with truncated heavy-tailed noise}% [1] talk title
% {Chang-Han Rhee}% [2] speaker name
% {Northwestern University}% [3] affiliations
% {chang-han.rhee@northwestern.edu}% [4] email
% {Xingyu Wang, Sewoong Oh}% [5] coauthors
% {}% [6] special session.
% {\timeslot{Monday, July 18, 2022}{16:00}{16:30}{Lecture Hall 6}}% [7] time slot
% {4522}% [8] talk id
% {4520}% [9] session id
%The empirical success of deep learning is often attributed to SGD's mysterious ability to avoid sharp local minima in the loss landscape, as sharp minima are known to lead to poor generalization. Recently, empirical evidence of heavy-tailed gradient noise was reported in many deep learning tasks, and it was shown that SGD can escape sharp local minima under the presence of such heavy-tailed gradient noise, providing a partial solution to the mystery. In this work, we analyze the metastability of a popular variant of SGD where gradients are truncated above a fixed threshold. We show that such SGD achieves a stronger notion of avoiding sharp minima: it can effectively eliminate sharp local minima entirely from its training trajectory. We show this by characterizing the dynamics of truncated SGD driven by heavy-tailed noises. First, we prove that the truncation threshold and width of the attraction field dictate the order of the first exit time from the associated local minimum. Moreover, when the loss landscape satisfies appropriate structural conditions, we prove that, as the learning rate decreases, the dynamics of heavy-tailed truncated SGD closely resemble those of a continuous-time Markov chain that never visits any sharp minima. Real data experiments on deep learning confirm our theoretical prediction that heavy-tailed SGD with gradient clipping finds a flatter local minima and achieves better generalization.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Metropolis adjusted Langevin trajectories: a robust alternative to Hamiltonian Monte Carlo}% [1] talk title
% {Lionel Riou-Durand}% [2] speaker name
% {University of Warwick}% [3] affiliations
% {lionel.riou-durand@warwick.ac.uk}% [4] email
% {Jure Vogrinc}% [5] coauthors
% {Robust Innovations in Gradient-Based MCMC}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{11:30}{12:00}{Lecture Hall 4}}% [7] time slot
% {2273}% [8] talk id
% {2270}% [9] session id
%Hamiltonian Monte Carlo (HMC) is a widely used sampler, known for its efficiency on high dimensional distributions. Yet HMC remains quite sensitive to the choice of integration time. Randomizing the length of Hamiltonian trajectories (RHMC) has been suggested to smooth the Auto-Correlation Functions (ACF), ensuring robustness of tuning. We present the Langevin diffusion as an alternative to control these ACFs by inducing randomness in Hamiltonian trajectories through a continuous refreshment of the velocities. We connect and compare the two processes in terms of quantitative mixing rates for the 2-Wasserstein and $\mathbb{L}_2$ distances. The Langevin diffusion is presented as a limit of Randomised Hamiltonian dynamics achieving the fastest mixing rate for strongly log-concave targets. We introduce a robust alternative to HMC built upon these dynamics, named Metropolis adjusted Langevin trajectories (MALT). Studying the scaling limit of MALT, we obtain optimal tuning guidelines similar to HMC, and recover the same scaling with respect to the dimension without additional assumptions. We illustrate numerically the efficiency of MALT compared to HMC and RHMC.
%\end{talk}
%
%\begin{talk}
% {Equivalence of integration on Gaussian spaces and Hermite spaces}% [1] talk title
% {Klaus Ritter}% [2] speaker name
% {TU Kaiserslautern}% [3] affiliations
% {ritter@mathematik.uni-kl.de}% [4] email
% {Aicke Hinrichs, Michael Gnewuch, Robin R\"u\ss mann}% [5] coauthors
% {}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{16:00}{16:30}{Lecture Hall 3}}% [7] time slot
% {4242}% [8] talk id
% {4240}% [9] session id
%We study integration of functions of
%$d$ variables with respect to the $d$-fold product
%of the standard normal distribution, where
%$d \in \mathbb{N}$ or $d = \infty$.
%The underlying function space is a reproducing kernel Hilbert space
%whose kernel $L_\sigma$ is the tensor product of
%univariate Gaussian kernels with
%shape parameters $\sigma_j>0$, i.e.,
%$L_\sigma(x,y) := \prod_{j=1}^d \exp(-\sigma_j^2 \cdot (x_j-y_j)^2)$.
%For every Gaussian kernel $L_\sigma$ (with square-summable
%shape parameters if $d=\infty$) we determine a Hermite kernel $K_\sigma$
%such that the integration problem
%on the Gaussian space $H(L_\sigma)$ is
%equivalent to the same integration problem on the Hermite space
%$H(K_\sigma)$. More precisely, there is a one-to-one correspondence
%between quadrature formulas on $H(L_\sigma)$ and $H(K_\sigma)$
%such that the worst case errors on the corresponding unit balls
%coincide. The proof is constructive, and a similar
%result, however with a different Hermite kernel, holds for
%$L^2$-approximation.
%\end{talk}
%
%\begin{talk}
% {Bayesian calibration for summary statistics with applications to a cluster dynamics model}% [1] talk title
% {Pieterjan Robbe}% [2] speaker name
% {Sandia National Laboratories}% [3] affiliations
% {pmrobbe@sandia.gov}% [4] email
% {}% [5] coauthors
% {Developments in and Applications of MCQMC Software}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{17:00}{17:30}{Lecture Hall 5}}% [7] time slot
% {2176}% [8] talk id
% {2170}% [9] session id
%We present a Bayesian calibration strategy for problems where observed data summaries are available as measurement values with associated measurement errors, where the latter are represented by error bars. Our method finds a collection of synthetic data sets, such that statistics computed from the pushed forward posterior (i.e., the parameter values after observing the data, propagated through the deterministic model) are consistent with the reported summary statistics. In doing so, the reported measurement errors are reflected in the inferred uncertain parameters. We apply our method to a cluster dynamics model for the prediction of uranium and xenon fission gas diffusivity and oxygen non-stoichiometry in uranium dioxide nuclear fuel. To keep the approach computationally tractable, we replace the cluster dynamics model with a prebuilt polynomial surrogate mode. The observed summary statistics used in our calibration effort are taken from various sources in the literature. We discuss the performance of the algorithm, and investigate how we can introduce weights to account for the different number of measurement values in each experimental data set. We implement our approach in UQTk, a software package developed at Sandia.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Multilevel simulation of hard sphere mixtures}% [1] talk title
% {Paul B.~Rohrbach}% [2] speaker name
% {University of Cambridge}% [3] affiliations
% {pbr28@cam.ac.uk}% [4] email
% {Hideki Kobayashi, Robert Scheichl, Nigel B.~Wilding, Robert L.~Jack}% [5] coauthors
% {}% [6] special session.
% {\timeslot{Thursday, July 21, 2022}{15:30}{16:00}{Lecture Hall 6}}% [7] time slot
% {4571}% [8] talk id
% {4570}% [9] session id
%We present a self-consistent multilevel simulation method to estimate equilibrium properties of multiscale physical systems.
%Inspired by multilevel Markov chain Monte Carlo methods, we use an efficient but inexact coarse-grained approximation as the starting point of a hierarchical method to simulate the exact system of interest.
%We apply this method to highly size-asymmetric binary mixtures of hard spheres, where the scale separation between big and small particles poses a substantial challenge to standard Monte Carlo simulation methods.
%The big particles of this system display interesting collective behaviour, including a de-mixing transition at large size-ratios and high small-particle densities.
%To investigate this system, we first develop a two-level method that enables us to simulate the system up to this transition, providing the first computational evidence of its existence and locating the associated critical point [1].
%Subsequently, we discuss a generalisation of the two-level method that makes use of multiple levels of physical coarse-graining, and apply a three-level version to the binary mixture.
%For this example, we compare the numerical and asymptotic performance of the two- and three-level method.
%We show that taking an intermediate level into account can lower the variance of the method at fixed computational cost.
%
%\medskip
%
%\begin{itemize}
%\item[{[1]}] Kobayashi, H., Rohrbach, P.B., Scheichl, R., Wilding, N.B. and Jack, R.L., 2021. Critical point for demixing of binary hard spheres. Physical Review E, 104(4), p.044603.
%\end{itemize}
%\leavevmode
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {A kernelized consensus-based optimization method}% [1] talk title
% {Tim Roith}% [2] speaker name
% {FAU Erlangen-N\"{u}rnberg}% [3] affiliations
% {tim.roith@fau.de}% [4] email
% {Leon Bungert, Philipp Wacker}% [5] coauthors
% {Advanced Particle Methods for Bayesian Inference}% [6] special session.
% {\timeslot{Thursday, July 21, 2022}{11:30}{12:00}{Lecture Hall 4}}% [7] time slot
% {2093}% [8] talk id
% {2090}% [9] session id
%Consensus-based optimization (CBO) [1] is a derivative-free method for minimizing a function $V:\mathbb{R}^d\to\mathbb{R}$ by evolving an ensemble of particles towards its mean value with respect to the Gibbs measure $\exp(-\beta V)$ where $\beta>0$ is an inverse heat parameter.
%After long time the ensemble will concentrate close to a minimizer of $V$.
%Generalizations of CBO to sampling also exist [2].
%While being computationally efficient, these methods are of limited use for minimizing non-convex functions or sampling from multi-modal distributions, basically because the whole ensemble follows one common mean value.
%In this talk I present a novel CBO method which uses a kernelized notion of mean value.
%This kernelized mean is different for every particle and---for kernels $k(x,y)$ which are decreasing functions of the distance between $x$ and $y$---coincides with a weighted average of close-by points.
%This way the proposed method allows for finding several global minima of non-convex functions and for multi-modal sampling.
%I will present numerical examples and first theoretical results on this novel method.
%
%\medskip
%
%[1] Pinnau, R., Totzeck, C., Tse, O. and Martin, S., 2017. A consensus-based model for global optimization and its mean-field limit. \emph{Mathematical Models and Methods in Applied Sciences}, 27(01), pp.183--204.
%
%[2] Carrillo, J.A., Hoffmann, F., Stuart, A.M. and Vaes, U., 2022. Consensus-based sampling. \emph{Studies in Applied Mathematics}, 148(3), pp.1069--1140.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Geometric convergence of polar slice sampling}% [1] talk title
% {Daniel Rudolf}% [2] speaker name
% {University of Passau}% [3] affiliations
% {daniel.rudolf@uni-passau.de}% [4] email
% {Philip Sch\"ar}% [5] coauthors
% {Stochastic Computation and Complexity: High Dimensional Approximation, Integration, and PDEs}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{10:30}{11:00}{STC 1012}}% [7] time slot
% {2161}% [8] talk id
% {2160}% [9] session id
%Roberts and Rosenthal introduced and analyzed in [1] the polar slice sampler for approximate sampling w.r.t. a posterior target distribution on $\mathbb{R}^d$. They showed that it performs, in contrast to other sampling methods, dimension independent, at least if suitably initialized and if the posterior density satisfies some structural properties. By extending arguments of [2] we prove that it has a particularly simple, explicit and dimension-independent spectral gap for strictly increasing, convex and twice differentiable negative log density functions.
%
%\medskip
%
%\renewcommand{\labelenumi}{[\arabic{enumi}]}
%\begin{enumerate}
%	\item G.~Roberts and J.~Rosenthal, \emph{The polar slice sampler}, Stoch. Models 18(2), 257-280, 2002.
%	\item V.~Natarovskii, D.~Rudolf and B.~Sprungk, \emph{Quantitative spectral gap estimate and Wasserstein contraction of simple slice sampling}, Ann. Appl. Probab. 31(2), 806-825, 2021.
%\end{enumerate}
%\end{talk}
%
%\begin{talk}
% {Quasi-Monte Carlo methods and discontinuous Galerkin}% [1] talk title
% {Andreas Rupp}% [2] speaker name
% {LUT University}% [3] affiliations
% {andreas.rupp@lut.fi}% [4] email
% {Vesa Kaarnioja}% [5] coauthors
% {}% [6] special session.
% {\timeslot{Monday, July 18, 2022}{17:30}{18:00}{Lecture Hall 6}}% [7] time slot
% {4533}% [8] talk id
% {4530}% [9] session id
%In this talk, we design and develop Quasi-Monte Carlo (QMC) cubatures for non-conforming discontinuous Galerkin approximations of elliptic PDE problems with random coefficients. In particular, we are interested in using QMC cubatures to compute the response statistics (expectation and variance) of the discretized PDE problem and we derive rigorous QMC convergence rates for this problem.
%\end{talk}
%
%
%\begin{talk}
% {Recent advances of Euler-Krylov’s polygonal approximations in ML and AI}% [1] talk title
% {Sotirios Sabanis} % [2] speaker name
% {University of Edinburgh, Alan Turing Institute, National Technical University of Athens} % [3] affiliations
% {s.sabanis@ed.ac.uk}% [4] email
% {Dong-Young Lim, Ariel Neufeld, Ying Zhang}% [5] coauthors
% {Stochastic Computation and Complexity: Quadrature for SDEs and SPDEs, Stochastic Optimization, Neural Networks} % [6] special session.
% {\timeslot{Monday, July 18, 2022}{11:30}{12:00}{STC 1012}}% [7] time slot
% {2233}% [8] talk id
% {2230}% [9] session id
%The idea of using a new form of Euler’s polygonal approximations, one which allows coefficients to depend directly on the step size, was highlighted in [1] and [2]. More recently, this new form of Euler’s polygonal approximations has been used to create new, stochastic (adaptive) optimization algorithms with superior performance, in many cases, than other leading optimization algorithms within the context of fine tuning of artificial neural networks, see [3] and [4]. Key findings of this new methodology will be reviewed, with particular focus on the latter two references.
%
%\medskip
%
%
%[1] N. V. Krylov. \newblock {\em Extremal properties of the solutions of stochastic equations.
%Theory of Probability and
%its Applications}.
%\newblock 29(2):205–217, 1985.
%
%[2] N. V. Krylov. \newblock {\em A simple proof of the existence of a solution to the Itô’s equation with monotone
%coefficients. Theory of Probability and its Applications}.
%\newblock 35(3):583--587, 1990.
%
%[3] D.-Y. Lim and S. Sabanis
%\newblock {\em Polygonal Unadjusted Langevin Algorithms: Creating stable and efficient adaptive algorithms for neural networks. arXiv preprint arXiv:	arXiv:2105.13937},
%\newblock 2021.
%
%
%[4] D.-Y. Lim, A. Neufeld, Y. Zhang and S. Sabanis
%\newblock {\em Non-asymptotic estimates for TUSLA algorithm for non-convex learning with applications to neural networks with ReLU activation function. arXiv preprint arXiv:	arXiv:2107.08649},
%\newblock 2021.
%\end{talk}
%
%\newpage
%
%
%\begin{talk}
% {Robust control variates optimization for rendering}% [1] talk title
% {Corentin Sala\"{u}n}% [2] speaker name
% {Max-Planck-Institut f{\"u}r Informatik}% [3] affiliations
% {csalaun@mpi-inf.mpg.de}% [4] email
% {Adrien Gruson, Binh-Son Hua, Toshiya Hachisuka, Gurprit Singh}% [5] coauthors
% {}% [6] special session
% {\timeslot{Tuesday, July 19, 2022}{15:30}{16:00}{Lecture Hall 5}}% [7] time slot
% {4421}% [8] talk id
% {4420}% [9] session id
%Monte Carlo integration is a recurrent problem in computer graphics. This numerical estimation is error prone and many methods have been developed to limit it magnitude. One of them is the use of control variate to simplify the integration problem. When using a suitable control variate, it is possible to significantly reduce the complexity of the integration problem and thus the amount of error produced. On the other hand, using the bad control variate can increase the error. The major difficulty of these methods is to choose robustly these control variate.
%We propose an optimization-based method that ensures a variance reduction compared to a Monte Carlo estimator. This method uses the samples of a Monte Carlo estimator to build a reliable estimate of the integrated function. We then use this estimate as a control variate function. Under certain simple conditions, it is provable that this estimator has a reduced variance over to a Monte Carlo one. This method can be used as a substitute of Monte Carlo estimator in many problems. We have demonstrated its applicability to different light transport simulation problems.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Ensuring unbiased sampling of HMC schemes for non separable Hamiltonian systems}% [1] talk title
% {R\'egis Santet}% [2] speaker name
% {\'{E}cole des Ponts, Inria}% [3] affiliations
% {regis.santet@enpc.fr}% [4] email
% {Gabriel Stoltz, Tony Leli\`evre}% [5] coauthors
% {}% [6] special session
% {\timeslot{Wednesday, July 20, 2022}{14:30}{15:00}{STC 1012}}% [7] time slot
% {4332}% [8] talk id
% {4330}% [9] session id
%Hamiltonian Monte Carlo (or Hybrid Monte Carlo)~[1] is a Markov Chain Monte Carlo method that allows to sample high dimensional probability measures. Girolami \textit{et al.}~[2] have used it to include a position-dependent diffusion coefficient, coming from the overdamped Langevin dynamics, that improves the convergence of the numerical method. It however requires simulating Hamiltonian dynamics with a non separable Hamiltonian, which is done in practice with implicit methods in order to ensure the preservation of key properties of the Hamiltonian dynamics (symplecticity and time-reversibility in particular)~[3]. Unfortunately, actual implicit numerical schemes cannot be reversible, as already noted in the context of constrained stochastic differential equations~[4,5]. We show here how to enforce the numerical reversibility of the method to guaranteed that the sampling is unbiased. Our numerical results demontrate that this correction is indeed relevant in practice.
%
%\medskip
%
%\begin{enumerate}
% \item [{[1]}] S. Duane, A. D. Kennedy, B. J. Pendleton, and D. Roweth. Hybrid monte carlo. \textit{Physics Letters B}, 195(2):216–222, 1987.
% \item [{[2]}] M. Girolami and B. Calderhead. Riemann manifold langevin and hamiltonian monte carlo methods. \textit{Journal of the Royal Statistical Society: Series B (Statistical Method-
% ology)}, 73(2):123–214, 2011.
% \item [{[3]}] B. Leimkuhler and S. Reich. \textit{Simulating Hamiltonian Dynamics}. Cambridge Monographs on Applied and Computational Mathematics. Cambridge University Press,
% Cambridge, 2005.
% \item [{[4]}] E. Zappa, M. Holmes-Cerfon, and J. Goodman. Monte carlo on manifolds: sampling densities and integrating functions. \textit{Communications on Pure and Applied Mathematics}, 71(12):2609–2647, 2018.
% \item [{[5]}] T. Leli\`{e}vre, M. Rousset, and G. Stoltz. Hybrid monte carlo methods for sampling probability measures on submanifolds. \textit{Numerische Mathematik}, 143(2):379–421, October 2019.
%\end{enumerate}
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Modeling a life insurer’s balance sheet and analyzing its long-term stability}% [1] talk title
% {J\"{o}rn Sass}% [2] speaker name
% {TU Kaiserslautern}% [3] affiliations
% {sass@mathematik.uni-kl.de}% [4] email
% {Maximilian Diehl, Roman Horsky, Susanne Reetz}% [5] coauthors
% {Simulation and Monte Carlo Methods in Quantitative Finance and Insurance}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{16:30}{17:00}{Lecture Hall 5}}% [7] time slot
% {2101}% [8] talk id
% {2100}% [9] session id
%We devise a stochastic asset-liability management model for a life insurance company. A flexible procedure for the generation of insurers’ compressed contract portfolios that respects the given biometric structure is presented. The introduced balance sheet model is in line with the principles of double-entry bookkeeping as required in accounting. We prove the consistency of the balance sheet equations. We further focus on the incorporation of new business, i.e. the addition of newly concluded contracts and thus of insured in each period. Efficient simulations are retained by integrating new policies into existing cohorts according to contract-related criteria. In extensive Monte Carlo simulation studies for different scenarios regarding the business form of today’s life insurers, we utilize these to analyze the long-term behavior and the stability of the components of the balance sheet for different asset-liability approaches and interest rate scenarios. Finally, we investigate the robustness of two prominent investment strategies against crashes in the capital markets, which lead to extreme liquidity shocks and thus threaten the insurer’s financial health. We discuss the relevance of the results based on possible simulation errors and model parameters.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Convergence of adaptive stochastic collocation with finite elements}% [1] talk title
% {Andrea Scaglioni}% [2] speaker name
% {TU Wien}% [3] affiliations
% {andrea.scaglioni@tuwien.ac.at}% [4] email
% {Michael Feischl}% [5] coauthors
% {Smoothing and Adaptive Methods}% [6] Special session title
% {\timeslot{Friday, July 22, 2022}{09:00}{09:30}{STC 1012}}% [7] time slot
% {2135}% [8] talk id
% {2130}% [9] session id
%In [1], we approximate a partial differential equation with random data using sparse grids (a collocation method) in the probability space and finite elements in the spatial domain. Both methods are adaptive: The set of collocation points used in the probability space is enlarged and the finite element meshes are refined. The adaptive refinement is steered by the reliable a-posteriori error estimator proposed in [2].
%Our main result is a convergence proof of the adaptive algorithm. The analysis consists of two steps: First, we establish convergence of the semi-discrete (probability space only) scheme. Then, we extend the result to the fully discrete setting employing convergence properties of h-adaptive finite elements. To our knowledge, this is the first convergence proof of an adaptive stochastic collocation-finite elements scheme. Furthermore, we present numerical tests to validate the theoretical results and discuss the performance of the algorithm.
%
%\medskip
%
%\begin{enumerate}
%\item M.\ Feischl, and A.\ Scaglioni, \emph{Convergence of adaptive stochastic collocation with finite elements}, Computers \& Mathematics with Applications.\ 98:139--156, 2021.
%\item D.\ Guignard, and F.\ Nobile, \emph{A posteriori error estimation for the stochastic collocation finite element method}, SIAM J. Numer. Anal.\ 56(5):3121--3143, 2018.
%\end{enumerate}
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {On the support of minimizers of causal variational principles on the sphere}% [1] talk title
% {Daniela Schiefeneder}% [2] speaker name
% {University of Innsbruck}% [3] affiliations
% {daniela.schiefeneder@uibk.ac.at}% [4] email
% {Lucia B\"{a}uml, Felix Finster, Heiko von der Mosel}% [5] coauthors
% {Energy-Minimizing Point Configurations and Measures II}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{17:30}{18:00}{Lecture Hall 3}}% [7] time slot
% {2283}% [8] talk id
% {2280}% [9] session id
%As an approach for formulating relativistic quantum field theory, causal variational principles have been proposed in [1]. In one setting, the aim of such causal variational principles is to minimize an action defined as the double integral of special non-negative functions (so-called \textit{Lagrangians}) within the class of regular Borel probability measures on the two-sphere. We show that depending on the chosen Lagrangian, minimizers of these principles either satisfy certain properties (we call these minimizers \textit{generically timelike}) or else have singular support (see [2]). In the latter case, it can be proven that the support of every
%minimizing measure is contained in a finite number of smooth curves which intersect at a finite number of points, or that the support has Hausdorff dimension at most 6/7 (see [3]). Numerical results supplement our investigations.\\
%
%[1] Felix Finster, \textit{The Continuum Limit of Causal Fermion Systems}, Fundamental Theories of Physics, vol. 186, Springer, 2016.
%
%[2] F. Finster, D. Schiefeneder, \textit{On the support of minimizers of causal variational principles}, Arch. Ration. Mech. Anal. 210 (2013), no. 2, 321-364.
%
%[3] L. B\"{a}uml, F. Finster, H. von der Mosel, and D. Schiefeneder, \textit{Singular support of minimizers
%of the causal variational principle on the sphere}, Calc. Var. Partial
%Differential Equations 58 (2019), no. 6, 205.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Convergence of unadjusted Hamiltonian Monte Carlo for mean-field models}% [1] talk title
% {Katharina Schuh}% [2] speaker name
% {University of Bonn}% [3] affiliations
% {s6knschu@uni-bonn.de}% [4] email
% {Nawaf Bou-Rabee}% [5] coauthors
% {Recent Advances in MCMC Sampling Techniques}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{17:30}{18:00}{Lecture Hall 4}}% [7] time slot
% {2213}% [8] talk id
% {2210}% [9] session id
%We study unadjusted Hamiltonian Monte Carlo (uHMC) and present dimension-free convergence bounds for the uHMC algorithm applied to high-dimensional probability distributions of mean-field type.
%These bounds require the discretization step to be sufficiently small, but do not require strong convexity of either the unary or pairwise potential terms present in the mean-field model. To handle high dimensionality, our proof uses a particlewise coupling that is contractive in a complementary particlewise metric.
%Moreover, we provide quantitative discretization error bounds for uHMC.
%The talk is based on [1].
%
%\medskip
%
%\begin{itemize}
%	\item[{[1]}] Convergence of unadjusted Hamiltonian Monte Carlo for mean-field models, Nawaf Bou-Rabee and Katharina Schuh, ArXiv preprint arXiv:2009.08735, 2020.
%\end{itemize}
%\end{talk}
%
%\begin{talk}
% {Regular conditional distributions for semimartingale SDEs}% [1] talk title
% {Verena Schwarz}% [2] speaker name
% {University of Klagenfurt}% [3] affiliations
% {verena.schwarz@aau.at}% [4] email
% {Pawe{\l} Przyby{\l}owicz, Michaela Sz\"olgyenyi}% [5] coauthors
% {Analysis and Simulation of SDEs in Non-Standard Settings}% [6] Special session title
% {\timeslot{Friday, July 22, 2022}{09:30}{10:00}{Lecture Hall 3}}% [7] time slot
% {2192}% [8] talk id
% {2190}% [9] session id
%In this talk an existence result for the regular conditional distribution a large class of semi-martingale driven SDEs is presented. For this we show that the solution of these SDEs can be written as a measurable function of its driving processes into the space of all càdlàg functions equipped with the Borel algebra generated by all open sets with respect to the Skorohod metric. Our result is relevant, for example, in computational stochastics: as corollary it provides a Markov property which is essential for proving convergence results of numerical methods for general semi-martingale driven SDEs.
%
%\medskip
%
%[1] P.~Przyby{\l}owicz, V.~Schwarz, M.~Sz\"olgyenyi. \textit{Regular conditional distributions for semimartingale SDEs} (2022), preprint: https://arxiv.org/pdf/2201.06278.pdf.
%\end{talk}
%
%
%\begin{talk}
% {Connecting advanced models and advanced UQ: the MIT UQ library (MUQ) and a universal UQ/model interface}% [1] talk title
% {Linus Seelinger}% [2] speaker name
% {Heidelberg University}% [3] affiliations
% {linus.seelinger@iwr.uni-heidelberg.de}% [4] email
% {Anne Reinarz, Robert Scheichl}% [5] coauthors
% {Algorithmic Advancements in MCQMC Software}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{11:30}{12:00}{Lecture Hall 5}}% [7] time slot
% {2243}% [8] talk id
% {2240}% [9] session id
%Mathematical models of complex real-world phenomena result in computational challenges, necessitating advanced software and High Performance Computing systems. Uncertainty quantification (UQ) on such models is even more challenging, since uncertainties essentially increase dimensionality of the problem at hand.
%
%Addressing those challenges, we present a Multilevel Markov Chain Monte Carlo [1] framework within the MIT Uncertainty Quantification Library (MUQ) [2]. This framework exploits model hierarchies for efficiency and allows for massive parallelism despite data dependencies in the algorithm. We show a demonstration applying it to a Bayesian inverse problem on a shallow water PDE modelling the 2011 Tohoku tsunami [3].
%
%We further introduce UM-Bridge, a new software framework for coupling arbitrary model codes with arbitrary UQ packages, regardless of the respective software tools used. UM-Bridge makes it easy to apply advanced UQ methods on challenging models, while offering model portability through (optional) containerization as well as separation of concerns between model experts and UQ developers.
%
%Finally, a work-in-progress set of standardized UQ benchmarks based on UM-Bridge is presented, inviting the community to get involved in their definition and implementation.
%
%\medskip
%
%[1] Multilevel Markov Chain Monte Carlo, T. J. Dodwell, C. Ketelsen, R. Scheichl, A. L. Teckentrup, SIAM Review, https://doi.org/10.1137/19M126966X
%
%[2] MUQ: The MIT Uncertainty Quantification Library, M. Parno, A. Davis, L. Seelinger, Journal of Open Source Software, https://doi.org/10.21105/joss.03076
%
%[3] High Performance Uncertainty Quantification with Parallelized Multilevel Markov Chain Monte Carlo, L. Seelinger, A. Reinarz, L. Rannabauer, M. Bader, P. Bastian, R. Scheichl, The International Conference for High Performance Computing, Networking, Storage, and Analysis 2021, https://doi.org/10.1145/3458817.3476150
%\end{talk}
%
%\begin{talk}
% {Multilevel Monte Carlo with machine learned surrogate models for resource adequacy assessment}% [1] talk title
% {Ensieh Sharifnia}% [2] speaker name
% {Delft University of Technology}% [3] affiliations
% {e.sharifnia@tudelft.nl}% [4] email
% {Simon Tindemans}% [5] coauthors
% {}% [6] special session
% {\timeslot{Monday, July 18, 2022}{15:30}{16:00}{Lecture Hall 6}}% [7] time slot
% {4521}% [8] talk id
% {4520}% [9] session id
%Monte Carlo (MC) simulation is often used to evaluate the reliability of large electrical power grids. The impact of stochastic equipment outages and operating conditions is analysed with the aim to quantify risks to delivery of energy to customers. Today's grids rapidly increase in complexity, so that the evaluation of a single state can be computationally demanding. Moreover, the power system is highly reliable, and failure states that significantly affect reliability evaluation are rare. Hence, many states should be evaluated in MC simulations to obtain the desired level of accuracy, which makes the simulation computationally expensive.
%
%Many efforts have been made to make the simulation faster. Among them, Multilevel Monte Carlo (MLMC) is one the most powerful methods that can be applied to obtain speedup computation without compromising model complexity and accuracy. High speedups can be achieved when making use of multiple models with high pair-wise correlations and large differences in evaluation speed~[1]. Therefore, having good combinations of models has a significant effect on MLMC performance. However, manually constructing models with the above conditions~[2] may require substantial domain knowledge. In this talk we demonstrate how machine-learned surrogate models are able to fulfil this role without resorting to careful development of approximate models. Different strategies for constructing and training surrogate models are discussed. A resource adequacy case study based on the Great Britain system with storage units is used to demonstrate the effectiveness of the proposed approach, and the sensitivity to surrogate model accuracy. The high accuracy and inference speed of machine-learned surrogates result in very large speedups, compared to using MLMC with only hand-built models.
%
%\medskip
%
%[1] M. B. Giles, “Multilevel monte carlo methods,” Acta numerica, vol. 24, pp. 259–328, 2015.
%
%[2] S. Tindemans and G. Strbac, “Accelerating system adequacy assessment using the multilevel monte carlo approach,” Electric Power Systems Research, vol. 189, p. 106 740, 2020.
%
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {$s$-numbers of embeddings of weighted Wiener classes}% [1] talk title
% {Winfried Sickel}% [2] speaker name
% {Friedrich-Schiller-University Jena}% [3] affiliations
% {winfried.sickel@uni-jena.de}% [4] email
% {Van Dung Nguyen, Van Kien Nguyen}% [5] coauthors
% {Stochastic Computation and Complexity: High Dimensional Approximation, Integration, and PDEs}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{11:30}{12:00}{STC 1012}}% [7] time slot
% {2163}% [8] talk id
% {2160}% [9] session id
%In my talk I will discuss the behaviour of some $s$-numbers
%(including approximation numbers) of three different types of embeddings of the weighted Wiener algebra $A_w (\mathbb{T}^d)$ defined on the $d$-dimensional torus:
%\begin{itemize}
% \item $A_w (\mathbb{T}^d) \to A(\mathbb{T}^d)$, where $A(\mathbb{T}^d)$ denotes the Wiener algebra itself;
% \item $A_w (\mathbb{T}^d) \to L_2(\mathbb{T}^d)$;
% \item $A_w (\mathbb{T}^d) \to H^1(\mathbb{T}^d)$, where $w$ is given by \[
% w (k) = w_{s,r} (k) := \left\{\begin{array}{lll}
%\prod_{i=1}^d (1+|k_i|^r)^{s/r} &\qquad & \mbox{if}\quad 0 < r < \infty\, ;
%\\
%&&\\
%\prod_{i=1}^d \max (1,|k_i|)^{s} &\qquad & \mbox{if}\quad r = \infty\, .
%\end{array}\right.
% \]
%\end{itemize}
%It will be the main aim of my talk to describe the behaviour of the associated $s$-numbers in dependence of $n$ and the dimension $d$.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {The power of random information for recovery in $\ell_2$}% [1] talk title
% {Mathias Sonnleitner}% [2] speaker name
% {University of Passau}% [3] affiliations
% {mathias.sonnleitner@uni-passau.de}% [4] email
% {Aicke Hinrichs, Joscha Prochno}% [5] coauthors
% {Stochastic Computation and Complexity: High Dimensional Approximation, Integration, and PDEs}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{16:30}{17:00}{STC 1012}}% [7] time slot
% {2165}% [8] talk id
% {2160}% [9] session id
%Linear functionals can be used to recover objects in (quasi-)normed spaces with a high but finite dimension. We study the effectiveness of a random (Gaussian) choice of linear functionals compared to optimal linear functionals when the error of recovery is measured in $\ell_2$. We give an overview of existing results and present new results for normed spaces whose unit balls are generalized ellipsoids, which are images of $\ell_p$-balls under diagonal operators. Depending on the lengths of the semiaxes, random linear functionals may be either close to optimal or almost useless with high probability.
%\end{talk}
%
%\begin{talk}
% {Quasi-Monte Carlo for vector functions of integrals}% [1] talk title
% {Aleksei Sorokin}% [2] speaker name
% {Illinois Institute of Technology}% [3] affiliations
% {asorokin@hawk.iit.edu}% [4] email
% {Jagadeeswaran Rathinavel, Fred J.~Hickernell}% [5] coauthors
% {Monte Carlo and Quasi-Monte Carlo Software}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{11:00}{11:30}{Lecture Hall 5}}% [7] time slot
% {2242}% [8] talk id
% {2240}% [9] session id
%Quasi-Monte Carlo methods present an efficient approach for multivariate numerical integration. Algorithms exist to adaptively sample the integrand until a user defined error tolerance is satisfied with theoretical guarantees or with high probability. This work describes our extension of such methods to support adaptive sampling to satisfy error criteria for vector functions of multiple integrals. Although several functions involving multiple integrals are being evaluated, only one low discrepancy sequence is required, albeit sometimes of larger dimension than the integration domain. These enhanced algorithms are implemented in the QMCPy Python package with support for vectorized, economical integrand evaluation. Motivating examples include the approximation of sensitivity indices, coefficients for Bayesian logistic regression, and vectorized acquisition function values in Bayesian optimization.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Monte Carlo variance reduction using Stein operators}% [1] talk title
% {Leah F.~South}% [2] speaker name
% {Queensland University of Technology}% [3] affiliations
% {l1.south@qut.edu.au}% [4] email
% {Toni Karvonen, Christopher Drovandi, Antonietta Mira, Christopher Nemeth, Mark Girolami,, Chris Oates}% [5] coauthors
% {Developments in Markov Chain Monte Carlo}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{11:30}{12:00}{Lecture Hall 4}}% [7] time slot
% {2253}% [8] talk id
% {2250}% [9] session id
%This talk will focus on two new methods for estimating posterior expectations when the derivatives of the log posterior are available. The proposed methods are in a class of estimators that use Stein operators to generate control variates or control functionals. The first method [1] applies regularisation to improve the performance of popular Stein-based control variates for high-dimensional Monte Carlo integration. The second method [2], referred to as semi-exact control functionals (SECF), is based on control functionals and Sard’s approach to numerical integration. The use of Sard’s approach ensures that our control functionals are exact on all polynomials up to a fixed degree in the Bernstein-von-Mises limit. Several Bayesian inference examples will be used to illustrate the potential for reduction in mean square error.
%
%\medskip
%
%[1] South, L. F., Oates, C. J., Mira, A., \& Drovandi, C. Regularised zero-variance control variates. \textit{arXiv preprint arXiv:1811.05073}.
%
%[2] South, L. F., Karvonen, T., Nemeth, C., Girolami, M., \& Oates, C. (2021). Semi-Exact Control Functionals From Sard's Method. \textit{Biometrika}.
%\end{talk}
%
%%\newpage
%
%\begin{talk}
% {Efficient computation of linear response of nonequilibrium stochastic dynamics}% [1] talk title
% {Renato Spacek}% [2] speaker name
% {\'{E}cole des Ponts, Inria Paris}% [3] affiliations
% {renato.spacek@enpc.fr}% [4] email
% {Gabriel Stoltz}% [5] coauthors
% {}% [6] special session.
% {\timeslot{Tuesday, July 19, 2022}{16:00}{16:30}{Lecture Hall 6}}% [7] time slot
% {4542}% [8] talk id
% {4540}% [9] session id
%Transport coefficients, such as the mobility, thermal conductivity and shear viscosity, are quantities of prime interest in statistical physics. At the macroscopic level, transport coefficients relate an external forcing of magnitude $\eta$, with $\eta \ll 1$, acting on the system to an average response expressed through some steady-state flux. In practice, steady-state averages involved in the linear response are computed as time averages over a realization of some stochastic differential equation. Variance reduction techniques are of paramount interest in this context, as the linear response is scaled by a factor of $1/\eta$, leading to large statistical error.
%
%One way to limit the increase in the variance is to allow for larger values of $\eta$ by increasing the range of values of the forcing for which the nonlinear part of the response is sufficiently small. In theory, one can add an extra forcing to the physical perturbation of the system, called synthetic forcing, as long as this extra forcing preserves the invariant measure of the reference system. The aim is to find synthetic perturbations allowing to reduce the nonlinear part of the response as much as possible. In this talk, I will present a mathematical framework for quantifying the quality of synthetic forcings, in the context of linear response theory, and discuss various possible choices for them. I will illustrate my analysis with numerical results on the computation of the mobility in low dimensional systems.
%\medskip
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Hierarchical and adaptive methods for efficient risk estimation}% [1] talk title
% {Jonathan Spence}% [2] speaker name
% {Heriot-Watt University}% [3] affiliations
% {jws5@hw.ac.uk}% [4] email
% {Abdul-Lateef Haji-Ali}% [5] coauthors
% {}% [6] special session.
% {\timeslot{Friday, July 22, 2022}{09:00}{09:30}{Lecture Hall 6}}% [7] time slot
% {4581}% [8] talk id
% {4580}% [9] session id
%Financial derivatives in over-the-counter markets are subject to a series of valuation adjustments. These terms combine several layers of approximation, posing difficulties for efficient Monte Carlo estimation. As an example, we consider estimation of the value-at-risk of the credit valuation adjustment. This requires Monte Carlo estimation of
%\[
%\mathbb{E}[\mathbb{H}(\mathbb{E}[f(\mathbb{E}[S_T\ |\ S_\tau])\ |\ S_h])],
%\]
%for a Lipschits function \(f\), the Heaviside function \(\mathbb{H}\) and relevant market and risk factors \(S\) at times \(h, \tau\) and \(T\). The nested structure of expectations, paired with numerical approximation of the market factors results in an \(\mathcal{O}(\varepsilon^{-5}) \) cost for standard Monte Carlo estimation with root mean square error \(\varepsilon\). To remedy this, we construct a hierarchy of unbiased multilevel Monte Carlo estimators for \(\mathbb{E}[f(\mathbb{E}[S_T\ |\ S_\tau])\ |\ S_h] \), combined with adaptive multilevel Monte Carlo estimation for the expectation of the Heaviside function [1]. The resulting estimator has a greatly reduced \(\mathcal{O}(\varepsilon^{-2}(\log\varepsilon)^2) \) cost.
%
%\medskip
%
%[1] A.-L. Haji-Ali, J. Spence, and A. Teckentrup. Adaptive Multilevel Monte Carlo for Probabilities, 2021.
%\end{talk}
%
%
%\begin{talk}
% {Convergence of the tamed Euler--Maruyama method for SDEs with discontinuous and polynomially growing drift}% [1] talk title
% {Kathrin Spendier}% [2] speaker name
% {University of Klagenfurt}% [3] affiliations
% {kathrin.spendier@aau.at}% [4] email
% {Michaela Sz\"{o}lgyenyi}% [5] coauthors
% {Stochastic Computation and Complexity: Approximation of SDEs with Non-Standard Coefficients}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{12:00}{12:30}{STC 1012}}% [7] time slot
% {2298}% [8] talk id
% {2290}% [9] session id
%SDEs with irregular coefficients are currently of high interest. There are some specific types of irregularities leading to different problems when studying convergence of numerical schemes. These types of irregularities are usually studied separately in the literature. Examples are polynomially growing coefficients, or discontinuous coefficients. We consider SDEs that suffer from both of these types of irregularities and study strong convergence of the tamed Euler-Maruyama scheme.
%\end{talk}
%
%
%
%\begin{talk}
% {Multilevel Monte Carlo method with meta-model for advection-diffusion problems}% [1] talk title
% {Martin \v{S}petl\'{\i}k}% [2] speaker name
% {Technical University of Liberec}% [3] affiliations
% {martin.spetlik@tul.cz}% [4] email
% {Jan B\v{r}ezina, jan.brezina@tul.cz}% [5] coauthors
% {}% [6] special session
% {\timeslot{Wednesday, July 20, 2022}{11:30}{12:00}{Lecture Hall 6}}% [7] time slot
% {4553}% [8] talk id
% {4550}% [9] session id
%In this talk, we will present our results in modelling advection-diffusion processes using a combination of the multilevel Monte Carlo method (MLMC) and deep learning techniques.
%We deal with various simulations of Darcy flow and solute transport, particularly in the vicinity of a future underground nuclear waste repository.
%Our simulation problems are described by partial differential equations (PDEs) and solved numerically by the finite element method.
%Given the bedrock environment uncertainties, we consider simulation inputs as random variables and use the MLMC to estimate the expected values of simulation outputs.
%Depending on the required accuracy, it might lead to thousands of simulations, significantly affecting computational costs.
%
%To overcome this difficulty, we substitute appropriate simulations with a meta-model.
%In particular, we employ a graph convolutional neural network (GCN) to approximate the solution of a PDE.
%This approach saves computational costs but also affects some MLMC estimator properties.
%The talk will cover the incorporation of a meta-model into a multilevel estimator, including its applicability and limitations. Numerical experiments will show the effectiveness of the proposed approach.
%\end{talk}
%
%
%\begin{talk}
% {Dimension-independent Markov chain Monte Carlo on the sphere}% [1] talk title
% {Bj\"orn Sprungk}% [2] speaker name
% {TU Bergakademie Freiberg}% [3] affiliations
% {bjoern.sprungk@math.tu-freiberg.de}% [4] email
% {Han Cheng Lie, Daniel Rudolf, Tim J. Sullivan}% [5] coauthors
% {Advanced Particle Methods for Bayesian Inference}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{12:00}{12:30}{Lecture Hall 4}}% [7] time slot
% {2094}% [8] talk id
% {2090}% [9] session id
%We consider Bayesian analysis on high-dimensional spheres with angular central Gaussian priors. These priors model antipodally-symmetric directional data, are easily defined in Hilbert spaces and occur, for instance, in Bayesian binary classification and level set inversion. In this paper we derive efficient Markov chain Monte Carlo methods for approximate sampling of posteriors with respect to these priors. Our approaches rely on lifting the sampling problem to the ambient Hilbert space and exploit existing dimension-independent samplers in linear spaces. By a push-forward Markov kernel construction we then obtain Markov chains on the sphere, which inherit reversibility and spectral gap properties from samplers in linear spaces. Moreover, our proposed algorithms show dimension-independent efficiency in numerical experiments.
%
%\medskip
%
%[1] H.~C.~Lie, D.~Rudolf, B.~Sprungk, T.~J.~Sullivan. Dimension-independent Markov chain Monte Carlo on the sphere. Preprint available at \url{https://arxiv.org/abs/2112.12185}
%\end{talk}
%
%\begin{talk}
% {Approximate Bayesian algorithm for tensor robust principal component analysis}% [1] talk title
% {Andrej Srakar}% [2] speaker name
% {Institute for Economic Research (IER), University of Ljubljana}% [3] affiliations
% {srakara@ier.si}% [4] email
% {}% [5] coauthors
% {Developments in Markov Chain Monte Carlo}% [6] Special session title
% {\timeslot{Monday, July 18, 2022}{12:00}{12:30}{Lecture Hall 4}}% [7] time slot
% {2254}% [8] talk id
% {2250}% [9] session id
%Recently proposed Tensor Robust Principal Component Analysis (TRPCA) aims to exactly recover the low-rank and sparse components from their sum, extending the earlier Low-Rank Tensor Completion model representation. We construct a Bayesian approximate inference algorithm for TRPCA, based on regression adjustment methods suggested in the literature to correct for high-dimensional nature of the problem and sequential Monte Carlo approach with adaptive weights. Our results are compared to previous studies which used variational Bayes inference for matrix and tensor completion. In a short application, we study spatiotemporal traffic data imputation using nine-week spatiotemporal traffic speed data set of Guangzhou, China.
%\end{talk}
%
%\begin{talk}
% {Approximating distribution functions in uncertainty quantification using quasi-Monte Carlo methods}% [1] talk title
% {Abirami Srikumar}% [2] speaker name
% {University of New South Wales}% [3] affiliations
% {a.srikumar@student.unsw.edu.au}% [4] email
% {Frances Y.~Kuo, Ian H.~Sloan, Alexander D.~Gilbert}% [5] coauthors
% {Smoothing and Adaptive Methods}% [6] Special session title
% {\timeslot{Friday, July 22, 2022}{09:30}{10:00}{STC 1012}}% [7] time slot
% {2136}% [8] talk id
% {2130}% [9] session id
%As high-dimensional problems become increasingly prevalent in many applications, the effective evaluation of these problems within the limits of our current technology poses a great hurdle due to the exponential increase in computational cost as dimensionality increases. One class of strategies for evaluating such problems efficiently are quasi-Monte Carlo (QMC) methods. Recently the application of quasi-Monte Carlo methods to approximate expected values associated with solutions to elliptic partial differential equations with random coefficients in uncertainty quantification has been of great interest. In this talk, we look into extending this from the computation of expected values to the approximation of distribution functions by reformulating these functions as expectations of an indicator function. However this requires the integration of discontinuous functions and hence the need for preintegration, whereby we integrate out a single variable of the discontinuous function in order to obtain a function of one dimension less with sufficient level of smoothness to apply QMC methods. We also present some theoretical results regarding the error bounds associated with such approximations and the results of numerical experiments.
%\end{talk}
%
%\begin{talk}
% {Using importance sampling to speed up non-intrusive uncertainty quantification for Monte Carlo simulations}% [1] talk title
% {Pia Stammer}% [2] speaker name
% {Karlsruhe Institute of Technology, German Cancer Research Center - DKFZ}
% {pia.stammer@kit.edu}% [4] email
% {Lucas N. Burigo, Oliver J\"{a}kel, Martin Frank, Niklas Wahl}% [5] coauthors
% {}% [6] special session.
% {\timeslot{Thursday, July 21, 2022}{16:00}{16:30}{STC 1012}}% [7] time slot
% {4142}% [8] talk id
% {4140}% [9] session id
%Monte Carlo (MC) methods are used in radiation therapy to simulate the transport and dose deposition of particles in patients. Additional uncertainty quantification (UQ) can be challenging, as a naive application of UQ methods, like (quasi-) MC or stochastic collocation, requires numerous dose computations at different points in the parameter space. We exploit that parametric uncertainties can be modelled through changes to the probability distributions describing non-deterministic input particle phase space for MC dose calculations. The concept of importance sampling can then be used to reconstruct unbiased estimators of the dose for different error realizations from the simulated particle trajectories of just one dose computation. Combined with regular non-intrusive strategies and multivariate uncertainty models, efficient estimates for quantities of interest such as the expected dose or dose variance, are obtained. Using the common assumption of Gaussian parameter distributions and uncertainty in the patient position, we further derive a parameter distribution for the direct reconstruction of the expected dose. For the variance, we choose a randomized quasi-MC approach and reconstruct the solution for each sample using the importance weighting approach. We achieve a speed-up of more than an order of magnitude while maintaining $99\%-100\%$ agreement to a regular randomized quasi-MC reference for the dose expected value and variance according to the clinical $\gamma_{2mm/2\%}$-index, a distance to agreement criterion which is common in radiation therapy [1]. This contribution is based on [2].
%
%
%[1] D. A. Low, W. B. Harms, S. Mutic, and J. A. Purdy. A technique for the quantitative evaluation of dose distributions. Medical Physics, 25(5):656–661, May 1998.\\
%{[2]} P. Stammer, L. Burigo, O. J\"{a}kel, M. Frank, and N. Wahl (2022). Multivariate error modeling and uncertainty quantification using importance (re-) weighting for Monte Carlo simulations in particle transport. arXiv preprint arXiv:2202.02379.
%
%\end{talk}
%
%
%\begin{talk}
% {Multi-Level Monte Carlo FEM for elliptic PDEs with Besov random tree priors}% [1] talk title
% {Andreas Stein}% [2] speaker name
% {ETH Z\"{u}rich}% [3] affiliations
% {andreas.stein@sam.math.ethz.ch}% [4] email
% {Christoph Schwab}% [5] coauthors
% {Multilevel and Higher-Order Approximations for Stochastic Processes, Random Fields and PDEs}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{18:00}{18:30}{Lecture Hall 4}}% [7] time slot
% {2024}% [8] talk id
% {2020}% [9] session id
%We develop a Multilevel Monte Carlo (MLMC) FEM algorithm
%for linear, elliptic diffusion problems in polytopal domain $\mathcal D\subset \mathbb R^d$,
%with Besov-tree random coefficients.
%This is to say that the logarithms of the diffusion coefficients are sampled from
%so-called Besov-tree priors,
%which have recently been proposed to model
%data for fractal phenomena in science and engineering.
%Numerical analysis of the fully discrete FEM includes quadrature
%approximation and accounts for
%a) nonuniform pathwise upper and lower coefficient
%bounds, and for
%b) low path-regularity of the Besov-tree coefficients.
%
%Admissible non-parametric random coefficients
%correspond to random functions exhibiting singularities on random fractals
%with tunable fractal dimension, but involve no a-priori specification of the
%fractal geometry of singular supports of sample paths.
%Optimal complexity and convergence rate estimates for quantities of interest are proved.
%A convergence analysis for MLMC-FEM is performed which yields
%choices of the algorithmic steering parameters for
%efficient implementation.
%A complexity (``error vs work'') analysis of the MLMC-FEM
%approximations is provided.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Logarithmic energy of points on $\mathbb{S}^2$}% [1] talk title
% {Stefan Steinerberger}% [2] speaker name
% {University of Washington, Seattle}% [3] affiliations
% {steinerb@uw.edu}% [4] email
% {}% [5] coauthors
% {Quantifying Notions of Equidistribution on the Sphere}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{11:30}{12:00}{Lecture Hall 3}}% [7] time slot
% {2063}% [8] talk id
% {2060}% [9] session id
%I will discuss a very classical problem: understanding the smallest possible logarithmic energy of $n$ points $\left\{x_1, \dots, x_n\right\} \subset \mathbb{S}^2$. It is not terribly difficult to see that one expects
%$$ \min_{\left\{x_1, \dots, x_n\right\}} \sum_{i,j=1\atop i\neq j}^{n} \log\left(\frac{1}{\|x_i- x_j\|}\right) \sim \left(\frac{1}{2} - \log{2} \right) n^2 - \frac{n \log{n}}{2} + c n + o(n).$$
%The constant $c$ is expected to be
%$$ c_{\log} = 2\log{2} + \frac{1}{2} \log\frac{2}{3} + 3 \log \frac{\sqrt{\pi}}{\Gamma(1/3)} \sim -0.055605\dots$$
%but so far only upper and lower bounds are known. I will explain a completely new approach to the problem that replaces the logarithm by something dramatically more complicated which will be dramatically easier to analyze -- it gives rather sharp bounds on $c$ and, assuming some local hexagonal symmetry, even predicts the (conjectured) optimal value. The same idea should be applicable to other manifolds.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {From numerical schemes for SDEs to analysis of Lipschitz maps}% [1] talk title
% {Alexander Steinicke}% [2] speaker name
% {Montanuniversit\"{a}t Leoben}% [3] affiliations
% {alexander.steinicke@unileoben.ac.at}% [4] email
% {Gunther Leobacher, Zolt\'{a}n Buczolich}% [5] coauthors
% {Analysis and Simulation of SDEs in Non-Standard Settings.}% [6] special session.
% {\timeslot{Friday, July 22, 2022}{10:30}{11:00}{Lecture Hall 3}}% [7] time slot
% {2194}% [8] talk id
% {2190}% [9] session id
%Various phenomena in insurance dividend optimization or in modeling the energy market lead to stochastic differential equations (SDEs) with discontinuous drift terms and degenerate diffusion. In real world applications, such drift terms are multidimensional, with discontinuities located at multidimensional manifolds. Numerical schemes and rates for such equations have been given in [3] and [4], requiring the points of discontinuity of the drift coefficient to be a smooth ($C^4$) manifold $\Theta$. On the complement of this manifold, the drift is assumed to be smooth
%and thus locally Lipschitz continuous.
%
%In [3], a transform was constructed, which transforms the SDE with discontinuous drift into one with Lipschitz
%continuous drift, thus allowing the application of classical results.
%
%There, a key lemma was used that allows to conclude Lipschitz continuity of a function from its continuity plus
%`intrinsic Lipschitz continuity'. However, the validity of this conclusion relies on the regularity of the manifold.
%In [2] we coined the notion of a permeable subset of a metric space and showed that permeability is a sufficient
%condition.
% In [1] we construct an impermeable H\"older-submanifold of $\mathbb{R}^d$ for which the conclusion fails to hold.
%
%\medskip
%
%[1] Z.~Buczolich, G.~Leobacher, and A.~Steinicke.
%\newblock {Continuous functions with impermeable graphs}.
%\newblock {\em arXiv:2201.02159}, 2022.
%
%[2] G.~Leobacher and A.~Steinicke.
%\newblock {Exception sets of intrinsic and piecewise Lipschitz functions}.
%\newblock {\em Journal of Geometric Analysis}, 32, 2022.
%
%[3]
%G.~Leobacher and M.~Sz\"olgyenyi.
%\newblock A strong order $1/2$ method for multidimensional {SDE}s with
% discontinuous drift.
%\newblock {\em Ann. Appl. Probab.}, 27(4):2383--2418, 2017.
%
%[4]
%G.~Leobacher and M.~Sz\"olgyenyi.
%\newblock {Convergence of the Euler-Maruyama method for multidimensional SDEs
% with discontinuous drift and degenerate diffusion coefficient}.
%\newblock {\em Numerische Mathematik}, 138(1):219--239, 2018.
%\end{talk}
%
%
%
%\begin{talk}
% {Concave-Convex PDMP-based samplers}% [1] talk title
% {Matthew Sutton}% [2] speaker name
% {Queensland University of Technology}% [3] affiliations
% {matt.sutton@qut.edu.au}% [4] email
% {Paul Fearnhead, Augustin Chevallier}% [5] coauthors
% {}% [6] special session.
% {\timeslot{Thursday, July 21, 2022}{15:30}{16:00}{STC 1012}}% [7] time slot
% {4141}% [8] talk id
% {4140}% [9] session id
%Recently non-reversible samplers based on simulating piecewise deterministic Markov processes (PDMPs) have shown potential for efficient sampling in Bayesian inference problems. In this talk, I will show how these methods may be implemented efficiently when the rate function admits a concave-convex decomposition [1]. This approach facilitates simple implementation and computationally efficient thinning for a wide range of problems. In particular, our approach is well suited to local PDMP simulation where known conditional independence of the target can be exploited for potentially huge computational gains. I will show the merits of this approach with empirical scaling analysis and application to variable selection problems using reversible-jump PDMP-based samplers [2].
%
%\medskip
%
%[1] Sutton, M., \& Fearnhead, P. (2021). Concave-Convex PDMP-based sampling. In arXiv [stat.ME]. arXiv. http://arxiv.org/abs/2112.12897
%
%[2] Chevallier, A., Fearnhead, P., \& Sutton, M. (2020). Reversible Jump PDMP Samplers for Variable Selection. In arXiv [stat.CO]. arXiv. http://arxiv.org/abs/2010.11771
%\end{talk}
%
%\begin{talk}
% {Component-by-component construction of randomized rank-1 lattice rules achieving almost the optimal randomized error rate}% [1] talk title
% {Kosuke Suzuki}% [2] speaker name
% {Hiroshima University}% [3] affiliations
% {kosuke-suzuki@hiroshima-u.ac.jp}% [4] email
% {Josef Dick, Takashi Goda}% [5] coauthors
% {Quasi-Monte Carlo Methods of High Order and Beyond}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{17:00}{17:30}{Lecture Hall 6}}% [7] time slot
% {2156}% [8] talk id
% {2150}% [9] session id
%We study a randomized quadrature algorithm to approximate the integral of periodic functions defined over the high-dimensional unit cube. Recent work by Kritzer, Kuo, Nuyens and Ullrich (2019) shows that rank-1 lattice rules with a randomly chosen number of points and good generating vector achieve almost the optimal order of the randomized error in weighted Korobov spaces, and moreover, that the error is bounded independently of the dimension if the weight parameters, $\gamma_j$, satisfy the summability condition $\sum_{j=1}^{\infty}\gamma_j^{1/\alpha}<\infty$, where $\alpha$ is a smoothness parameter. The argument is based on the existence result that at least half of the possible generating vectors yield almost the optimal order of the worst-case error in the same function spaces.
%
%In this talk we provide a component-by-component construction algorithm of such randomized rank-1 lattice rules, without any need to check whether the constructed generating vectors satisfy a desired worst-case error bound. Similarly to the above-mentioned work, we prove that our algorithm achieves almost the optimal order of the randomized error and that the error bound is independent of the dimension if the same condition $\sum_{j=1}^{\infty}\gamma_j^{1/\alpha}<\infty$ holds.
%\end{talk}
%
%\begin{talk}
% {Scaled lattice rules for integration over $\mathbb{R}^d$ achieving higher order convergence}% [1] talk title
% {Yuya Suzuki}% [2] speaker name
% {Norwegian University of Science and Technology}% [3] affiliations
% {yuya.suzuki@ntnu.no}% [4] email
% {Dirk Nuyens}% [5] coauthors
% {Quasi-Monte Carlo Methods of High Order and Beyond}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{17:30}{18:00}{Lecture Hall 6}}% [7] time slot
% {2157}% [8] talk id
% {2150}% [9] session id
%In this talk, we show that by simply scaling lattice rules from the unit cube $[0,1]^d$ to properly sized boxes on $\mathbb{R}^d$, taking into account all errors, we can achieve higher-order convergence in approximating an integral on~$\mathbb{R}^d$ where the order of convergence matches the smoothness of the integrand function in a certain Sobolev space of dominating mixed smoothness.
%Our method only assumes that we can evaluate the integrand function $f$ and does not assume a particular density nor the ability to sample from it.
%We also conduct numerical experiments comparing with other methods such as (i) direct product of Gauss--Hermite quadrature, (ii) Sparse grid based on Gauss--Hermite, and (iii) scaled interlaced Sobol' sequence. This talk is based on a join work with Dirk Nuyens [1].
%
%[1]\;{\sc D.~Nuyens and Y.~Suzuki}, {\em Scaled lattice rules for integration on
% $\mathbb{R}^d$ achieving higher-order convergence with error analysis in
% terms of orthogonal projections onto periodic spaces}, arXiv preprint {\tt
% arXiv:2108.12639 [math.NA]}, (2021).
%\end{talk}
%
%\begin{talk}
% {Existence, uniqueness, and approximation for jump-driven SDEs with discontinuous drift}% [1] talk title
% {Michaela Sz\"olgyenyi}% [2] speaker name
% {University of Klagenfurt}% [3] affiliations
% {michaela.szoelgyenyi@aau.at}% [4] email
% {Pawe{\l} Przyby{\l}owicz, Fanhui Xu}% [5] coauthors
% {Stochastic Computation and Complexity: Approximation of SDEs with Non-Standard Coefficients}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{10:30}{11:00}{STC 1012}}% [7] time slot
% {2295}% [8] talk id
% {2290}% [9] session id
%
%In this talk we present an existence and uniqueness result of strong solutions to multi-dimensional jump-diffusion SDEs with discontinuous drift and general finite activity jumps. Jump-diffusion SDEs are used for example in models for applications in energy markets, where sudden movements of the energy price have to be captured.
%For a special scalar case, we study the strong convergence order of the Euler-Maruyama scheme and recover the optimal rate $1/2$.
%\end{talk}
%
%\begin{talk}
% {Option pricing and regularity of payoffs}% [1] talk title
% {Stefan Thonhauser}% [2] speaker name
% {Graz University of Technology}% [3] affiliations
% {stefan.thonhauser@math.tugraz.at}% [4] email
% {Florian Nachbagauer}% [5] coauthors
% {Simulation and Monte Carlo Methods in Quantitative Finance and Insurance} % [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{17:00}{17:30}{Lecture Hall 5}}% [7] time slot
% {2102}% [8] talk id
% {2100}% [9] session id
%We consider a problem of option pricing in a multi-variate financial market model from the perspective of quasi-Monte Carlo integration. For controlling the numerical approximation's error, the variation of the resulting integrand needs to be analyzed. In particular, we are able to show that a certain non-smooth payoff function leads to an integrand of bounded variation, even in the restrictive sense of Hardy and Krause. The key to this result is the application of a special transformation to the unit cube. The theoretical findings are illustrated by numerical examples and compared to results obtained using quantization techniques.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Randomized quasi-Monte Carlo methods: Central limit theorem and confidence interval}% [1] talk title
% {Bruno Tuffin}% [2] speaker name
% {Inria, Univ Rennes, CNRS, IRISA}% [3] affiliations
% {bruno.tuffin@inria.fr}% [4] email
% {Marvin K. Nakayama}% [5] coauthors
% {}% [6] special session
% {\timeslot{Monday, July 18, 2022}{12:00}{12:30}{Lecture Hall 6}}% [7] time slot
% {4514}% [8] talk id
% {4510}% [9] session id
%Quasi-Monte Carlo (QMC) methods are deterministic approximation methods to compute integrals by averaging the integrand taken at well-spread points of a \emph{low discrepancy sequence}, but for which practical error bounds are rarely available.
%Randomized quasi-Monte Carlo (RQMC) methods have been introduced to cope with this problem. The type of RQMC method
%we focus on during this talk consists in randomizing the low-discrepancy sequence without losing its good repartition property and for which an error estimation is obtained by applying a central limit theorem over independent randomizations.
%To increase precision
%for a given computational budget, the number of independent randomizations is usually set to a
%small value so that a large
%number of points are used from each randomized
%low-discrepancy sequence
%to benefit from the fast
%convergence rate of quasi-Monte Carlo.
%This talk presents sufficient conditions on the relative
%growth rates of the number of randomizations and the quasi-Monte Carlo sequence length to ensure a central limit theorem and also an asymptotically
%valid confidence interval. We obtain several results based on
%the Lindeberg condition and expressed in terms of the regularity of the integrand and the convergence speed of the
%quasi-Monte Carlo method.
%We also analyze the
%resulting estimator's
%convergence rate.
%
%\medskip
%
%The talk is based on the following papers:
%
%[1] Nakayama M. K, Tuffin B. Sufficient conditions for a central limit theorem to assess the error of randomized quasi-Monte Carlo methods. In the \emph{Proceedings of the 2021 Winter Simulation Conference} (IEEE), Phoenix, USA, December 2021.
%
%[2] Nakayama, M. K., and B. Tuffin. Sufficient Conditions for Central Limit Theorems and Confidence Intervals for
%Randomized Quasi-Monte Carlo Methods. Techreport hal-03196085, INRIA. \url{https://hal.inria.fr/hal-03196085}. 2021
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Rare event estimation with PDE-based models}% [1] talk title
% {Elisabeth Ullmann}% [2] speaker name
% {Technical University of Munich}% [3] affiliations
% {elisabeth.ullmann@tum.de}% [4] email
% {Jonas Latz, Iason Papaioannou, Fabian Wagner}% [5] coauthors
% {Approximate Models for Rare Event Simulation and Uncertainty Quantification}% [6] Special session title
% {\timeslot{Wednesday, July 20, 2022}{12:00}{12:30}{Lecture Hall 5}}% [7] time slot
% {2084}% [8] talk id
% {2080}% [9] session id
%The estimation of the probability of rare events is an important task in reliability and risk assessment of critical societal systems, for example, groundwater flow and transport, and engineering structures. In this talk we consider rare events that are expressed in terms of a limit state function which depends on the solution of a partial differential equation (PDE). We present recent progress on mathematical and computational aspects of this problem: (1) the impact of the PDE approximation error on the failure probability estimate, and (2) the use of the Ensemble Kalman Filter for the estimation of failure probabilities.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {On the power of function values for $L_2$-approximation}% [1] talk title
% {Mario Ullrich}% [2] speaker name
% {JKU Linz}% [3] affiliations
% {mario.ullrich@jku.at}% [4] email
% {Matthieu Dolbeault, David Krieg}% [5] coauthors
% {Approximation from Random Data}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{10:30}{11:00}{Lecture Hall 3}}% [7] time slot
% {2181}% [8] talk id
% {2180}% [9] session id
%We survey on recent developments on $L_2$-approximation
%using function values.
%In particular, we explain how the individual contributions from~[1,2,3,4]
%lead to the following statement:\\
%%
%There is a universal constant $c>0$ such that
%the sampling numbers %$g_{cn}$
%of the unit ball $F$ of every separable reproducing kernel Hilbert space
%are bounded by %the tails
%%$$ g_{n}(F)^2 \,\le\, \frac{C}{n}\sum_{k\geq \lfloor cn\rfloor} d_k(F)^2,$$
%$$ g_{cn}(F)^2 \,\le\, \frac{1}{n}\sum_{k\geq n} d_k(F)^2,$$
%where $d_k(F)$ are the Kolmogorov widths (or approximation numbers)
%of $F$ in $L_2$.
%We also obtain similar upper bounds for more general classes, and
%provide examples where our bounds are attained up to a constant. \\
%We also give pointers to other talks in this session, where
%%this result is extended, applied, or where similar results in other settings
%different aspects of this problem
%will be discussed.
%\begin{itemize}
%	\item[1] M. Dolbeault, D. Krieg and M. Ullrich,
%A sharp upper bound for sampling numbers in $L_2$,
%preprint.
%\item[2] D. Krieg and M. Ullrich,
%Function values are enough for $L_2$-approximation,
%\emph{Found.~Comput.~Math.} {\bf 21} (2021), 1141--1151.
%\item[3] D. Krieg and M. Ullrich,
%Function values are enough for $L_2$-approximation: Part II,
%\emph{J. Complexity} {\bf 66} (2021).
%\item[4] N. Nagel, M. Sch\"afer and T. Ullrich,
%A new upper bound for sampling numbers,
%\emph{Found.~Comput.~Math.} {\bf 21} (2021).
%\end{itemize}
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Exact sequential inference for a diffusion-driven Cox process}% [1] talk title
% {Szymon Urbas}% [2] speaker name
% {STOR-i CDT, Lancaster University}% [3] affiliations
% {s.urbas@lancaster.ac.uk}% [4] email
% {Chris Sherlock}% [5] coauthors
% {}% [6] special session
% {\timeslot{Thursday, July 21, 2022}{15:30}{16:00}{Lecture Hall 4}}% [7] time slot
% {4341}% [8] talk id
% {4340}% [9] session id
%Temporal point processes are widely used to model phenomena in areas such as finance, epidemiology or signal processing. One general model is the sigmoidal Gaussian Cox process (SGCP), first introduced in Adams et al. (2009), where a transformation the intensity function governing the data-generation is assigned a Gaussian process prior. The resulting model posterior, however, is doubly-intractable with its likelihood function not having a closed form, and so various data-augmentation schemes are required to perform likelihood-based inference.
%We introduce a novel unbiased estimator of the SGCP likelihood, motivated by the thinning procedure used to generate non-homogeneous Poisson process realisations. The proposed estimator is a generalisation of the existing \emph{Poisson estimator} of Wagner (1988) . By splitting the full observation window into smaller subintervals, a sequential Monte Carlo algorithm is used to perform exact inference on the intensity function, up to Monte Carlo error, with no need for data augmentation. Additionally, either a pseudo-marginal Markov chain Monte Carlo scheme or importance sampling can be used to sample from the hyper-parameter posteriors.
%\end{talk}
%
%
%
%\begin{talk}
% {Mobility estimation for Langevin dynamics using control variates}% [1] talk title
% {Urbain Vaes}% [2] speaker name
% {Inria Paris}% [3] affiliations
% {urbain.vaes@inria.fr}% [4] email
% {Grigorios Pavliotis, Gabriel Stoltz}% [5] coauthors
% {}% [6] special session
% {\timeslot{Friday, July 22, 2022}{09:30}{10:00}{Lecture Hall 6}}% [7] time slot
% {4582}% [8] talk id
% {4580}% [9] session id
%The scaling of the mobility of two-dimensional Langevin dynamics in a periodic potential as the friction vanishes is not well understood for non-separable potentials.
%Theoretical results are lacking,
%and numerical calculation of the mobility in the underdamped regime is challenging because
%the computational cost of standard Monte Carlo methods is inversely proportional to the friction coefficient,
%while deterministic methods are ill-conditioned.
%In this talk, we propose a new variance-reduction method based on control variates for efficiently estimating the mobility of Langevin-type dynamics.
%We provide bounds on the bias and variance of the proposed estimator,
%and illustrate its efficacy through numerical experiments,
%first in simple one-dimensional settings
%and then for two-dimensional Langevin dynamics.
%Our results corroborate previous numerical evidence that
%the mobility scales as~$\gamma^{-\sigma}$, where~$\gamma$ is the friction and~$0 < \sigma \leq 1$,
%in the low friction regime and in the case of a simple non-separable potential.
%\end{talk}
%
%
%
%\begin{talk}
% {Unbiased approximation of posteriors via coupled particle Markov chain Monte Carlo}% [1] talk title
% {Willem van den Boom}% [2] speaker name
% {National University of Singapore}% [3] affiliations
% {vandenboom@nus.edu.sg}% [4] email
% {Ajay Jasra, Maria De Iorio, Alexandros Beskos, Johan G.\ Eriksson}% [5] coauthors
% {Recent Advances in Unbiased Estimation Techniques}% [6] Special session title
% {\timeslot{Wednesday, July 20, 2022}{11:30}{12:00}{Lecture Hall 4}}% [7] time slot
% {2123}% [8] talk id
% {2120}% [9] session id
%Markov chain Monte Carlo (MCMC) is a powerful methodology for the approximation of posterior distributions. However, the iterative nature of MCMC does not naturally facilitate its use with modern highly parallel computation on HPC and cloud environments. Another concern is the identification of the bias and Monte Carlo error of produced averages. The above have prompted the recent development of fully (`embarrassingly') parallel unbiased Monte Carlo methodology based on coupling of MCMC algorithms. A caveat is that formulation of effective coupling is typically not trivial and requires model-specific technical effort. We propose coupling of MCMC chains deriving from sequential Monte Carlo (SMC) by considering adaptive SMC methods in combination with recent advances in unbiased estimation for state-space models. Coupling is then achieved at the SMC level and is, in principle, not problem-specific. The resulting methodology enjoys desirable theoretical properties. A central motivation is to extend unbiased MCMC to more challenging targets compared to the ones typically considered in the relevant literature. We illustrate the effectiveness of the algorithm via application to two complex statistical models: (i) horseshoe regression; (ii) Gaussian graphical models.
%\end{talk}
%
%
%\begin{talk}
% {A micro-macro Markov chain Monte Carlo method with applications in molecular dynamics}% [1] talk title
% {Hannes Vandecasteele}% [2] speaker name
% {KU Leuven}% [3] affiliations
% {hannes.vandecasteele@kuleuven.be}% [4] email
% {Giovanni Samaey}% [5] coauthors
% {}% [6] special session
% {\timeslot{Tuesday, July 19, 2022}{16:00}{16:30}{STC 1012}}% [7] time slot
% {4122}% [8] talk id
% {4120}% [9] session id
%In many problems and applications in molecular dynamics, one is typically interested in sampling from the time-invariant probability distributions of the system. Within many of these molecular systems, there is a natural time-scale separation present between the fast (microscopic) dynamics, and the slowly changing global conformation of the molecule determined by a few (macroscopic) variables.
%
%\vspace{2mm}
%Markov chain Monte Carlo (MCMC) is a general sampling algorithm that has been designed for sampling from probability distributions determined by a potential energy function. The objective is to construct a stochastic process whose time-invariant distribution is the invariant distribution of the molecular system By ergodicity, we can record samples from a single path of the process, and then these samples are consistent with invariant distribution. However, when the underlying system has a medium to large time-scale separation, the MCMC method may remain stuck in one of the local minima of the potential energy function, prohibiting a swift exploration of the complete state space of the molecular system.
%
%\vspace{2mm}
%In my talk, I will present a new micro-macro MCMC method (mM-MCMC) in which we first sample from the macroscopic variables, before reconstructing a new molecular instance that is consistent with the macroscopic value. I will give a detailed explanation of the algorithm, and show its efficiency on two molecular examples if time permits.
%\end{talk}
%
%
%\begin{talk}
% {Multilevel Markov Chain Monte Carlo for full-field data assimilation}% [1] talk title
% {Pieter Vanmechelen}% [2] speaker name
% {KU Leuven}% [3] affiliations
% {pieter.vanmechelen@kuleuven.be}% [4] email
% {Geert Lombaert, Giovanni Samaey}% [5] coauthors
% {}% [6] special session
% {\timeslot{Wednesday, July 20, 2022}{14:30}{15:00}{STC 1012}}% [7] time slot
% {4132}% [8] talk id
% {4130}% [9] session id
%In recent years, the development of new observation techniques in various branches of engineering disciplines has created the possibility of generating full-field data on systems under study. An example of this is Digital Image Correlation in structural mechanics, which allows for full-field vibration measurements of civil engineering structures.
%
%\smallskip
%
%In some cases, however, the resolution of this full-field data is so high that the computational cost of using this data to solve Bayesian inverse problems becomes prohibitively expensive. While the incorporation of expensive forward models in a data assimilation context has recently been addressed by the multilevel Monte Carlo methodology, the standard setting still assumes that measurement data is only available in selected measurement points.
%
%\smallskip
%
%In this talk, we show a successful generalisation of a multilevel Markov Chain Monte Carlo algorithm, proposed by [1] within the context of structural health monitoring using full-field vibration data. The method reduces computational efforts by allowing the resolution of the data to vary across levels, along with the resolution of the forward model. We discuss our results from [2] and show that the data can be scaled in a simple way to decrease the cost of likelihood evaluation at the coarser levels.
%
%\medskip
%
%[1] T.J. Dodwell, C. Ketelsen, R. Scheichl and A. Teckentrup. \textit{Multilevel Markov Chain Monte Carlo}, SIAM Rev. 61(3):509-545, 2019.
%\newline
%[2] P. Vanmechelen, G. Lombaert and G. Samaey. \textit{Multilevel Markov Chain Monte Carlo with likelihood scaling for full-field data assimilation in structural damage assessment}, in preparation.
%\end{talk}
%
%\newpage
%
%
%\begin{talk}
% {Zig-Zag for approximate Bayesian computation}% [1] talk title
% {Giorgos Vasdekis}% [2] speaker name
% {University of Warwick}% [3] affiliations
% {giorgos.vasdekis.1@warwick.ac.uk}% [4] email
% {Richard Everitt}% [5] coauthors
% {Recent Advances in Piecewise Deterministic Monte Carlo Methods}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{11:30}{12:00}{Lecture Hall 6}}% [7] time slot
% {2053}% [8] talk id
% {2050}% [9] session id
%Piecewise Deterministic Markov Processes (PDMPs) (see Fearnhead et.al.2018) have recently caught the attention of the MCMC community for having a non-diffusive behaviour and being able to explore the state space more efficiently. This makes them good candidates to generate MCMC algorithms.
%One important problem in Bayesian computation the last ten years is inference for models where the likelihood is intractable. A popular method to deal with problems in this setting is the Aprroximate Bayesian Computation (ABC). In this talk we describe a PDMP algorithm, based on the Zig-Zag process (see Bierkens and Roberts 2019), that is designed to target ABC posteriors. This way we combine the areas of PDMPs and ABC. We show that the algorithm targets the distribution of interest and we provide numerical examples to show its effectiveness. This is joint work with Richard Everitt.
%
%\medskip
%
%{\bf \large{References}}
%
%\begin{itemize}
%\item[] [1] J. Bierkens, P. Fearnhead, and G. Roberts. The zig-zag process and super-efficient sampling for bayesian
%analysis of big data. Ann. Statist., 47(3):1288–1320, 06 2019. doi: 10.1214/18-AOS1715. URL
%https://doi.org/10.1214/18-AOS1715.
%\item[] [2] R. Everitt and G. Vasdekis. ABC Zig-Zag. Under Preparation.
%\item[] [3] P. Fearnhead, J. Bierkens, M. Pollock, and G. Roberts. Piecewise deterministic markov processes for continuous-
%time monte carlo. Statistical Science, 33, 11 2016. doi: 10.1214/18-STS648
%\end{itemize}
%\end{talk}
%
%\newpage
%
%
%\begin{talk}
% {Optimal design of the Barker proposal and other locally-balanced Metropolis-Hastings algorithms}% [1] talk title
% {Jure Vogrinc}% [2] speaker name
% {University of Warwick}% [3] affiliations
% {Jure.Vogrinc@warwick.ac.uk}% [4] email
% {Samuel Livingstone, Giacomo Zanella}% [5] coauthors
% {Robust Innovations in Gradient-Based MCMC}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{10:30}{11:00}{Lecture Hall 4}}% [7] time slot
% {2271}% [8] talk id
% {2270}% [9] session id
%
%We study the class of first-order locally-balanced Metropolis-Hastings algorithms introduced in [1]. To choose a specific algorithm within the class the user must select a balancing function $g:\mathbb{R}\to\mathbb{R}$ satisfying $g(t)=tg(1/t)$, and a noise distribution for the proposal increment.
%Popular choices within the class are the Metropolis-adjusted Langevin algorithm (MALA) and the recently introduced robust alternative, the Barker proposal.
%We establish a universal limiting optimal acceptance rate of $57\%$ and scaling of $n^{-1/3}$ as the dimension $n$ tends to infinity among all members of the class under mild smoothness assumptions on $g$ and when the target distribution for the algorithm is of the product form.
%In particular we obtain an explicit expression for the asymptotic efficiency of an arbitrary algorithm in the class, as measured by expected squared jumping distance. We optimise this expression under various constraints. We derive an optimal choice of noise distribution for the Barker proposal, optimal choice of balancing function under a Gaussian noise distribution, and optimal choice of first-order locally-balanced algorithm among the entire class, which turns out to depend on the specific target distribution. Numerical simulations confirm our theoretical findings and in particular show that a bi-modal choice of noise distribution in the Barker proposal gives rise to a practical algorithm that is consistently at least as efficient as MALA and as robust as the original version of the Barker proposal with Gaussian noise.
%
%\medskip
%
%\begin{enumerate}
%\item[{[}1{]}] Samuel Livingstone and Giacomo Zanella. The Barker proposal: combining robustness and efficiency
%in gradient-based MCMC. \it{Journal of the Royal Statistical Society: Series B (Statistical Methodology),
%in press}, 2021.
%\end{enumerate}
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Schur's multiplication theorem and lower bounds for numerical integration}% [1] talk title
% {Jan Vyb\'iral}% [2] speaker name
% {Czech Technical University in Prague, Technical University of Munich}% [3] affiliations
% {jan.vybiral@fjfi.cvut.cz}% [4] email
% {Aicke Hinrichs, David Krieg, Erich Novak}% [5] coauthors
% {Approximation from Random Data}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{17:00}{17:30}{Lecture Hall 3}}% [7] time slot
% {2186}% [8] talk id
% {2180}% [9] session id
%The classical Schur's product theorem says that the coordinate-wise product of two
%symmetric positive semi-definite matrices is a positive semi-definite matrix.
%We derive a new version of the Schur's product theorem and use it to solve
%an open problem of Erich Novak about the tractability of numerical integration in high dimensions.
%Furthermore, we show the consequences of the new Schur's theorem for Bochner's theorem,
%covariance matrices and mean values of trigonometric polynomials.
%\end{talk}
%
%\begin{talk}
% {Well-posedness of the MAP estimator in sequence spaces}% [1] talk title
% {Philipp Wacker}% [2] speaker name
% {Freie Universit\"{a}t Berlin}% [3] affiliations
% {p.wacker@fu-berlin.de}% [4] email
% {Ilja Klebanov}% [5] coauthors
% {Laplace Approximation and Other Model-Based Preconditioning Methods for Monte Carlo Algorithms}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{17:30}{18:00}{Lecture Hall 6}}% [7] time slot
% {2263}% [8] talk id
% {2260}% [9] session id
%Many preconditioning methods rely on the existence of a ``mode'' or optimal point within the range of parameters around which to construct a region of special interest. For example, the Laplace approximation acts as a preconditioner which singles out (essentially) an elliptical region centered around the mode (i.e. point of highest density). In the context of Bayesian inversion, this mode is called the maximum-a-posteriori estimator (MAP estimator). While in finite dimensions, the MAP estimator is just the maximizer of the posterior density, it needs to be defined differently in infinite dimensional settings due to lack of a Lebesgue measure. We present new results regarding the well-posedness of this concept of ``point of highest density'' for parameter inference problems in sequence spaces $\ell^p$ with a diagonal Gaussian prior $\mu = \otimes N(0,\sigma_k^2)$. This includes and generalizes the case of parameter inference on arbitrary Hilbert spaces with a Gaussian prior.
%\end{talk}
%
%\begin{talk}
% {Comparison of Markov chains via weak Poincar\'e inequalities with application to pseudo-marginal MCMC}% [1] talk title
% {Andi Q.~Wang}% [2] speaker name
% {University of Bristol}% [3] affiliations
% {andi.wang@bristol.ac.uk}% [4] email
% {Christophe Andrieu, Anthony Lee, Sam Power}% [5] coauthors
% {Recent Advances in MCMC Sampling Techniques}% [6] Special session title
% {\timeslot{Tuesday, July 19, 2022}{18:00}{18:30}{Lecture Hall 4}}% [7] time slot
% {2214}% [8] talk id
% {2210}% [9] session id
%I will discuss the use of a certain class of functional inequalities known as weak Poincar\'e inequalities to bound convergence of Markov chains to equilibrium. We show that this enables the straightforward and transparent derivation of subgeometric convergence bounds for methods such as the Independent Metropolis--Hastings sampler and pseudo-marginal methods for intractable likelihoods, the latter being subgeometric in many practical settings. These results rely on novel quantitative comparison theorems between Markov chains. Associated proofs are simpler than those relying on drift and minorization conditions and the tools developed allow us to recover and further extend known results as particular cases. We are then able to provide new insights into the practical use of pseudo-marginal algorithms, such as analysing the effect of averaging in Approximate Bayesian Computation (ABC) and to study the case of lognormal weights relevant to Particle Marginal Metropolis--Hastings (PMMH).
%
%[1] Andrieu, C., Lee, A., Power, S., Wang, A. Q. (2021). Comparison of Markov chains via weak Poincar\'e inequalities with application to pseudo-marginal MCMC. Preprint available at \url{https://arxiv.org/abs/2112.05605}.
%\end{talk}
%
%\begin{talk}
% {Optimal approximation of break-of-scale embeddings}% [1] talk title
% {Markus Weimar}% [2] speaker name
% {Ruhr University Bochum}% [3] affiliations
% {markus.weimar@rub.de}% [4] email
% {Janina H\"ubner, Glenn Byrenheid}% [5] coauthors
% {}% [6] special session
% {\timeslot{Monday, July 18, 2022}{16:00}{16:30}{Lecture Hall 3}}% [7] time slot
% {4212}% [8] talk id
% {4210}% [9] session id
%As a rule of thumb in approximation theory, the asymptotic speed of convergence of numerical methods is governed by the regularity of the objects we like to approximate. Besides classical isotropic Sobolev smoothness, the notion of dominating mixed regularity of functions turned out to be an important concept in numerical analysis. Although approximation rates of embeddings \emph{within} the scales of isotropic or dominating-mixed $L_p$-Sobolev spaces are well-understood, not that much is known for embeddings \emph{across} those scales. In this talk we introduce particular instances of new hybrid smoothness spaces which cover both scales as special cases. Moreover, we present (non-)adaptive wavelet-based approximation algorithms that achieve optimal dimension-independent rates of convergence for certain practically important break-of-scale embeddings.
%
%
%\medskip
%
%References:
%\begin{itemize}
%	\item[{[1]}] G.~Byrenheid, J.~H\"{u}bner, and M.~Weimar. Rate-optimal sparse approximation of compact break-of-scale embeddings. In preparation, 2022+.
%\end{itemize}
%\end{talk}
%
%\begin{talk}
% {Covering numbers by intervals and equistribution theory}% [1] talk title
% {Christian Wei\ss{}}% [2] speaker name
% {Ruhr West University of Applied Sciences}% [3] affiliations
% {christian.weiss@hs-ruhrwest.de}% [4] email
% {}% [5] coauthors
% {}% [6] special session
% {\timeslot{Friday, July 22, 2022}{10:30}{11:00}{Lecture Hall 6}}% [7] time slot
% {4584}% [8] talk id
% {4580}% [9] session id
%Kronecker sequences belong to the classical examples of low-discrepancy sequences. From a dynamical viewpoint, they are realized as orbits of circle rotations by an irrational angle $\alpha$. Moreover, the corresponding maps $f_\alpha$ are known to be dynamical systems of rank one. This means that there exist base sets $B$ such that for arbitrarily high $h \in \mathbb{N}$ an arbitrarily large proportion of the circle can be covered by the Rokhlin tower $(f_\alpha^k(B))_{k=0}^{h-1}$. However, these sets $B$ might be very complicated from a topological point of view. In this talk, we discuss how well topologically simple base sets $B$, i.e. unions of intervals, perform in covering the circle by a Rokhlin tower. We will also see how finding these simpler sets is related to the pair correlation statistic.
%
%\medskip
%
%[1] C. Wei\ss{}. \textit{Systems of rank one, explicit Rokhlin towers, and covering numbers}.to appear in: Arch. Math., 2021.
%\end{talk}
%
%\begin{talk}
% {A multilevel subset simulation for estimating rare events via shaking transformations}% [1] talk title
% {Simon Weissmann}% [2] speaker name
% {University of Heidelberg}% [3] affiliations
% {simon.weissmann@uni-heidelberg.de}% [4] email
% {Daniel Elfverson, Robert Scheichl, Francisco Alejandro Diaz De la O}% [5] coauthors
% {Smoothing and Adaptive Methods}% [6] Special session title
% {\timeslot{Friday, July 22, 2022}{10:00}{10:30}{STC 1012}}% [7] time slot
% {2137}% [8] talk id
% {2130}% [9] session id
%In this talk, we analyse a multilevel version of subset simulation to estimate the probability
%of rare events for complex physical systems. Given a sequence of nested failure domains of
%increasing size, the rare event probability is expressed as a product of conditional probabilities. The proposed estimator uses different model resolutions and varying numbers of samples across the hierarchy of nested failure sets. The key idea in our proposed estimator is the use of a selective refinement strategy
%that guarantees the critical subset property which may be violated when changing model resolution from one failure set to the next.
%In order to estimate the probabilities of the underlying subsets we formulate and analyse a parallel one-path algorithm based on shaking transformations. Considering a physical model based on Gaussian transformation we can verify the ergodicity of the resulting Markov chain. Additionally, we present a detailed complexity analysis of the considered subset simulation.
%\end{talk}
%
%%\newpage
%
%\begin{talk}
% {Applications of the central limit theorem for pricing cliquet-style options}% [1] talk title
% {J\"{o}rg Wenzel}% [2] speaker name
% {Fraunhofer ITWM}% [3] affiliations
% {joerg.wenzel@itwm.fraunhofer.de}% [4] email
% {Ralf Korn, B\"{u}\c{s}ra Zeynep Temo\c{c}in}% [5] coauthors
% {Simulation and Monte Carlo Methods in Quantitative Finance and Insurance}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{17:30}{18:00}{Lecture Hall 5}}% [7] time slot
% {2103}% [8] talk id
% {2100}% [9] session id
%Cliquet-style options in different variants are basic building
% blocks in select products which are offered by German life insurance
% companies. We present both an analytical pricing approximation via
% the central limit theorem and a corresponding control variate Monte
% Carlo approach for their valuation. The control variate approach
% turns out to be a good alternative to the integral representation of
% [1]. Further, it can be modified to increase the
% efficiency of pricing cliquet-style options in the Heston price
% setting.
%
%\medskip
%
% [1] Bernard, C., Li, W.V.: Pricing and hedging of cliquet options and locally-capped contracts.
%SIAM J. Fin. Math. 4, 353–371, (2013)
%\end{talk}
%
%\newpage
%
%
%\begin{talk}
% {Efficient importance sampling via stochastic optimal control for stochastic reaction networks}% [1] talk title
% {Sophia Wiechert}% [2] speaker name
% {RWTH Aachen University}% [3] affiliations
% {wiechert@uq.rwth-aachen.de}% [4] email
% {Chiheb Ben Hammouda, Nadhir Ben Rached, Ra\'{u}l Tempone}% [5] coauthors
% {Monte Carlo Methods and Variance Reduction Techniques for Stochastic Reaction Networks}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{11:30}{12:00}{Lecture Hall 5}}% [7] time slot
% {2033}% [8] talk id
% {2030}% [9] session id
%We explore the efficient estimation of statistical quantities, particularly rare event probabilities, for stochastic reaction networks and biochemical systems. To this end, we propose a novel importance sampling (IS) approach to improve the efficiency of Monte Carlo (MC) estimators when based on an approximate tau-leap scheme. The crucial step in the IS framework is choosing an appropriate change of probability measure for achieving substantial variance reduction. Typically, this is challenging and often requires insights into the given problem. Based on an original connection between finding the optimal IS parameters within a class of probability measures and a stochastic optimal control (SOC) formulation, we propose an automated approach to obtain a highly efficient path-dependent measure change. The optimal IS parameters are obtained by solving a variance minimization problem. We begin by deriving an associated backward equation solved by these optimal parameters. Given the challenge of analytically solving this backward equation, we propose a numerical dynamic programming algorithm to approximate the optimal control parameters. To mitigate the curse of dimensionality issue caused by solving the backward equation in the multi-dimensional case, we propose a learning-based method that approximates the value function using a neural network, the parameters of which are determined via a stochastic optimization algorithm. Our numerical experiments demonstrate that our learning-based IS approach substantially reduces the variance of the MC estimator. Moreover, when applying the numerical dynamic programming approach for the particular one-dimensional case, we obtained a variance that decays at a rate of $\mathcal{O}(\Delta t)$ for a step size of $\Delta t$, compared to $\mathcal{O}(1)$ for a standard MC estimator. For a given prescribed error tolerance, $\text{TOL}$, this implies an improvement in the computational complexity to become $\mathcal{O}(\text{TOL}^{-2})$ instead of $\mathcal{O}(\text{TOL}^{-3})$ when using a standard MC estimator.
%\medskip
%
%{[1]} Hammouda, C. B., Rached, N. B., Tempone, R., \& Wiechert, S. (2021). Optimal Importance Sampling via Stochastic Optimal Control for Stochastic Reaction Networks. arXiv preprint arXiv:2110.14335.
%\end{talk}
%
%
%\begin{talk}
% {A randomised lattice algorithm for integration using a fixed generating vector}% [1] talk title
% {Laurence Wilkes}% [2] speaker name
% {KU Leuven}% [3] affiliations
% {laurence.wilkes@kuleuven.be}% [4] email
% {Frances Y.~Kuo, Dirk Nuyens}% [5] coauthors
% {Approximation from Random Data}% [6] Special session title
% {\timeslot{Thursday, July 21, 2022}{17:30}{18:00}{Lecture Hall 3}}% [7] time slot
% {2187}% [8] talk id
% {2180}% [9] session id
%This talk will focus on a new randomised algorithm for lattice-based integration. In $[1]$, it was shown that there exists a randomised algorithm producing a lattice rule which gives the optimal rate of convergence for the worst-case expected error and in $[2]$, it was shown that this rate can be achieved with a constructible randomised algorithm. These two algorithms involve choosing both the generating vector and the number of sample points at random. In this talk we will see that, with a carefully selected generating vector, only the number of sample points need be chosen at random in order to achieve the optimal rate of convergence for the worst-case expected error.
%
%\medskip
%
%\begin{enumerate}
% \item[{[1]}] P. Kritzer, F. Y. Kuo, D. Nuyens, M. Ullrich ``Lattice rules with random n achieve nearly the optimal $O(n^{-\alpha-1/2})$ error independently of the dimension.'' \emph{Journal of Approximation Theory} 240 (2019): 96-113.
% \item[{[2]}] J. Dick, T. Goda, K. Suzuki ``Component-by-component construction of randomized rank-1 lattice rules achieving almost the optimal randomized error rate.'' \emph{preprint} (2021)
%\end{enumerate}
%\end{talk}
%
%
%\newpage
%
%
%\begin{talk}
% {Pseudorandom sequences derived from automatic sequences} % [1] talk title
% {Arne Winterhof}% [2] speaker name
% {Austrian Academy of Sciences}% [3] affiliations
% {arne.winterhof@ricam.oeaw.ac.at}% [4] email
% {L\'{a}szl\'{o} M\'{e}rai}% [5] coauthors
% {Pseudo-Random Number Generation.}% [6] special session.
% {\timeslot{Friday, July 22, 2022}{10:30}{11:00}{Lecture Hall 5}}% [7] time slot
% {2224}% [8] talk id
% {2220}% [9] session id
%Many automatic sequences, such as the Thue-Morse sequence or the Rudin-Shapiro sequence,
%have some desirable features of pseudorandomness such as a large linear complexity and a small well-distribution measure.
%However, they also have some undesirable properties in view of certain applications. For example, the majority of possible binary patterns never appears in automatic sequences and their correlation measure of order $2$ is extremely large.
%
%Certain subsequences, such as automatic sequences along squares, may keep the good properties of the original sequence but avoid the bad ones.
%
%In this survey talk we investigate properties of pseudorandomness and non-randomness of automatic sequences and their subsequences and present results on their behaviour under several measures of pseudorandomness including linear complexity, correlation measure of order $k$, expansion complexity and normality.
%
%
%\begin{enumerate}
% \item[{[1]}] L. M\'erai, A. Winterhof, Pseudorandom sequences derived from automatic sequences,
% Cryptogr. Commun., to appear, \url{https://arxiv.org/abs/2105.03086}.
%\end{enumerate}
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Which problems can be solved by randomized algorithms?}% [1] talk title
% {Marcin Wnuk}% [2] speaker name
% {University of Osnabr\"{u}ck}% [3] affiliations
% {marcin.wnuk@uni-osnabrueck.de}% [4] email
% {}% [5] coauthors
% {}% [6] special session.
% {\timeslot{Monday, July 18, 2022}{11:30}{12:00}{Lecture Hall 6}}% [7] time slot
% {4513}% [8] talk id
% {4510}% [9] session id
%Let $F$ and $G$ be separable Banach spaces. A linear problem is given by a continuous linear operator $S:F \rightarrow G.$ The aim ist to approximate $S(f)$ for each $f \in F$ by means of an algorithm. Approximation error of an algorith $A$ is given by
%$$e^{det}(A,S) = \sup_{f \in F, \lVert f \rVert_{F} = 1} \lVert S(f) - A(f) \rVert_{G} \quad \text{if $A$ is a deterministic algorithm}$$
%and
%$$e^{ran}(A,S) = \sup_{f \in F, \lVert f \rVert_{F} = 1} \mathbb{E}\left[ \lVert S(f) - A(\omega, f) \rVert_{G} \right] \quad \text{if $A$ is a randomized algorithm}.$$
%Denote by $e^{\det}(n,S)$ the minimal error of any deterministic algorithm using at most $n$ information evaluation. We say that the problem $S$ is solvable in the deterministic setting when
%$$\lim_{n \rightarrow \infty} e^{det}(n,S) = 0.$$
%We define $e^{ran}(n,S)$ analogously and say that the problem $S$ is solvable in the randomized setting if
%$$\lim_{n \rightarrow \infty} e^{ran}(n,S) = 0.$$
%In this talk we focus on the situation when we can use any continuous functional on $F$ as an information.
%
%The main question is: which problems are solvable? It is well-known that in the deterministic setting the problem given by $S$ is solvable if and only if $S$ is a compact operator. The situation seems to be more complicated if we allow for randomized algorithms. In this talk we sketch the proof that if the operator $S$ is not finitely strictly singular then it is certainly not solvable in the randomized setting. Furthermore, we present an example demonstrating that the proof technique used cannot be succesfully applied to show that only compcat operators are solvable in the randomized setting. In the end we present some open questions.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Analysis and optimization of certain parallel Monte Carlo methods in the low temperature limit}% [1] talk title
% {Guo-Jhen Wu}% [2] speaker name
% {KTH Royal Institute of Technology}% [3] affiliations
% {gjwu@kth.se}% [4] email
% {Paul Dupuis}% [5] coauthors
% {}% [6] special session.
% {\timeslot{Thursday, July 21, 2022}{16:00}{16:30}{Lecture Hall 4}}% [7] time slot
% {4342}% [8] talk id
% {4340}% [9] session id
%Metastability is a formidable challenge to Markov chain Monte Carlo methods. In this talk we present methods for algorithm design to meet this challenge. The design problem we consider is temperature selection for the infinite swapping scheme, which is the limit of the widely used parallel tempering scheme obtained when the swap rate tends to infinity. We use a recently developed tool for the large deviation properties of the empirical measure of a metastable small noise diffusion to transform the variance reduction problem into an explicit graph optimization problem. The nodes in the graph optimization problem correspond to metastable states of the noiseless dynamics. Our first analysis of the optimization problem is in the setting of a double well model, and it shows that the optimal selection of temperature ratios is a geometric sequence except possibly the highest temperature. In the same setting we identify two different sources of variance reduction, and show how their competition determines the optimal highest temperature. In the general multi-well setting we prove that the same geometric sequence of temperature ratios as in the two-well case is always nearly optimal, with a performance gap that decays geometrically in the number of temperatures. Moreover, this optimal placement of temperatures is explicit and independent of the particular functional being integrated on the potential.
%
%\medskip
%
%[1] P. Dupuis, G.-J. Wu (2022) “Analysis and optimization of certain parallel Monte Carlo methods in the low temperature limit”, \textit{SIAM Journal Multiscale Modeling and Simulation}, Vol 20, 220--249.
%
%[2] P. Dupuis, G.-J. Wu (2021) “Large deviation properties of the empirical measure of a metastable small noise diffusion”, \textit{Journal of Theoretical Probability}.
%
%[3] P. Dupuis, Y. Liu, N. Plattner and J. D. Doll (2012) “On the infinite swapping limit for parallel tempering”, \textit{SIAM Journal Multiscale Modeling and Simulation}, Vol 10, 986--1022.
%\end{talk}
%
%\newpage
%
%
%
%\begin{talk}
% {Managing the risk of derivatives underlying portfolios}% [1] talk title
% {Wei Xu}% [2] speaker name
% {Toronto Metropolitan University (formerly Ryerson University)}% [3] affiliations
% {wei.xu@ryerson.ca}% [4] email
% {}% [5] coauthors
% {}% [6] special session.
% {\timeslot{Tuesday, July 19, 2022}{16:00}{16:30}{Lecture Hall 5}}% [7] time slot
% {4422}% [8] talk id
% {4420}% [9] session id
%Derivatives underlying a portfolio is popular on the market to diversify the market risk. However, existing method, the nested simulation, is quite time-consuming for pricing and managing the risk. In this article, we propose an efficient approach, randomized willow tree method. There are three main stages for our approach, portfolio distribution approximation, randomized willow tree construction and managing the risk of derivatives. We first generate some simulated paths to describe the evolution of dynamic portfolio values. Then, the minimal relative entropy (MRE) method is applied to approximate the distribution of portfolio values at each time based on the simulated data. After the approximated distributions are determined, a randomized willow tree can be constructed for pricing and managing the risk of derivatives underlying the portfolio. Finally, we apply the proposed approach to calculate annual dollar delta, 99\% VaR and CVaR of a particular derivative, i.e., a 19-year variable annuity with guarantee riders. This application demonstrates the efficiency and accuracy of the proposed approach compared with the common nested simulation technique, especially for a large pool of derivatives underlying the same portfolio.%
%\end{talk}
%
%
%\begin{talk}
% {Stereographic Markov chain Monte Carlo}% [1] talk title
% {Jun Yang}% [2] speaker name
% {University of Oxford}% [3] affiliations
% {jun.yang@stats.ox.ac.uk}% [4] email
% {Krzysztof \L{}atuszy\'{n}ski and Gareth O.\, Roberts}% [5] coauthors
% {}% [6] special session.
% {\timeslot{Tuesday, July 19, 2022}{15:30}{16:00}{STC 1012}}% [7] time slot
% {4121}% [8] talk id
% {4120}% [9] session id
%High dimensional distributions, especially those with heavy tails, are notoriously difficult for off the shelf MCMC samplers: the combination of unbounded state spaces, diminishing gradient information, and local moves, results in empirically observed "stickiness" and poor theoretical mixing properties -- lack of geometric ergodicity. In this talk, we introduce a new class of MCMC samplers that map the original high dimensional problem in Euclidean space onto a sphere and remedy these notorious mixing problems. In particular, we develop random-walk Metropolis type algorithms as well as versions of Bouncy Particle Sampler that are uniformly ergodic for a large class of light and heavy tailed distributions and also empirically exhibit rapid convergence in high dimensions.
%\end{talk}
%
%\newpage
%
%\begin{talk}
% {Multi-index sequential Monte Carlo and randomized multi-index sequential Monte Carlo ratio estimators}% [1] talk title
% {Shangda Yang}% [2] speaker name
% {University of Manchester}% [3] affiliations
% {shangda.yang@manchester.ac.uk}% [4] email
% {Kody J.H. Law, Xinzhu Liang}% [5] coauthors
% {Recent Advances in Unbiased Estimation Techniques}% [6] Special session title
% {\timeslot{Wednesday, July 20, 2022}{12:00}{12:30}{Lecture Hall 4}}% [7] time slot
% {2124}% [8] talk id
% {2120}% [9] session id
%We consider the problem of estimating expectations with respect to a target
%distribution with an unknown normalizing constant, and where even the unnormalized
%target needs to be approximated at finite resolution.
%This setting is ubiquitous across science and engineering applications,
%for example in the context of Bayesian inference where a physics-based model
%governed by an intractable partial differential equation (PDE) appears in the likelihood.
%A multi-index sequential Monte Carlo (MISMC) method and a randomised multi-index sequential Monte Carlo method are used to construct ratio estimators
%which provably enjoy the complexity improvements of multi-index Monte Carlo (MIMC)
%as well as the efficiency of Sequential Monte Carlo (SMC) for inference. The ratio estimators are constructed by the ratio of two unbiased estimators of the corresponding unnormalised targets. This introduces discretisation bias to MISMC method, but the partially unbiased formulation offers the theoretical evidence of convergence under realistic assumptions. By leveraging a randomisation strategy as randomised MISMC, the bias can be removed entirely, which simplies estimation substantially. Both of the proposed methods provably achieve the canonical complexity
%of MSE$^{-1}$, while single level methods require MSE$^{-\xi}$
%for $\xi>1$. This is illustrated on examples of Bayesian inverse problems with an elliptic PDE forward model in $2$ spatial dimensions, where
%$\xi$ is $3/2$. It is also illustrated on a more challenging
%log Gaussian Cox model from spatial statistics,
%where single level complexity is {approximately $\xi=9/4$} and
%multilevel Monte Carlo (or MIMC with an inappropriate index set) gives {$\xi = 5/4 + \omega$, for $\omega > 0$},
%whereas our methods are again canonical.
%\end{talk}




% ----------------------------------------------------------------
% ----------------------------------------------------------------
% ----------------------------------------------------------------



\input{MCQMC2024_book_practical_info}

% ----------------------------------------------------------------
% ----------------------------------------------------------------
% ----------------------------------------------------------------
\scnote{Commented out the following file to fix error}
%\input{ParticipantsNoEmail}
\input{Participants}
\end{document}

