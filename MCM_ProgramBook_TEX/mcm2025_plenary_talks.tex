\chapter{Plenary Talks}
\newpage

\begin{talk}
	{Stochastic Approximation beyond the gradient case}% [1] talk title
	{Gersende Fort}% [2] speaker name
	{CNRS, Institut de Math\'ematiques de Toulouse, France}% [3] affiliations
	{gersende.fort@math.univ-toulouse.fr}% [4] email
	{}% [5] coauthors
	{}% [6] special session
	{\timeslot{Monday, August 19, 2024}{14:00}{15:00}{STC 1012}}% [7] time slot
	{PL01}% [8] talk id
	{photo}% [9] session id or photo
	In statistical learning, many analyses and methods rely on optimization, including its stochastic versions introduced for example, to overcome an intractability of the objective function or to reduce the computational cost of the deterministic optimization step.

In 1951, H. Robbins and S. Monro introduced a novel iterative algorithm, named "Stochastic Approximation", for the computation of the zeros of a function defined by an expectation with no closed-form expression. This algorithm produces a sequence of iterates, by replacing at each iteration the unknown expectation with a Monte Carlo approximation based on one sample. Then, this method was generalized: it is a stochastic algorithm designed to find the zeros of a vector field  when only stochastic oracles of this vector field are available.

 

Stochastic Gradient Descent algorithms are the most popular examples of Stochastic Approximation : oracles come from a Monte Carlo approximation of a large sum. Possibly less popular are examples named "beyond the gradient case", for at least two reasons. First, they rely on oracles that are biased approximation of the vector field, as it  occurs when biased Monte Carlo sampling is used for the definition of the oracles. Second, the vector field is not necessarily a gradient vector field. Many examples in Statistics and more generally in statistical learning are "beyond the gradient case": among examples, let us cite compressed stochastic gradient descent, stochastic Majorize-Minimization methods such as the Expectation-Maximization algorithm, or the Temporal Difference algorithm in reinforcement learning.

 

In this talk, we will show that these "beyond the gradient case" Stochastic Approximation algorithms  still converge, even when the oracles are biased, as soon as some parameters of the algorithm are tuned enough. We will discuss what 'tuned enough' means  when the convergence criterion relies on epsilon-approximate stationarity, and we will comment the efficiency of the algorithm through sample complexity.  Such analyses are based on non-asymptotic convergence bounds in expectation: we will present a unified method to obtain such bounds for a large class of Stochastic Approximation methods including both the gradient case and the beyond the gradient case.


\end{talk}

\clearpage

\begin{talk}
	{Randomized lattice rules for high-dimensional integration}% [1] talk title
	{Takashi Goda}% [2] speaker name
	{School of Engineering, The University of Tokyo}% [3] affiliations
	{goda@frcer.t.u-tokyo.ac.jp}% [4] email
	{}% [5] coauthors
	{}% [6] special session
	{\timeslot{Thursday, August 22, 2024}{09:00}{10:00}{STC 1012}}% [7] time slot
	{PL02}% [8] talk id
	{photo}% [9] session id or photo
	Lattice rules have been extensively studied for high-dimensional numerical integration. One crucial question has been how to select good generating vectors. It has been shown both in theory and practice that good generating vectors can be selected by component-wise greedy optimization, known as the component-by-component construction. On the other hand, the standard error analyses for such constructive approaches rely on the averaging argument (i.e., the best one is better than the average), and so, the Markov inequality implies that there exist many equally good generating vectors. The aim of this talk is to present some new results for randomized lattice rules by exploiting the property that ``the most of the generating vectors are good.''

The first result involves randomly selecting generating vectors multiple times, obtaining several integral estimates, and then using their median as the final estimate. This method is proven robust to the smoothness and weight parameters of the weighted Korobov spaces. Secondly, when employing the mean square error as a measure criterion, we provide two implementable randomization methods that exploit the property that ``the most of the generating vectors are good'' to improve the convergence rate compared to worst-case error.

This talk builds up on the results from several papers and acknowledges the contributions of my collaborators (in alphabetical order): Josef Dick, Pierre L'Ecuyer, and Kosuke Suzuki.
\end{talk}

\clearpage

\begin{talkcr}
	{Some recent approaches to sampling recovery}% [1] talk title
	{David Krieg}% [2] speaker name
	{University of Passau, Germany}% [3] affiliations
	{david.krieg@uni-passau.de}% [4] email
	{}% [5] coauthors
	{}% [6] special session
	{\timeslot{Monday, August 19, 2024}{09:00}{10:00}{STC 1012}}% [7] time slot
	{PL03}% [8] talk id
	{photo}% [9] session id or photo
	Recovering a function based on a finite sample of its function values is a very natural problem.
The question for good sampling nodes and for good recovery algorithms 
already fueled mathematical research 
more than a hundred years ago
when, for instance, the Chebyshev nodes turned out to be almost optimal
for the task of uniform approximation of univariate functions by polynomials. 
The question is no less important now, as intelligent people and intelligent machines alike try to find (typically very high-dimensional) functions that describe the behavior of their data and which are suited to give reliable predictions. 
Consequently, the theory is immense and there is a great variety of results, especially when it comes to particular instances of function approximation problems.

In this talk, I want to present some recent results and approaches to the problem that are of a general nature and which are supposed to give some insight on the power of sampling algorithms in general. 
Namely, we discuss how close sampling algorithms can get you
to (a)~the best approximation within a finite-dimensional space of your choice,
(b)~the best sparse approximation with respect to a dictionary,
or (c)~the best linear approximation procedure (like a truncated singular value decomposition).

In other words, 
we want to compare the sampling numbers 
\[
 g_n(F,L_p) \,:=\, \inf_{\substack{x_1,\hdots,x_n\in D \\ \phi\colon \mathbb{C}^n \to L_p(D)}}
 \,\sup_{f\in F}\, \big\Vert f - \phi\big( f(x_1),\dots,f(x_n)\big)\big\Vert_{L_p(D)}
\]
of a class $F$ of functions on a measure space $D$ 
with singular numbers, with approximation numbers, with Kolmogorov widths, and with best $m$-term widths. 
It turns out that, in many scenarios, sampling algorithms 
can get us surprisingly close to the three desired approximation benchmarks 
if we choose the sampling points $x_i$ and the recovery map $\phi$ optimally.
\end{talkcr}

\clearpage

\begin{talk}
 {Lattice rules, kernel methods, DNNs, and how to connect them}% [1] talk title
 {Frances Kuo}% [2] speaker name
 {University of New South Wales (Sydney), Australia}% [3] affiliations
 {f.kuo@unsw.edu.au}% [4] email
 {}% [5] coauthors
 {}% [6] special session
 {\timeslot{Wednesday, August 21, 2024}{14:00}{15:00}{STC 1012}}% [7] time slot
 {PL04}% [8] talk id
 {photo}% [9] session id or photo

Lattice rules are my favorite family of quasi-Monte Carlo methods. They are proven to be effective for high dimensional integration and multivariate function approximation in a number of settings. They are extremely easy to implement thanks to their very simple formulation --- all we require is a ``good'' integer vector of length matching the dimensionality of the problem. We know how to construct such good vectors tailored to applications in different areas, e.g., in PDEs with random coefficients, both for computing expected values (integrals) of quantities of interest as well as in obtaining surrogates of the PDE solution using lattice-based kernel interpolants. In recent years there has been a burst of research activities on the application and theory of Deep Neural Networks (DNNs). We explore how lattice rules can be used in the framework of DNNs.

This is based on joint work with Alexander Keller (NVIDIA), Dirk Nuyens (KU Leuven) and Ian H. Sloan (UNSW Sydney). 
\end{talk}

\clearpage

\begin{talk}
 {Bootstrap with One (or Few) Resamples: Statistical Optimality and an Integrative View on Data and Monte Carlo Uncertainties}% [1] talk title
 {Henry Lam}% [2] speaker name
 {Columbia University, USA}% [3] affiliations
 {khl2114@columbia.edu}% [4] email
 {}% [5] coauthors
 {}% [6] special session
 {\timeslot{Thursday, August 22, 2024}{14:00}{15:00}{STC 1012}}% [7] time slot
 {PL05}% [8] talk id
 {photo}% [9] session id or photo
 
While the bootstrap is demonstrably powerful in quantifying statistical uncertainty, its implementation could face substantial computation from repeated resampling. We present a bootstrap implementation that can drive down the number of resamples to minimally possible, namely as low as one, while maintaining valid coverage guarantees. Our approach is empowered by an integrative view on the statistical noise in the data and the Monte Carlo noise in the resampling together, in contrast to separately handling them in conventional bootstraps. We leverage our idea to efficiently quantify uncertainty in several tasks, including neural network training, simulation modeling and stochastic gradient descent. We also explain the statistical optimality of our implementation and compare it against other competing low-computation inference methods.
\end{talk}

\clearpage

\begin{talk}
	{Richardson Extrapolation meets Multi-Fidelity Modelling}% [1] talk title
	{Chris Oates}% [2] speaker name
	{Newcastle University, UK}% [3] affiliations
	{chris.oates@ncl.ac.uk}% [4] email
	{Toni Karvonen, Aretha Teckentrup, Marina Strocchi, Steven Niederer}% [5] coauthors
	{}% [6] special session
	{\timeslot{Wednesday, August 21, 2024}{09:00}{10:00}{STC 1012}}% [7] time slot
	{PL06}% [8] talk id
	{photo}% [9] session id or photo
	For over a century, extrapolation methods have provided a powerful tool to improve the convergence order of a numerical method. However, these tools are not well-suited to modern computer codes, where multiple continua are discretised and convergence orders are not easily analysed. To address this challenge we present a probabilistic perspective on Richardson extrapolation, a point of view that unifies classical extrapolation methods with modern multi-fidelity modelling, and handles uncertain convergence orders by allowing these to be statistically estimated. The approach is developed using Gaussian processes, leading to Gauss-Richardson Extrapolation (GRE). Conditions are established under which extrapolation using the conditional mean achieves a polynomial (or even an exponential) speed-up compared to the original numerical method. Further, the probabilistic formulation unlocks the possibility of experimental design, casting the selection of fidelities as a continuous optimisation problem which can then be (approximately) solved. A case-study involving a computational cardiac model demonstrates that practical gains in accuracy can be achieved using the GRE method.
\end{talk}

\clearpage

\begin{talk}
	{Simulation algorithms for branching recursions}% [1] talk title
	{Mariana Olvera-Cravioto}% [2] speaker name
	{UNC-Chapel Hill, USA}% [3] affiliations
	{molvera@email.unc.edu}% [4] email
	{}% [5] coauthors
	{}% [6] special session
	{\timeslot{Tuesday, August 20, 2024}{14:00}{15:00}{STC 1012}}% [7] time slot
	{PL07}% [8] talk id
	{photo}% [9] session id or photo
	Many interesting problems today, ranging from the analysis of centrality measures on large complex networks, some algorithms for community detection, to problems in statistical physics and the analysis of opinions on social networks, involve large graphs whose analysis leads to branching recursions. The analysis of branching recursions can often be done using distributional fixed-point equations, which in some cases can easily provide formulas for means and variances of the processes being studied. In general, computing the distribution of such processes, or even their moments in non-linear recursions, must be done numerically. However, large graphs in the original problems give rise to branching recursions with very large mean number of offspring, i.e., fast geometric growth, making any naïve simulation idea impractical. This talk discusses two different types of efficient simulation algorithms: one for computing the distribution of solutions to branching stochastic fixed-point equations, known as population dynamics, and one for computing rare event probabilities for the branching random walk.
\end{talk}

\clearpage

\begin{talk}
	{Recent progress in error estimation for quasi-Monte Carlo}% [1] talk title
	{Art Owen}% [2] speaker name
	{Stanford University, USA}% [3] affiliations
	{owen@stanford.edu}% [4] email
	{Michael Gnewuch, Peter Kritzer, Pierre L'Ecuyer, Marvin Nakayama,  Zexin Pan, Bruno Tuffin}% [5] coauthors
	{}% [6] special session
	{\timeslot{Tuesday, August 20, 2024}{09:00}{10:00}{STC 1012}}% [7] time slot
	{PL08}% [8] talk id
	{photo}% [9] session id or photo
	For many high dimensional integration problems, Quasi-Monte Carlo methods
attain the best accuracy.  In settings where high accuracy is required it is
also valuable to show that it has been attained. Those two criteria are somewhat
at odds with each other.  This talk looks at recent ways to quantify the
accuracy attained by QMC.  It includes progress in forming confidence
intervals based on replication of randomized QMC.  The surprise there is that
a plain Student's t based confidence interval method proved to be much more
reliable than some bootstrap methods that were expected to be best [1].  A second
area of recent progress provides computable and provable upper and lower
bounds on the integral.  These methods require special QMC points that
have a non-negative local discrepancy property along with an integrand
that has a complete monotonicity property [2]. Briefly: some of the best
QMC accuracy results arise for a median of means strategy [3,4].  That raises
a severe challenge of quantifying the uncertainty in a mean when one
has computed a median.				

\medskip

[1] L’Ecuyer P, Nakayama MK, Owen AB, Tuffin B. Confidence intervals for randomized quasi-Monte Carlo estimators. In 2023 Winter Simulation Conference (pp. 445--456).

[2] Gnewuch M, Kritzer P, Owen AB, Pan Z. Computable error bounds for quasi-Monte Carlo using points with non-negative local discrepancy. arXiv preprint arXiv:2309.04209. 

[3] Pan Z, Owen A. Super-polynomial accuracy of one dimensional randomized nets using the median of means. Mathematics of Computation. 2023. 92(340):805--837.

[4] Pan Z, Owen A. Super-polynomial accuracy of multidimensional randomized nets using the median-of-means. Mathematics of Computation. 2024.

\end{talk}

\begin{talkp}
    {30 years of MCQMC -- Panel Discussion}
    {Aretha Teckentrup}
    {Josef Dick, Fred J.~Hickernell, Alexander Keller, Frances~Y.~Kuo, Art B.~Owen}
    {\timeslot{Friday, August 23, 2024}{09:00}{10:00}{STC 1012}}% [7] time slot}
    {PL30}
    The first MCQMC Conference was initiated by Harald Niederreiter and was held in Las Vegas in 1994. This 16th installment of the MCQMC Conference therefore marks the 30th anniversary of the conference. With this panel discussion, we wish to reflect as a community on how the field evolved in 30 years, what has been the impact of the MCQMC conference on our respective research careers, and what are the new big ideas or interesting open problems. Questions will be asked to the panelists by the moderator to initiate the conversation, followed by a Q\&A and general sharing of comments and reflections. 
    
\end{talkp}