
\documentclass[12pt,a4paper,figuresright]{book}





\usepackage{amsmath,amssymb}
\usepackage{tabularx,graphicx,url,xcolor,rotating,multicol,epsfig,colortbl}

\setlength{\textheight}{25.2cm}
\setlength{\textwidth}{16.5cm} %\setlength{\textwidth}{18.2cm}
\setlength{\voffset}{-1.6cm}
\setlength{\hoffset}{-0.3cm} %\setlength{\hoffset}{-1.2cm}
\setlength{\evensidemargin}{-0.3cm} 
\setlength{\oddsidemargin}{0.3cm}
\setlength{\parindent}{0cm} 
\setlength{\parskip}{0.3cm}


\setlength{\floatsep}{12pt plus 2pt minus 2pt}








% -- adding a talk
\newenvironment{talk}[6]% [1] talk title
                         % [2] speaker name, [3] affiliations, [4] email,
                         % [5] coauthors, [6] special session
                         % [7] time slot
                         % [8] talk id, [9] session id or photo
 {%\needspace{6\baselineskip}%
  \vskip 0pt\nopagebreak%
%   \colorbox{gray!20!white}{\makebox[0.99\textwidth][r]{}}\nopagebreak%
%   \ifthenelse{\equal{#9}{photo}}{%
%                     \\\\\colorbox{gray!20!white}{\makebox{\includegraphics[width=3cm]{#8}}}\nopagebreak}{}%
 \vskip 0pt\nopagebreak%
%  \label{#8}%
  \textbf{#1}\vspace{3mm}\\\nopagebreak%
  \textit{#2}\\\nopagebreak%
  #3\\\nopagebreak%
  \url{#4}\vspace{3mm}\\\nopagebreak%
  \ifthenelse{\equal{#5}{}}{}{Coauthor(s): #5\vspace{3mm}\\\nopagebreak}%
  \ifthenelse{\equal{#6}{}}{}{Special session: #6\quad \vspace{3mm}\\\nopagebreak}%
 }
 {\vspace{1cm}\\\nopagebreak}%



\pagestyle{empty}

% ------------------------------------------------------------------------
% Document begins here
% ------------------------------------------------------------------------
\begin{document}



\begin{talk}
  {On diffusion-based generative models and their error bounds: The log-concave case with full convergence estimates.}% [1] talk title
  {Stefano Bruno}% [2] speaker name
  {University of Edinburgh}% [3] affiliations
  {sbruno@ed.ac.uk}% [4] email
  {Sotirios Sabanis, {\"O}mer Deniz Akyildiz, Dong-Young Lim, Ying Zhang}% [5] coauthors
  {}% [6] special session. Leave this field empty for contributed talks. 
				% Insert the title of the special session if you were invited to give a talk in a special session.

				
				

Diffusion-based generative models are a recent class of generative models showing state-of-art performances in many data generation tasks. These models use a forward process to progressively corrupt samples from a target data distribution with noise and then learn to reverse this process for generation of new samples. In this talk, we provide full theoretical guarantees for the convergence behaviour of such models. We demonstrate via a motivating example, sampling from a Gaussian distribution with unknown mean, the powerfulness of our approach.  In this case, explicit estimates are provided for the associated optimization problem, i.e. score approximation, while these are combined with the corresponding sampling estimates. As a result,  we obtain the best known estimates for the Wasserstein distance of order two between the data distribution and our sampling algorithm. Beyond the motivating example, we present our results for sampling from strongly log-concave distributions using an $L^2$-accurate score estimation assumption, which is formed under an expectation with respect to a stochastic optimizer and our novel auxiliary process that uses only known information. This talk is relevant to the special session ‘Stochastic Computation and Complexity’ and other related sessions.

\medskip

[1] S Bruno, Y Zhang, DY Lim, {\"O} D Akyildiz, S Sabanis. On diffusion-based generative models and their error bounds: The log-concave case with full convergence estimates. (2023).	arXiv:2311.13584. 
%If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots . Please refrain from 
%using the \texttt{bibliography} environment or \texttt{bibtex} files. 
\end{talk}


\end{document}