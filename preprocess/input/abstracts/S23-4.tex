\documentclass[12pt,a4paper,figuresright]{book}

\usepackage{amsmath,amssymb}
\usepackage{tabularx,graphicx,url,xcolor,rotating,multicol,epsfig,colortbl}

\setlength{\textheight}{25.2cm}
\setlength{\textwidth}{16.5cm} %\setlength{\textwidth}{18.2cm}
\setlength{\voffset}{-1.6cm}
\setlength{\hoffset}{-0.3cm} %\setlength{\hoffset}{-1.2cm}
\setlength{\evensidemargin}{-0.3cm} 
\setlength{\oddsidemargin}{0.3cm}
\setlength{\parindent}{0cm} 
\setlength{\parskip}{0.3cm}

% -- adding a talk
\newenvironment{talk}[6]% [1] talk title
                         % [2] speaker name, [3] affiliations, [4] email,
                         % [5] coauthors, [6] special session
                         % [7] time slot
                         % [8] talk id, [9] session id or photo
 {%\needspace{6\baselineskip}%
  \vskip 0pt\nopagebreak%
%   \colorbox{gray!20!white}{\makebox[0.99\textwidth][r]{}}\nopagebreak%
%   \ifthenelse{\equal{#9}{photo}}{%
%                     \\\\\colorbox{gray!20!white}{\makebox{\includegraphics[width=3cm]{#8}}}\nopagebreak}{}%
 \vskip 0pt\nopagebreak%
%  \label{#8}%
  \textbf{#1}\vspace{3mm}\\\nopagebreak%
  \textit{#2}\\\nopagebreak%
  #3\\\nopagebreak%
  \url{#4}\vspace{3mm}\\\nopagebreak%
  \ifthenelse{\equal{#5}{}}{}{Coauthor(s): #5\vspace{3mm}\\\nopagebreak}%
  \ifthenelse{\equal{#6}{}}{}{Special session: #6\quad \vspace{3mm}\\\nopagebreak}%
 }
 {\vspace{1cm}\nopagebreak}%

\pagestyle{empty}

% ------------------------------------------------------------------------
% Document begins here
% ------------------------------------------------------------------------
\begin{document}
	
\begin{talk}
  {Delocalization of Bias in Unadjusted Hamiltonian Monte Carlo}% [1] talk title
  {Xiaoou Cheng}% [2] speaker name
  {New York University}% [3] affiliations
  {chengxo@nyu.edu}% [4] email
  {Yifan Chen, Jonathan Niles-Weed, Jonathan Weare}% [5] coauthors
  {Analysis of Langevin and Related Sampling Algorithms, Part I}% [6] special session. Leave this field empty for contributed talks. 
				% Insert the title of the special session if you were invited to give a talk in a special session.
			
Hamiltonian Monte Carlo is a commonly used algorithm to sample high dimensional probability distributions. However, for strongly log-concave distributions, existing analyses of the unadjusted algorithm show that the number of iterations follows a power law in terms of the dimension $d$, to ensure convergence within a desired error in the $W_2$ metric. Also, because of the large bias, Hamiltonian Monte Carlo is often Metropolized to remove the bias effectively. [1] suggests that for unadjusted Langevin algorithm, similar power law dimension scaling of convergence and bias in the $W_2$ metric can be misleading. There, for strongly log-concave distributions with certain sparse interactions, the \emph{marginal} distribution of a small number of $K$ variables can be well-approximated in the $W_2$ metric, with a small number of iterations proportional to $K$ up to \emph{logarithmic} terms in $d$. A novel $W_{2,\ell^\infty}$ metric is used in analysis. We show that this \emph{delocalization of bias} effect also exists in unadjusted Hamiltonian Monte Carlo with the leapfrog integrator, which suggests that Metropolization may not be necessary in this situation. A key observation is that the propagator of the leapfrog integrator is closely related to Chebyshev polynomials.

\medskip

% If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
% Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.
% APA reference style is recommended.
\begin{enumerate}
	\item[{[1]}] Chen, Y., Cheng, X., Niles-Weed, J., \& Weare, J. (2024). Convergence of Unadjusted Langevin in High Dimensions: Delocalization of Bias. \textit{arXiv preprint arxiv: 2408.13115}.
\end{enumerate}

\end{talk}

\end{document}

