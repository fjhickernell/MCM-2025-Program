\documentclass[12pt,a4paper,figuresright]{book}

\usepackage{amsmath,amssymb}
\usepackage{tabularx,multirow,graphicx,url,wrapfig,xcolor,rotating,multicol,epsfig,colortbl}

\setlength{\textheight}{25.2cm}
\setlength{\textwidth}{16.5cm} %\setlength{\textwidth}{18.2cm}
\setlength{\voffset}{-1.6cm}
\setlength{\hoffset}{-0.3cm} %\setlength{\hoffset}{-1.2cm}
\setlength{\evensidemargin}{-0.3cm}
\setlength{\oddsidemargin}{0.3cm}
\setlength{\parindent}{0cm}
\setlength{\parskip}{0.3cm}

\renewcommand{\topfraction}{1}
\renewcommand{\textfraction}{0}
\setlength{\floatsep}{12pt plus 2pt minus 2pt}

\newenvironment{session}[7] % [1] session title
                            % [2] organiser name, [3] affiliations, [4] email
                            % [5] organiser name, [6] affiliations, [7] email
                            % [8] session id
 {%\needspace{6\baselineskip}
  \vskip 0pt\nopagebreak%
  %\label{#8}%
  \textbf{#1}\vspace{3mm}\\\nopagebreak%
  \ifthenelse{\equal{#5}{ }}{Organizer:}{Organizers:}\vspace{2mm}\\\nopagebreak%
  \textit{#2}\\\nopagebreak%
  #3\\\nopagebreak%
  \url{#4}\vspace{3mm}\\\nopagebreak%
  \ifthenelse{\equal{#5}{ }}{}{\textit{#5}\\\nopagebreak%
                              #6\\\nopagebreak%
                              \url{#7}\vspace{3mm}\\\nopagebreak}%
  \quad\\\nopagebreak%
  %Session Description:\vspace{3mm}\\\nopagebreak%
 }
 {\nopagebreak}%

\pagestyle{empty}

% ------------------------------------------------------------------------
% Document begins here
% ------------------------------------------------------------------------
\begin{document}

\begin{session}
  {Heavy-tailed Sampling}% [1] session title
  {2} %[2]  number of organizers
  {\organizer{Alex Shestopaloff}% [2] organizer name
    {Queen Mary University of London, UK}% [3] affiliations
    {a.shestopaloff@qmul.ac.uk}}% [4] email
  {\organizer{Jun Yang}% [5] second organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
    {University of Copenhagen, Denmark}% [6] second organizer affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
    {jy@math.ku.dk}}% [7] second organizer email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
  {\organizer{}% organizer three name
	{}% organizer three affiliations
	{}}% organizer three email
	
Heavy-tailed distributions frequently arise in modern statistics, machine learning, and applied sciences, yet their intricate properties pose significant challenges for computational inference. This session, Heavy-Tailed Sampling, brings together cutting-edge advances in Monte Carlo methods and stochastic optimization to address these challenges. The topics span theoretical breakthroughs and practical algorithms, showcasing how heavy-tailed phenomena influence algorithmic design and performance. Our session aims to inspire new methods and applications in the broader Monte Carlo community. The session will explore:
\begin{itemize}
    \item 
Langevin Monte Carlo for Heavy-Tailed Distributions: A comprehensive complexity analysis of Langevin-based samplers for heavy-tailed targets using weighted Poincar√© inequalities. The results reveal fundamental limits of mean-square analysis and include innovative techniques for gradient approximation.
\item
Stereographic MCMC: A novel class of samplers that map Euclidean spaces onto spheres to resolve mixing issues inherent to heavy-tailed targets. These methods, featuring uniform ergodicity and rapid convergence, capitalize on the "blessings of dimensionality" to enhance performance in high dimensions.
\item
Large Deviation Principles in MCMC: A groundbreaking application of large deviation theory to assess and improve MCMC algorithms. This approach extends to Metropolis-Hastings and related methods on general state spaces, providing new insights into empirical measure convergence and rate functions.
\item 
Heavy-Tailed Phenomena in Stochastic Gradient Descent (SGD): An analysis of heavy-tailed noise in SGD and its impact on escaping sharp minima in deep learning. The session highlights a variant of SGD with gradient truncation, offering theoretical and empirical evidence of enhanced generalization through flatter minima.
\end{itemize}
\end{session}
\medskip

List of speakers
\begin{itemize}
    \item Murat A.~Erdogdu, University of Toronto, Canada
    \item Sebastiano Grazzi, Bocconi University, Italy
    \item Federica Milinanni, KTH Royal Institute of Technology, Sweden
    \item Xingyu Wang,  University of Amsterdam, Netherlands
\end{itemize}






\end{document}

