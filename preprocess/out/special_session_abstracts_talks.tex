\chapter{Abstracts}\newpage\section{Special Session Talks}

\begin{talk}
  {Quantitative Approximation of Stochastic Kinetic Equations: From Discrete to Continuum}% [1] talk title
  {Chengcheng Ling}% [2] speaker name
  {University of Augsburg}% [3] affiliations
  {chengcheng.ling@uni-a.de}% [4] email
  {Stochastic Computation and Complexity, Part I}% [5] coauthors
  {}% [6] special session
  {Mon, Jul 28 10:30–12:30}% [7] time slot
  {S1-1}% [8] talk id
  {S1}% [9] session id or photo

We study the strong convergence of a generic tamed Euler-Maruyama (EM) scheme for the kinetic type stochastic differential equation (SDE) (also known as second order SDE) driven by $\alpha$-stable type noise with $\alpha\in(1,2]$. We show that when the drift exhibits a relatively low regularity: anisotropic $\beta$-H\''older continuity with $\beta >1 - \frac{\alpha}{2}$, the corresponding tamed EM converges with a convergence rate $(\frac{1}{2} + \frac{\beta}{\alpha(1+\alpha)} \wedge \frac{1}{2})$, which aligns with the results of  first-order SDEs.


This talk is based on the work arXiv:2409.05706 (joint with Zimo Hao and Khoa L\^e)  and the work arXiv:2412.05142.

\medskip


\end{talk}

\begin{talk}
  {A strong order $1.5$ boundary preserving discretization scheme for scalar SDEs defined in a domain}% [1] talk title
  {Andreas Neuenkirch}% [2] speaker name
  {University of Mannheim}% [3] affiliations
  {neuenkirch@uni-mannheim.de}% [4] email
  {Ruishu Liu, Xiaojie Wang}% [5] coauthors
  {Stochastic Computation and Complexity}% [6] special session
  {Mon, Jul 28 10:30–12:30}% [7] time slot
  {S1-2}% [8] talk id
  {S1}% [9] session id or photo
				
			
We study the strong approximation of scalar SDEs, which take values in a domain and have non-Lipschitz coefficients.
By combining a Lamperti-type transformation with a semi-implicit discretization approach and a taming 
strategy,  we construct a domain-preserving scheme that strongly converges under weak assumptions. 
Moreover,
we show that this scheme has strong convergence order $1.5$ under additional assumptions on the coefficients of the SDE. In our scheme, the domain preservation is a consequence of the semi-implicit discretization approach, while the taming strategy allows controlling terms of the scheme that admit singularities but are required to obtain the desired order.

Our general convergence results  are  applied to various SDEs from applications, with sub-linearly or super-linearly growing and non-globally Lipschitz coefficients.


\medskip

\begin{enumerate}
	\item[{[1]}]  Ruishu Liu, Andreas Neuenkirch and Xiaojie Wang (2024+). A strong order $1.5$
	boundary preserving discretization scheme for scalar SDEs defined in a domain. {\it Mathematics of Computation.} doi:10.1090/mcom/4014 (to appear, online first)
\end{enumerate}
.
\end{talk}

\begin{talk}
  {Christopher Rauh\"ogger}% [1] talk title
  {University of Passau}% [2] speaker name
  {christopher.rauhoegger@uni-passau.de}% [3] affiliations
  {Stochastic Computation and Complexity}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Mon, Jul 28 10:30–12:30}% [7] time slot
  {S1-3}% [8] talk id
  {S1}% [9] session id or photo
				
			
We consider $d$-dimensional systems of SDEs with a discontinuous drift coefficient. More precisely,
we assume that there exists a $C^{5}$-hypersurface
$\Theta\subseteq \mathbb{R}^{d}$ such that the drift coefficient is intrinsic Lipschitz continuous on $\mathbb{R}^{d}\setminus \Theta$ and has intrinsic Lipschitz continuous derivative on $\mathbb{R}^{d}\setminus \Theta$.
Furthermore, the diffusion coefficient is $C^{1}$ on $\mathbb{R}^{d}$ and commutative with a bounded derivative that is intrinsic Lipschitz continuous on $\mathbb{R}^{d}\setminus \Theta$.

It was proven in [1] for $d = 1$ and more recently in [2] for general $d \in \mathbb{N}$ that in this setting a transformed Milstein scheme achieves an $L_{p}$-error rate of order at least $3/4-$ in terms of the number of evaluations of the
driving Brownian motion.
Furthermore it was proven in [3] that for $d = 1$ in the same setting an adaptive Milstein-type scheme achieves an $L_{p}$-error rate of order at least $1$ in terms of the average number of evaluations of the driving Brownian motion. 

In this talk we present a generalisation of the result from [3] to higher dimensions. More precisely, we introduce an adaptive transformed Milstein scheme which can be used for the approximation of solutions of $d$-dimensional systems of SDEs at the final time point in this setting and
prove that this scheme achieves an $L_{p}$-error rate of order at least $1$ in terms of the average number of evaluations of the
driving Brownian motion.

\medskip

\begin{enumerate}
	\item[{[1]}] M\''{u}ller-Gronbach, Thomas \& Yaroslavtseva, Larisa. (2022). {\it A strong order 3/4 method for {SDE}s with discontinuous drift
		coefficient}. IMA Journal of Numerical Analysis. 42. 229-259
	\item[{[2]}] Rauh\''ogger, Christopher. (2025+). {\it Milstein-type methods for strong approximation of systems of SDEs with a discontinuous drift coefficient}. In preparation
	\item[{[3]}] Yaroslavtseva, Larisa. (2022). {\it An adaptive strong order 1 method for {SDE}s with
		discontinuous drift coefficient}. Journal of Mathematical Analysis and Applications. 513. 2. Paper Number 126180, 29
\end{enumerate}

\end{talk}

\begin{talk}
  {Stong order 1 adaptive approximation of jump-diffusion SDEs with discontinuous drift}% [1] talk title
  {Verena Schwarz}% [2] speaker name
  {University of Klagenfurt}% [3] affiliations
  {verena.schwarz@aau.at}% [4] email
  {Stochastic Computation and Complexity}% [5] coauthors
  {}% [6] special session
  {Mon, Jul 28 10:30–12:30}% [7] time slot
  {S1-4}% [8] talk id
  {S1}% [9] session id or photo
				

In this talk we present an adaptive approximation scheme for jump-diffusion SDEs with discontinuous drift and (possibly) degenerate diffusion. The scheme is a transformation-based doubly-adaptive quasi-Milstein scheme, which 
is doubly-adaptive in the sense that it is jump-adapted, i.e.~all jump times of the Poisson noise are grid points, and it includes an adaptive stepsize strategy to account for the discontinuities of the drift. It is proven to have strong convergence rate $1$ in $L^p$ for $p\in[1,\infty)$ with respect to the average computational cost for these SDEs. 
To obtain our result, we prove that under slightly stronger assumptions which are still weaker than those in existing literature, a related doubly-adaptive quasi-Milstein scheme has convergence order $1$. 
\end{talk}

\begin{talk}
  {QMC for Bayesian optimal experimental design with application to inverse problems governed by PDEs}% [1] talk title
  {Vesa Kaarnioja}% [2] speaker name
  {Free University of Berlin}% [3] affiliations
  {vesa.kaarnioja@fu-berlin.de}% [4] email
  {Claudia Schillings}% [5] coauthors
  {Nested expectations: models and estimators, Part I}% [6] special session
  {Mon, Jul 28 10:30–12:30}% [7] time slot
  {S3-1}% [8] talk id
  {S3}% [9] session id or photo
				
			
The goal in Bayesian optimal experimental design (OED) is to maximize the expected information gain for the reconstruction of unknown quantities in an experiment by optimizing the placement of measurements. The objective function in the resulting optimization problem involves a multivariate double integral over the high-dimensional parameter and data domains. For the efficient approximation of these integrals, we consider a sparse tensor product combination of quasi-Monte Carlo (QMC) cubature rules over the parameter and data domains. For the parameterization of the unknown quantitites, we consider a model recently studied by Chernov and L\^{e} [1,2] as well as Harbrecht, Schmidlin, and Schwab [3] in which the input random field is assumed to belong to a Gevrey class. The Gevrey class contains functions that are infinitely many times continuously differentiable with a growth condition on the higher-order partial derivatives, but which are not analytic in general. Using the techniques developed in [4], we investigate efficient Bayesian OED for inverse problems governed by partial differential equations (PDEs).
\begin{enumerate}
	\item[{[1]}] Chernov, Alexey, \& L\^{e}, T\`{u}ng (2024). Analytic and Gevrey class regularity for parametric elliptic eigenvalue problems and applications. \emph{SIAM Journal on Numerical Analysis}, \textbf{62}(4), 1874--1900.
	\item[{[2]}] Chernov, Alexey, \& L\^{e}, T\`{u}ng (2024). Analytic and Gevrey class regularity for parametric semilinear reaction-diffusion problems and applications in uncertainty quantification. \emph{Computers \& Mathematics with Applications}, \textbf{164}, 116--130.
	\item[{[3]}] Harbrecht, Helmut, Schmidlin, Marc, \& Schwab, Christoph (2024). The Gevrey class implicit mapping theorem with applications to UQ of semilinear elliptic PDEs. \emph{Mathematical Models and Methods in Applied Sciences}, \textbf{34}(5), 881--917.
	\item[{[4]}] Kaarnioja, Vesa, \& Schillings, Claudia (2024). Quasi-Monte Carlo for Bayesian design of experiment problems governed by parametric PDEs. Preprint, \emph{arXiv:2405.03529 [math.NA]}.
\end{enumerate}

\end{talk}

\begin{talk}
  {Double-loop randomized quasi-Monte Carlo estimator for nested integration}% [1] talk title
  {Sebastian Krumscheid}% [2] speaker name
  {Karlsruhe Institute of Technology}% [3] affiliations
  {sebastian.krumscheid@kit.edu}% [4] email
  {Arved Bartuska, Andr\'{e} Gustavo Carlon, Luis Espath, Ra\'{u}l Tempone}% [5] coauthors
  {}% [6] special session
  {Mon, Jul 28 10:30–12:30}% [7] time slot
  {S3-2}% [8] talk id
  {S3}% [9] session id or photo
  
				
			
We present a double-loop randomized quasi-Monte Carlo estimator for nested integrals. This estimator applies the randomized quasi-Monte Carlo (rQMC) method to both integrals in the nested setting. Error bounds are derived for outer integrands displaying singularities at the boundaries of the integration domain, based on Owen's work [1]. Standard error bounds via the Koksma--Hlawaka inequality are rendered ineffective as singularities lead to infinite Hardy--Krause variation. Moreover, finite element discretizations of the inner integrand are discussed, increasing the overall cost of nested integral estimators. 

The effectiveness of the proposed estimator is demonstrated in the Bayesian design setting for the estimation of the expected information gain of an experiment. A truncation scheme of the observation noise present in the experiment model allows for the application of the derived error bounds. Applications from pharmacokinetics and thermomechanics demonstrate the efficiency of the proposed method in high dimensions.

\medskip

\begin{enumerate}
	\item[{[1]}] Owen, Art B. (2006). {\it Halton sequences avoid the origin}. SIAM Review, 48:487–503.
\end{enumerate}

\end{talk}

\begin{talk}
  {Posterior-Free A-Optimal Bayesian Design of Experiments via Conditional Expectation}% [1] talk title
  {Truong Vinh Hoang}% [2] speaker name
  {hoang@uq.rwth-aachen.de}% [3] affiliations
  {Luis Espath, Sebastian Krumscheid, Ra\'ul Tempone}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Mon, Jul 28 10:30–12:30}% [7] time slot
  {S3-3}% [8] talk id
  {S3}% [9] session id or photo
  
				
			

\medskip

We propose a novel approach for solving the A-optimal Bayesian design of experiments that does not require sampling or approximating the posterior distribution. In this setting, the objective function is the expected conditional variance (ECV).
Our method estimates the ECV by leveraging conditional expectation, which we approximate using its orthogonal projection property. We derive an asymptotic error bound for this estimator and validate it through numerical experiments.
The method is particularly efficient when the design parameter space is continuous. In such scenarios, the conditional expectation can be approximated non-locally using tools such as neural networks. To reduce the number of evaluations of the measurement model, we incorporate transfer learning and data augmentation.
Numerical results show that our method significantly reduces model evaluations compared to standard importance sampling-based techniques.
Code available at: \href{https://github.com/vinh-tr-hoang/DOEviaPACE}{https://github.com/vinh-tr-hoang/DOEviaPACE}.

\begin{enumerate}
    \item [{[1]}] Hoang, V., Espath, L., Krumscheid, S., \& Tempone, R. (2025).  
    Scalable method for Bayesian experimental design without integrating over posterior distribution. {\it SIAM ASA Journal on Uncertainty Quantification, 13}(1), 114-139. \\
    \href{https://doi.org/10.1137/23M1603364}{https://doi.org/10.1137/23M1603364}
\end{enumerate}


\end{talk}

\begin{talk}
  {Optimal designs for function discretization and construction of tight frames}% [1] talk title
  {Kateryna Pozharska}% [2] speaker name
  {pozharska.k@gmail.com}% [3] affiliations
  {Felix Bartel,  Lutz K\"ammerer,  Martin Sch\"afer, Tino Ullrich}% [4] email
  {Stochastic Computation and Complexity}% [5] coauthors
  {}% [6] special session
  {Mon, Jul 28 15:30–17:30}% [7] time slot
  {S5-1}% [8] talk id
  {S5}% [9] session id or photo
				



\medskip

In the talk we will present a direct and constructive approach approach for the construction of tight frames and exact Marcinkiewicz-Zygmund inequalities in the Lebesque space [1]. 
It is based on a similar procedure of maximization of the determinant of a certain Gramian matrix with respect to points and weights, already used in [2] for discretization problem for the uniform norm, and results in a discrete measure  with at most $n^2+1$ atoms, which accurately subsamples the $L_2$-norm of complex-valued functions contained in a  given $n$-dimensional subspace.

This approach can as well be used for the reconstruction of functions from general RKHS in $L_p$ where one only has access to the most important eigenfunctions. The general results apply to the $d$-sphere or multivariate trigonometric polynomials on $\mathbb{T}^d$ spectrally supported on arbitrary finite index sets~$I \subset \mathbb{Z}^d$.  Numerical experiments indicate the sharpness of this result.


\begin{enumerate}
	\item[{[1]}]  Bartel, Felix,  \& Kämmerer, Lutz,  \& Pozharska,  Kateryna, \& Schäfer, Martin,  \& \newline Ullrich, Tino (2024). {\it Exact discretization, tight frames and recovery via $D$-optimal designs}. arXiv:2412.02489.
    
	\item[{[2]}] Krieg, David, \&  Pozharska, Kateryna, \& Ullrich, Mario \&  Ullrich, Tino (2024). \newline  {\it Sampling projections in the uniform norm}. arXiv:2401.02220.

\end{enumerate}


\end{talk}

\begin{talk}
  {Optimality of deterministic and randomized QMC-cubatures on several scales of function spaces}% [1] talk title
  {Michael Gnewuch}% [2] speaker name
  {University of Osnabrueck}% [3] affiliations
  {mgnewuch@uos.de}% [4] email
  {Josef Dick, Lev Markhasin, Winfried Sickel, Yannick Meiners}% [5] coauthors
  {Stochastic Computation and Complexity}% [6] special session
  {Mon, Jul 28 15:30–17:30}% [7] time slot
  {S5-2}% [8] talk id
  {S5}% [9] session id or photo
				
			
			
We study the integration problem over the s-dimensional unit cube on four scales of Banach spaces of integrands. First we consider Haar wavelet spaces $H_{p, q, \alpha}$, $1\le p, q \le \infty$, $\alpha > 1/p$, consisting of functions whose Haar wavelet coefficients exhibit a certain decay behavior measured by the parameters $p,q$, and, most importantly, $\alpha$.  We study the worst case error of a deterministic cubature rule over the norm unit ball 
%(i.e., the operator norm of the difference of the integration functional and the cubature rule)
and provide upper bounds for quasi-Monte Carlo (QMC) cubature rules based on arbitrary $(t,m,s)$-nets as well as matching lower error bounds for arbitrary cubature rules. These results show that using arbitrary $(t,m,s)$-nets as integration nodes yields the best possible rate of convergence. In the Hilbert space setting $p=2 = q$ it was earlier shown by Heinrich, Hickernell and Yue [2]  that scrambled (t,m,s)-nets yield optimal convergence rates in the randomized setting, where the randomized worst case error is considered. 

We establish several suitable function space embeddings that allow to transfer the deterministic and randomized upper error bounds on Haar wavelet spaces
to certain spaces of fractional smoothness $1/p < \alpha  \le 1$ and to Sobolev and Besov spaces of dominating mixed smoothness $1/p < a \le 1$.
Known lower bounds for Sobolev and Besov spaces of dominating mixed smoothness show that (deterministic or suitably randomized) $(t,m,s)$-nets yield optimal convergence rates also on the corresponding scales of spaces.			

The talk is based on the preprint [1] and the master thesis of my student Yannick Meiners.
\medskip

\begin{enumerate}
	\item[{[1]}] M. Gnewuch, J. Dick, L. Markhasin, W. Sickel, QMC integration based on arbitrary $(t,m,s)$-nets yields optimal convergence rates on several scales of function spaces, preprint 2024, arXiv:2409.12879. 
        \item[{[2]}] S. Heinrich, F. J. Hickernell and R. X. Yue, Optimal quadrature for Haar wavelet spaces, Math. Comput., 73 (2004), 259–277.
	\end{enumerate}

\end{talk}

\begin{talk}
  {Complexity of approximating piecewise smooth functions in the presence of deterministic or random noise}% [1] talk title
  {Leszek Plaskota}% [2] speaker name
  {University of Warsaw}% [3] affiliations
  {L.Plaskota@mimuw.edu.pl}% [4] email
  {Stochastic Computation and Complexity}% [5] coauthors
  {}% [6] special session
  {Mon, Jul 28 15:30–17:30}% [7] time slot
  {S5-3}% [8] talk id
  {S5}% [9] session id or photo
				
			
Consider the smoothness class of $1$-periodic functions $f:\mathbb R\to\mathbb R$ for which 
$$|f^{(r)}(x)-f^{(r)}(y)|\le |x-y|^\rho,\quad x,y\in\mathbb R,$$ 
where $r\in\{0,1,2,\ldots\}$ and $0<\rho\le 1.$ It is well known that the optimal worst case error of $L^p$-approximation ($1\le p\le\infty$) of such functions that can be achieved from $n$ exact evaluations of $f$ is proportional to $e_n=n^{-(r+\rho)}.$ Less obvious is what happens when the functions are piecewise smooth only with unknown break points. Even less obvious is the situation when the function values are additionally corrupted by some noise, i.e., when evaluating the value of $f$ at $x$ we obtain $y=f(x)+\xi$ where $|\xi|\le\delta$ (determnistic noise) or $\xi$ is a zero-mean random variable of variance $\sigma^2$ (random noise). In this talk we construct an algorithm which despite the presence of noise and break points achieves the worst case $L^p$-error still proportional to $e_n$ provided the noise level $\delta$ or $\sigma$ is of the same order $e_n$ (exept the case of $p=\infty$ and random noise where we have an additional logarithmic factor in the error). The algorithm uses divided differences and special adaptive extrapolation technique to locate the break points and approximate in their neighborhoods. 

\end{talk}

\begin{talk}
  {Wasserstein Convergence of Score-based Generative Models under Semiconvexity and Discontinuous Gradients}% [1] talk title
  {Sotirios Sabanis}% [2] speaker name
  {University of Edinburgh \& National Technical University of Athens \& Archimedes/Athena Research Centre}% [3] affiliations
  {s.sabanis@ed.ac.uk}% [4] email
  {Stefano Bruno}% [5] coauthors
  {Stochastic Computation and Complexity}% [6] special session
  {Tue, Jul 29 10:30–12:30}% [7] time slot
  {S8-1}% [8] talk id
  {S8}% [9] session id or photo
				
			
\noindent Score-based Generative Models (SGMs) approximate a data distribution by perturbing it with Gaussian noise and subsequently denoising it via a learned reverse diffusion process. These models excel at modeling complex data distributions and generating diverse samples, achieving state-of-the-art performance across domains such as computer vision, audio generation, reinforcement learning, and computational biology. Despite their empirical success, existing Wasserstein-2 convergence analysis typically assume strong regularity conditions—such as smoothness or strict log-concavity of the data distribution—that are rarely satisfied in practice.
		
	\noindent	In this work, we establish the first non-asymptotic Wasserstein-2 convergence guarantees for SGMs targeting semiconvex distributions with potentially discontinuous gradients. Our upper bounds are explicit and sharp in key parameters, achieving optimal dependence of $O(\sqrt{d})$ on the data dimension $d$ and convergence rate of order one. The framework accommodates a wide class of practically relevant distributions, including symmetric modified half-normal distributions, Gaussian mixtures, double-well potentials, and elastic net potentials. By leveraging semiconvexity without requiring smoothness assumptions on the potential such as differentiability, our results substantially broaden the theoretical foundations of SGMs, bridging the gap between empirical success and rigorous guarantees in non-smooth, complex data regimes.

\medskip


\begin{enumerate}
	\item[{[1]}] Bruno, Stefano \& Sabanis, Sotirios (2025). {\it Wasserstein Convergence of Score-based Generative Models under Semiconvexity and Discontinuous Gradients}. ArXiv.
\end{enumerate}


\end{talk}

\begin{talk}
  {Optimal strong approximation of SDEs with H\"older continuous drift coefficient}% [1] talk title
  {Larisa Yaroslavtseva}% [2] speaker name
  {University of Graz}% [3] affiliations
  {larisa.yaroslavtseva@uni-graz.at}% [4] email
  {Simon Ellinger and Thomas Müller-Gronbach}% [5] coauthors
  {}% [6] special session
  {Tue, Jul 29 15:30–17:30}% [7] time slot
  {S12-1}% [8] talk id
  {S12}% [9] session id or photo
  
				
			
We study strong approximation of the solution of a scalar stochastic differential equation (SDE)
\begin{equation}\label{sde0}
	\begin{aligned}
		dX_t \& = \mu(X_t) \, dt +  dW_t, \quad t\in [0,1],\\
		X_0 \& = x_0
	\end{aligned}
\end{equation}
at the final time point $1$
in the case that  the drift coefficient  $\mu$ is $\alpha$-H\''older continuous with $\alpha\in(0, 1]$.
Recently, it was  shown in [1] that for such SDEs the equidistant Euler approximation achieves an $L^p$-error rate of at least $(1+\alpha)/2$, up to an arbitrary small $\varepsilon$,
in terms of the number of evaluations of the driving Brownian motion $W$.
In this talk  we  
present a matching  lower error bound.   More precisely, we show that
the $L^p$-error rate $(1+\alpha)/2$ can
not be improved in general by  no numerical 
method based on finitely many evaluations of $W$ at fixed time points. For the proof of this result we choose  $\mu$ to be the Weierstrass function and we employ  the coupling of noise technique  recently introduced in [2].




\begin{enumerate}
	\item[{[1]}] Butkovsky, O., Dareiotis, K., \& Gerencs\'er, M. (2021). Approximation of SDEs: a stochastic sewing appproach. Probab. Theory Related Fields, \textbf{181}(4), 975--1034
	\item[{[2]}] Müller-Gronbach, T.  \& Yaroslavtseva, L. (2023). Sharp lower error bounds for strong approximation of
	SDEs with discontinuous drift coefficient by coupling of noise. Ann. Appl. Probab. \textbf{33}, 902–-935.
\end{enumerate}


\end{talk}

\begin{talk}
  {Malliavin differentiation of Lipschitz SDEs and BSDEs and an Application to Quadratic Forward-Backward SDEs}% [1] talk title
  {Alexander Steinicke}% [2] speaker name
  {University of Leoben}% [3] affiliations
  {alexander.steinicke@unileoben.ac.at}% [4] email
  {Hannah Geiss, C\'eline Labart, Adrien Richou}% [5] coauthors
  {Stochastic Computation and Complexity}% [6] special session
  {Tue, Jul 29 15:30–17:30}% [7] time slot
  {S12-2}% [8] talk id
  {S12}% [9] session id or photo
				
			
Geiss and Zhou [1] showed that SDEs and BSDEs with Lipschitz generators admit Malliavin differentiability in the Brownian setting. We extend and apply this result in the L\'evy case and present a differentiation formula for coefficients that are Lipschitz in the solution variable with respect to the Skorohod metric. The obtained formula then allows us to show the existence and uniqueness of solutions to a class of quadratic and superquadratic forward-backward SDE systems.

\medskip

\begin{enumerate}
	\item[{[1]}] Geiss, S.~and Zhou, X.~(2024). {\it Coupling of Stochastic Differential Equations on the Wiener Space}. https://arxiv.org/pdf/2412.10836.
\end{enumerate}

\end{talk}

\begin{talk}
  {Tractability of $L_2$-approximation and integration in weighted Hermite spaces of finite smoothness}% [1] talk title
  {Gunther Leobacher}% [2] speaker name
  {University of Graz}% [3] affiliations
  {gunther.leobacher@uni-graz.at}% [4] email
  {Adrian Ebert, Friedrich Pillichshammer}% [5] coauthors
  {Stochastic Computation and Complexity}% [6] special session
  {Tue, Jul 29 15:30–17:30}% [7] time slot
  {S12-3}% [8] talk id
  {S12}% [9] session id or photo
				
			

We consider integration and $L_2$-approximation for functions over $\mathbb R^s$ from weighted Hermite spaces as introduced in [1]. We study tractability of the integration and $L_2$-approximation problem for the different Hermite spaces, which describes the growth rate of the information complexity when the error threshold $\varepsilon$ tends to 0 and the problem dimension $s$ grows to infinity. Our main results are characterizations of tractability in terms of the involved weights, which  model the importance of the successive coordinate directions for functions from the weighted Hermite spaces.

\medskip

\begin{enumerate}
	\item[{[1]}] Ch.~Irrgeher and G.~Leobacher. High-dimensional integration on the $\mathbb R^d$, weighted Hermite spaces, and orthogonal transforms. \textit{J. Complexity} 31: 174--205, 2015. 
\end{enumerate}


\end{talk}

\begin{talk}
  {On the quantum complexity of parametric integration in Sobolev spaces}% [1] talk title
  {Stefan Heinrich}% [2] speaker name
  {heinrich@informatik.uni-kl.de}% [3] affiliations
  {Stochastic computation and complexity}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Wed, Jul 30 10:30–12:30}% [7] time slot
  {S16-1}% [8] talk id
  {S16}% [9] session id or photo
				
			
We consider the following problem of parametric integration in Sobolev spaces. We seek to approximate
$$
S:W_p^r(D)\to L_q(D_1), \quad (Sf)(s)=\int_{D_2}f(s,t)dt \quad (s\in D_1),
$$ 
where 
%
\begin{eqnarray*}
&&D=[0,1]^d=D_1\times D_2,\quad D_1=[0,1]^{d_1}, \quad D_2=[0,1]^{d_2}, 
\\
&&1\le p,q\le \infty, \quad d,d_1,d_2,r\in {\bf N},\quad d=d_1+d_2,\quad \frac{r}{d_1}>\left(\frac{1}{p}-\frac{1}{q}\right)_+\, .
\end{eqnarray*}
%
We study the complexity of this problem in the quantum setting of Information-Based Complexity [1]. Under the assumption that $W_p^r(D)$ is embedded into $C(D)$ (embedding condition) the case $p=q$ was solved by Wiegand [2]. Here we treat the case $p=q$ without embedding condition and the general case $p\ne q$ with or without the embedding condition. We also compare the rates with those in the (classical) randomized setting [3].


\medskip

\begin{enumerate}

\item[{[1]}] Heinrich, Stefan (2002).\  Quantum summation with an application to integration. 
Journal of Complexity 18, 1--50.
\item[{[2]}] Wiegand, Carsten (2006).\ {\it Optimal Monte Carlo and Quantum Algorithms for Parametric Integration}. Shaker Verlag.
\item[{[3]}] Heinrich, Stefan (2024).\  Randomized complexity of parametric integration and
the role of adaption  II. Sobolev spaces. Journal of Complexity 82, 101823.
\end{enumerate}

\end{talk}

\begin{talk}
  {Quantum Integration in Tensor Product  Besov Spaces}% [1] talk title
  {Bernd Käßemodel}% [2] speaker name
  {Faculty of Mathematics, Technische Universität Chemnitz}% [3] affiliations
  {bernd.kaessemodel@mathematik.tu-chemnitz.de}% [4] email
  {Tino Ullrich}% [5] coauthors
  {Stochastic Computation and Complexity}% [6] special session
  {Wed, Jul 30 10:30–12:30}% [7] time slot
  {S16-2}% [8] talk id
  {S16}% [9] session id or photo
				

We begin with a brief introduction to the basic concepts of quantum computing and quantum information-based complexity for multivariate integration and approximation problems in various smoothness classes. We then discuss characterizations of functions in tensor product Besov spaces (mixed smoothness) using the tensorized Faber-Cieselski basis with coefficients based on mixed iterated differences. Relying on such a decomposition we develop a quantum algorithm to establish bounds for the worst case quantum integration error for this function class. 

\medskip
%
%If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
%Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.
%APA reference style is recommended.
%\begin{enumerate}
%	\item[{[1]}] Niederreiter, Harald (1992). {\it Random number generation and quasi-Monte Carlo methods}. Society for Industrial and Applied Mathematics (SIAM).
%	\item[{[2]}] Roberts, Gareth O, \& Rosenthal, Jeffrey S. (2002).  Optimal scaling for various Metropolis-Hastings algorithms, \textbf{16}(4), 351--367.
%\end{enumerate}
%
%Equations may be used if they are referenced. Please note that the equation numbers may be different (but will be cross-referenced correctly) in the final program book.
\end{talk}

\begin{talk}
  {Multilevel randomized quasi-Monte Carlo estimator for nested expectations}% [1] talk title
  {Ra\'{u}l Tempone}% [2] speaker name
  {King Abdullah University of Science and Technology/RWTH Aachen University}% [3] affiliations
  {raul.tempone@kaust.edu.sa}% [4] email
  {Arved Bartuska, Andr\'{e} Gustavo Carlon, Luis Espath, Sebastian Krumscheid}% [5] coauthors
  {}% [6] special session
  {Thu, Jul 31 10:30–12:30}% [7] time slot
  {S24-1}% [8] talk id
  {S24}% [9] session id or photo
  
				
			
Estimation methods for nested integrals face several challenges, including nonlinearities separating the integrals, boundary singularities, and the need for numerical discretization of the integrand. In this talk, we present an advanced multilevel randomized double-loop quasi-Monte Carlo estimator that addresses these challenges by combining hierarchical approximations with deterministic and randomized quasi-Monte Carlo (rQMC) methods. This estimator is tailored towards scenarios where the inner integrand requires discretization via the finite element method and the outer integrand exhibits singularities at the boundaries of the integration domain. 

Applications from Bayesian experimental design, in particular, the expected information gain (EIG) of an experiment, necessitate a truncation scheme for observation noise to rigorously bound the estimation error. This truncation affects the computational cost only by a logarithmic factor. Numerical experiments demonstrate the predicted optimal cost of almost $\mathcal{O}(TOL^{-1-\gamma/\eta_{\text{w}}})$ where $\gamma$ and $\eta_{\text{w}}$ signify the cost and weak rate of finite element discretizations, respectively.

\end{talk}

\begin{talk}
  {Stochastic gradient with least-squares control variates}% [1] talk title
  {Matteo Raviola}% [2] speaker name
  {École polytechnique fédérale de Lausanne}% [3] affiliations
  {matteo.raviola@epfl.ch}% [4] email
  {Fabio Nobile, Nathan Schaeffer}% [5] coauthors
  {}% [6] special session
  {Thu, Jul 31 10:30–12:30}% [7] time slot
  {S24-2}% [8] talk id
  {S24}% [9] session id or photo
  
  
  
  The stochastic gradient (SG) method is a widely used approach for solving stochastic optimization problems, but its convergence is typically slow.
  Existing variance reduction techniques, such as SAGA [1], improve convergence by leveraging stored gradient information; however, they are restricted to settings where the objective functional is a finite sum, and their performance degrades when the number of terms in the sum is large.
  In this work, we propose a novel approach which also works when the objective is given by an expectation over random variables with a continuous probability distribution.
  Our method constructs a control variate by fitting a linear model to past gradient evaluations using weighted discrete least-squares, effectively reducing variance while preserving computational efficiency.
  We establish theoretical sublinear convergence guarantees and demonstrate the method's effectiveness through numerical experiments on random PDE-constrained optimization.
  
  \medskip
  
  \begin{enumerate}
    \item[{[1]}] Defazio, A., Bach, F., \& Lacoste-Julien, S. (2014). {\it SAGA: A fast incremental gradient method with support for non-strongly convex composite objectives.} Advances in neural information processing systems, 27.
  \end{enumerate}
  
\end{talk}

\begin{talk}
  {A one-shot method for Bayesian optimal experimental design}% [1] talk title
  {Philipp A. Guth}% [2] speaker name
  {RICAM, Austrian Academy of Sciences}% [3] affiliations
  {philipp.guth@ricam.oeaw.ac.at}% [4] email
  {Robert Gruhlke, Claudia Schillings}% [5] coauthors
  {Nested expectations: models and estimators, Part II}% [6] special session
  {Thu, Jul 31 10:30–12:30}% [7] time slot
  {S24-3}% [8] talk id
  {S24}% [9] session id or photo
				
		
Bayesian optimal experimental design (BOED) problems often involve nested integrals, making their direct computation challenging. To address this, a one-shot optimization approach is proposed, which decouples the design parameters from the forward model during the optimization process. In addition, the solution of the forward model can be replaced by a surrogate that is trained during the one-shot optimization. This allows for the generation of computationally inexpensive samples. Efficient sampling strategies are particularly important in BOED, as they reduce the high computational cost of nested integration, ultimately making the optimization more tractable.



%\medskip
%
%If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
%Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.
%APA reference style is recommended.
%\begin{enumerate}
%	\item[{[1]}] Niederreiter, Harald (1992). {\it Random number generation and quasi-Monte Carlo methods}. Society for Industrial and Applied Mathematics (SIAM).
%	\item[{[2]}] Roberts, Gareth O, \& Rosenthal, Jeffrey S. (2002).  Optimal scaling for various Metropolis-Hastings algorithms, \textbf{16}(4), 351--367.
%\end{enumerate}
%
%Equations may be used if they are referenced. Please note that the equation numbers may be different (but will be cross-referenced correctly) in the final program book.
\end{talk}

\begin{talk}
  {Inference for Stochastic Gradient Descent with Infinite Variance}% [1] talk title
  {Jose Blanchet}% [2] speaker name
  {Stanford University}% [3] affiliations
  {jose.blanchet@stanford.edu}% [4] email
  {Peter Glynn, Aleks Mijatovic, Wenhao Yang}% [5] coauthors
  {Recent Advances in Stochastic Gradient Descent}% [6] special session
  {Thu, Jul 31 15:30–17:30}% [7] time slot
  {S27-1}% [8] talk id
  {S27}% [9] session id or photo
				
                
Stochastic gradient descent (SGD) with infinite variance gradients arises, perhaps surprisingly, quite often in applications. Even in settings involving “finite variance” in theory, infinite variance models appear to provide a better statistical fit over spatial and temporal scales of interest in applied settings. Motivated by this, we investigate a general methodology that enables the development of valid confidence regions for SGD with infinite variance. Along the way, we also obtain key results and properties for SGD with infinite variance, for example, asymptotic limits, optimal convergence rates, etc., which are counterparts of celebrated results known only in the finite variance case.


\medskip

% If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
% Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.
% APA reference style is recommended.
% \begin{enumerate}
% 	\item[{[1]}] Niederreiter, Harald (1992). {\it Random number generation and quasi-Monte Carlo methods}. Society for Industrial and Applied Mathematics (SIAM).
% 	\item[{[2]}] L’Ecuyer, Pierre, \& Christiane Lemieux. (2002). Recent advances in randomized quasi-Monte Carlo methods. Modeling uncertainty: An examination of stochastic theory, methods, and applications, 419-474.
% \end{enumerate}

% Equations may be used if they are referenced. Please note that the equation numbers may be different (but will be cross-referenced correctly) in the final program book.
\end{talk}

\begin{talk}
  {Stochastic Gradient Descent with Adaptive Data}% [1] talk title
  {Jing Dong}% [2] speaker name
  {Columbia University}% [3] affiliations
  {jing.dong@gsb.columbia.edu}% [4] email
  {Ethan Che, Xin Tong}% [5] coauthors
  {Recent Advances in Stochastic Gradient Descent}% [6] special session
  {Thu, Jul 31 15:30–17:30}% [7] time slot
  {S27-2}% [8] talk id
  {S27}% [9] session id or photo
				
                
Stochastic gradient descent (SGD) is a powerful optimization technique that is particularly useful in online learning scenarios. Its convergence analysis is relatively well understood under the assumption that the data samples are independent and identically distributed (iid). However, applying SGD to policy optimization
problems in operations research involves a distinct challenge: the policy changes the environment and thereby affects the data used to update the policy. The adaptively generated data stream involves samples that are non-stationary, no longer independent from each other, and affected by previous decisions. The influence of previous decisions on the data generated introduces bias in the gradient estimate, which presents a potential source of instability for online learning not present in the iid case. In this paper, we introduce simple criteria for the adaptively generated data stream to guarantee the convergence of SGD. We show that the convergence
speed of SGD with adaptive data is largely similar to the classical iid setting, as long as the mixing time of the policy-induced dynamics is factored in. Our Lyapunov-function analysis allows one to translate existing stability analysis of stochastic systems studied in operations research into convergence rates for SGD, and
we demonstrate this for queueing and inventory management problems. We also showcase how our result can be applied to study the sample complexity of an actor-critic policy gradient algorithm.			


\medskip

% If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
% Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.
% APA reference style is recommended.
% \begin{enumerate}
% 	\item[{[1]}] Niederreiter, Harald (1992). {\it Random number generation and quasi-Monte Carlo methods}. Society for Industrial and Applied Mathematics (SIAM).
% 	\item[{[2]}] L’Ecuyer, Pierre, \& Christiane Lemieux. (2002). Recent advances in randomized quasi-Monte Carlo methods. Modeling uncertainty: An examination of stochastic theory, methods, and applications, 419-474.
% \end{enumerate}

% Equations may be used if they are referenced. Please note that the equation numbers may be different (but will be cross-referenced correctly) in the final program book.
\end{talk}

\begin{talk}
  {Filtered Markovian Projection: Dimensionality Reduction in Filtering for Stochastic Reaction Networks}% [1] talk title
  {Maksim Chupin}% [2] speaker name
  {King Abdullah University of Science and Technology (KAUST)}% [3] affiliations
  {maksim.chupin@kaust.edu.sa}% [4] email
  {Chiheb Ben Hammouda, Sophia M\"{u}nker, Ra\'{u}l Tempone}% [5] coauthors
  {Forward and Inverse Problems for Stochastic Reaction Networks}% [6] special session
  {Fri, Aug 1 09:00–10:30}% [7] time slot
  {S28-1}% [8] talk id
  {S28}% [9] session id or photo
				
			
Stochastic reaction networks (SRNs) model stochastic effects for various applications, including intracellular chemical or biological processes and epidemiology. A key challenge in practical problems modeled by SRNs is that only a few state variables can be dynamically observed. Given the measurement trajectories, one can estimate the conditional probability distribution of unobserved (hidden) state variables by solving a system filtering equation. The current numerical methods, such as the Filtered Finite State Projection [1], are hindered by the curse of dimensionality, significantly affecting their computational performance. To overcome this, we propose to use a dimensionality reduction technique based on the Markovian projection (MP), initially introduced for forward problems [2]. In this work, we explore how to adapt the existing MP approach to the filtering problem and introduce a novel version of the MP, the Filtered MP, that guarantees the consistency of the resulting estimator [3]. The novel method employs a reduced-variance particle filter for estimating the jump intensities of the projected model and solves the filtering equations in a low-dimensional space, improving computational efficiency over existing methods.





\medskip

\begin{enumerate}
	\item[{[1]}] D’Ambrosio, E., Fang, Z., Gupta, A., Kumar, S., \& Khammash, M. (2022). Filtered finite state projection method for the analysis and estimation of stochastic biochemical reaction networks. bioRxiv, 2022-10.
	\item[{[2]}] Hammouda, C. B., Rached, N. B., Tempone, R., \& Wiechert, S. (2024). Automated importance sampling via optimal control for stochastic reaction networks: A Markovian projection–based approach. Journal of Computational and Applied Mathematics, 446, 115853.
    \item [{[3]}] Hammouda, C. B., Chupin, M., Münker, S., \& Tempone, R. (2025). Filtered Markovian Projection: Dimensionality Reduction in Filtering for Stochastic Reaction Networks. arXiv preprint arXiv:2502.07918.
\end{enumerate}


\end{talk}

\begin{talk}
  {Fixed-budget simulation method for growing cell populations}% [1] talk title
  {Zhou Fang}% [2] speaker name
  {Academy of Mathematics and Systems Science, Chinese Academy of Sciences}% [3] affiliations
  {zhfang@amss.ac.cn}% [4] email
  {Shaoqing Chen, Zheng Hu, Da Zhou}% [5] coauthors
  {Forward and Inverse Problems for Stochastic Reaction Networks}% [6] special session
  {Fri, Aug 1 09:00–10:30}% [7] time slot
  {S28-2}% [8] talk id
  {S28}% [9] session id or photo
				
			
Investigating the dynamics of growing cell populations is crucial for unraveling key biological mechanisms in living organisms, with many important applications in therapeutics and biochemical engineering. Classical agent-based simulation algorithms are often inefficient for these systems because
they track each individual cell, making them impractical for fast (or even exponentially) growing
cell populations. To address this challenge, we introduce a novel stochastic simulation approach
based on a Feynman-Kac-like representation of the population dynamics. This method, named the
Feynman-Kac-inspired Gillespie’s Stochastic Simulation Algorithm (FKG-SSA), always employs a
fixed number of independently simulated cells for Monte Carlo computation of the system, resulting in a constant computational complexity regardless of the population size. Furthermore, we
theoretically show the statistical consistency of the proposed method, indicating its accuracy and
reliability. Finally, a couple of biologically relevant numerical examples are presented to illustrate the
approach. Overall, the proposed FKG-SSA effectively addresses the challenge of simulating growing
cell populations, providing a solid foundation for better analysis of these systems.


\end{talk}

\begin{talk}
  {State and parameter inference in stochastic reaction networks}% [1] talk title
  {Muruhan Rathinam}% [2] speaker name
  {University of Maryland Baltimore County}% [3] affiliations
  {muruhan@umbc.edu}% [4] email
  {Mingkai Yu}% [5] coauthors
  {}% [6] special session
  {Fri, Aug 1 09:00–10:30}% [7] time slot
  {S28-3}% [8] talk id
  {S28}% [9] session id or photo
  
				
Continuous time Markov chain models are widely used to model intracellular chemical reactions networks that arise in systems and synthetic biology. In this talk, we address the problem of inference of state and parameters of such systems from partial observations. We present details of recent particle filtering methods that are applicable to two different scenarios: one in which the observations are made continuously in time and the other in which the observations are made in discrete snapshots of time.            We provide the theoretical justification as well as numerical results to illustrate these methods.       
			
\medskip

%If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
%Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.
%APA reference style is recommended.
\begin{enumerate}
	\item[{[1]}] Rathinam, Muruhan \& Yu, Mingkai (2021). {\it State and parameter estimation from exact partial state observation in stochastic reaction networks}. The Journal of Chemical Physics. 
 154(3).
	\item[{[2]}] Rathinam, Muruhan \& Yu, Mingkai (2023). Stochastic Filtering of Reaction Networks Partially Observed in Time Snapshots. Journal of Computational Physics. 
Volume 515, 15 October 2024, 113265. 

\end{enumerate}

%Equations may be used if they are referenced. Please note that the equation numbers may be different (but will be cross-referenced correctly) in the final program book.
\end{talk}

\begin{talk}
  {Sophia Münker}% [1] talk title
  {RWTH Aachen University}% [2] speaker name
  {muenker@uq.rwth-aachen.de}% [3] affiliations
  {Chiheb Ben Hammouda, Nadhir Ben Rached, Raúl Tempone}% [4] email
  {Forward and Inverse Problems for Stochastic Reaction Networks}% [5] coauthors
  {}% [6] special session
  {Fri, Aug 1 09:00–10:30}% [7] time slot
  {S28-4}% [8] talk id
  {S28}% [9] session id or photo
				
			
A Stochastic Reaction Network (SRN) is a continuous-time, discrete-space Markov chain that models the random interaction of $d$ species through reactions, commonly applied in bio-chemical systems. We are interested in efficiently estimating rare event probabilities, where we consider path-dependent observables. Therefore, we present an importance sampling (IS) method based on the discrete Tau-Leap (TL) scheme to enhance the performance of Monte Carlo (MC) estimators. The primary challenge in IS is selecting an appropriate change of probability measure to significantly reduce variance, which often requires deep insights into the underlying problem. To address this, we propose a generic approach to obtain an efficient path-dependent measure change, based on an original connection between finding optimal IS parameters and solving a variance minimization problem using a stochastic optimal control (SOC) formulation [1]. The optimal IS parameters can be derived by solving a Hamilton-Jacobi-Bellman equation.

To address the curse of dimensionality, we propose the Markovian Projection (MP) technique to reduce the SRN to a lower-dimensional SRN (called MP-SRN) while preserving the marginal distribution of the original high-dimensional system. When solving the resulting SOC problem numerically to derive the variance reducing IS parameters, we derive the parameter for a reduced-dimensional model. These IS parameters can be applied to the full-dimensional SRN in the forward run. Analysis and numerical experiments demonstrate that our IS strategies substantially reduce the variance of the MC estimator, leading to lower computational complexity in the rare event regime compared to standard MC methods. 

At the end of the talk, we give a small outlook on a multilevel-IS scheme to further improve the efficiency of the estimator.


\begin{enumerate}
   \item[{[1]}] Ben Hammouda, C., Ben Rached, N., Tempone, R., \& Wiechert, S. (2024). Automated importance sampling via optimal control for stochastic reaction networks: A Markovian projection-based approach. Journal of Computational and Applied Mathematics, 446, 115853.
\end{enumerate}

\medskip
\end{talk}
