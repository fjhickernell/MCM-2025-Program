\chapter{Special Sessions}

\begin{session}
 {Stochastic Computation and Complexity, Part I}% [1] session title
 {Stefan Heinrich}% [2] organizer one name
 {RPTU Kaiserslautern-Landau}% [3] organizer one affiliations
 {heinrich@informatik.uni-kl.de}% [4] organizer one email
 {Thomas M\"uller-Gronbach}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {University of Passau}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Thomas.Mueller-Gronbach@uni-passau.de}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S1}% [8] session id
 {\thirdorganizer{Larisa Yaroslavtseva}{University of Graz}{larisa.yaroslavtseva@uni-graz.at}}% [9] third organizer, if any

 The session is devoted to algorithms and complexity for\\
 --- quadrature and strong approximation of SDEs and SPDEs, in particular under nonstandard assumptions,\\
 --- high and infinite dimensional integration and approximation, and\\
 --- stochastic optimization and neural networks,
 including connections to functional analysis and stochastic analysis.
\end{session}

\input{sessS1.tex}

\clearpage

\begin{session}
 {Domain uncertainty quantification}% [1] session title
 {}% [2] organizer one name
 {}% [3] organizer one affiliations
 {}% [4] organizer one email
 {}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S2}% [8] session id
 {\thirdorganizer{}{}{}}% [9] third organizer, if any

 {Andr\'e-Alexander Zepernick {\rm (Free University of Berlin)}\\
 Philipp A. Guth {\rm (RICAM, Austrian Academy of Sciences)}\\ Vesa Kaarnioja {\rm (Free University of Berlin)}}% [2] organizer name
 {{\tt a.zepernick@fu-berlin.de}\\{\tt philipp.guth@ricam.oeaw.ac.at}\\{\tt vesa.kaarnioja@fu-berlin.de}}% [3] affiliations
 {}% [4] email
 {}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 Uncertainty in computational measurement models poses significant challenges in engineering and applied mathematics, where inaccuracies in material properties or geometric domains can greatly impact outcomes. Geometric errors, such as manufacturing imperfections or improper modeling in applications like electronic design and tomography, can be the dominant error contributor. Some approaches to modeling domain uncertainty include homogenization, perturbation, and reference mapping techniques, which facilitate the analysis of uncertainty propagation within computational measurement models. This session brings together leading experts to present recent theoretical and computational advancements in the study of domain uncertainty quantification.
 List of speakers:
 1. Andr\'e-Alexander Zepernick (Free University of Berlin)
 2. Carlos Jerez-Hanckes (Universidad Adolfo Ib\'{a}\~{n}ez)
 3. J\"urgen D\"olz (University of Bonn)
 4. Harri Hakula (Aalto University)
\end{session}

\input{sessS2.tex}

\clearpage

\begin{session}
 {Nested expectations: models and estimators, Part I}% [1] session title
 {Arved Bartuska}% [2] organizer one name
 {King Abdullah University of Science and Technology/RWTH Aachen University}% [3] organizer one affiliations
 {arved.bartuska@kaust.edu.sa}% [4] organizer one email
 {Abdul-Lateef Haji-Ali}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Heriot-Watt University}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {a.hajiali@hw.ac.uk}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S3}% [8] session id
{}

 Nested expectations arise in many applications, such as in engineering, mathematical finance, and medical decision-making. In addition to their nested structure, numerical estimations of such expectations are often complicated by singularities or discontinuities. Moreover, approximations when evaluating inner expectations using, for example, finite element or time-stepping schemes render traditional estimation methods such as double-loop Monte Carlo prohibitively expensive. This session will explore models and applications with this structure and methods for efficient estimation.
\end{session}

\input{sessS3.tex}

\clearpage

\begin{session}
 {Hardware or Software for (Quasi-)Monte Carlo Algorithms, Part I}% [1] session title
 {Sou-Cheng T.  Choi}% [2] organizer one name
 {Illinois Institute of Technology}% [3] organizer one affiliations
 {schoi32@iit.edu}% [4] organizer one email
 {Pieterjan Robbe}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Sandia National Laboratories}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {pmrobbe@sandia.gov}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S4}% [8] session id
 {\thirdorganizer{Mike Giles}{University of Oxford}{mike.giles@maths.ox.ac.uk}}% [9] third organizer, if any

 Monte Carlo (MC) or quasi-Monte Carlo (QMC) algorithms are widely used in various fields such as finance, physics, and engineering for their ability to handle high-dimensional integration problems. The development and maintenance of software for (quasi-)Monte Carlo ((Q)MC) algorithms can significantly enhance the accessibility and usability of these techniques. This special session aims to bring together experts from academia and industry to discuss recent advances in (Q)MC software, share best practices, and explore future directions, fostering collaboration among researchers and practitioners.
 Topics of interest for the session include:
 \begin{itemize}
 \item Novel hardware or architectural designs for open-source (Q)MC libraries.
 \item Best collaborative practices for developing and maintaining efficient and reliable (Q)MC software.
 \item Challenges and opportunities in integrating (Q)MC methods with machine learning and AI techniques.
 \item High-performance computing solutions for (Q)MC software.
 \item Adaptation of (Q)MC software to application fields such as finance, computer graphics, sensitivity analysis, Bayesian optimization, and uncertainty quantification.
 \item Innovative approaches to enhancing and extending existing (Q)MC tools.
 \end{itemize}
\end{session}

\input{sessS4.tex}

\clearpage

\begin{session}
 {Stochastic Computation and Complexity, Part II}% [1] session title
 {Stefan Heinrich}% [2] organizer one name
 {RPTU Kaiserslautern-Landau}% [3] organizer one affiliations
 {heinrich@informatik.uni-kl.de}% [4] organizer one email
 {Thomas M\"uller-Gronbach}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {University of Passau}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Thomas.Mueller-Gronbach@uni-passau.de}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S5}% [8] session id
 {\thirdorganizer{Larisa Yaroslavtseva}{University of Graz}{larisa.yaroslavtseva@uni-graz.at}}% [9] third organizer, if any

 The session is devoted to algorithms and complexity for\\
 --- quadrature and strong approximation of SDEs and SPDEs, in particular under nonstandard assumptions,\\
 --- high and infinite dimensional integration and approximation, and\\
 --- stochastic optimization and neural networks,
 including connections to functional analysis and stochastic analysis.
\end{session}

\input{sessS5.tex}

\clearpage

\begin{session}
 {Recent advances in optimization under uncertainty}% [1] session title
 {Philipp A. Guth}% [2] organizer one name
 {RICAM, Austrian Academy of Sciences}% [3] organizer one affiliations
 {philipp.guth@ricam.oeaw.ac.at}% [4] organizer one email
 {Vesa Kaarnioja}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Free University of Berlin}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {vesa.kaarnioja@fu-berlin.de}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S6}% [8] session id
{}

 The quantification of uncertainties associated with large-scale optimization problems based on partial differential equation models typically involves a number of uncertainties. Some uncertain parameters may include, e.g., the material parameters, domain shape or sensor locations used to collect measurement data. The associated challenging high-dimensional integration problems can be solved efficiently using, e.g., multilevel Monte Carlo or quasi-Monte Carlo methods. This session aims to cover some recent developments in the computational and theoretical treatment of this actively developing field of research.
\end{session}

\input{sessS6.tex}

\clearpage

\begin{session}
 {Computational Methods for Low-discrepancy Sampling and Applications}% [1] session title
 {Nathan Kirk}% [2] organizer one name
 {Illinois Institute of Technology}% [3] organizer one affiliations
 {nkirk@iit.edu}% [4] organizer one email
 {François Clément}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {University of Washington}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {fclement@uw.edu}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S7}% [8] session id
{}

 This session aims to showcase recent advancements in the optimization of sample point distributions [1, 2] and their applications. Some of the methods on display will range from deep learning methods to permutation optimization and greedy approaches [3], showcasing the usefulness of the $L_2$-discrepancies in optimizing the $L_{\infty}$ discrepancies. As a consequence of some of these improved low-discrepancy sets, an application will be shown in improved path planning in robotics [4]. Several other applications will be explored in the context of using the median over the mean of $r$ RQMC estimates as proposed in several recent papers including [5].
 \medskip
 \begin{enumerate}
 \item[{[1]}] T. K. Rusch, N. Kirk, M. Bronstein, C. Lemieux and D. Rus, \textit{Message-Passing Monte Carlo: Generating low-discrepancy point sets via graph neural networks}, PNAS \textbf{121} (40) e2409913121 (2024)
 \item[{[2]}] F. Clément, C. Doerr, K. Klamroth, L. Paquete, \textit{Transforming the Challenge of Constructing Low-Discrepancy Point Sets into a Permutation Selection Problem}, \url{https://arxiv.org/abs/2407.11533}.
 \item[{[3]}] F. Cl\'ement, \textit{Outperforming the Best {1D} Low-Discrepancy Constructions with a Greedy Algorithm}, \url{https://arxiv.org/abs/2406.18132}.
 \item[{[4]}] M. Chahine, T. K. Rusch, Z. J. Patterson and D. Rus, \textit{Improving Efficiency of Sampling-based Motion Planning via Message-Passing Monte Carlo}, \url{https://arxiv.org/abs/2410.03909}
 \item[{[5]}] P. L'Ecuyer, M. K. Nayakama, A. B. Owen and B. Tuffin, \textit{Confidence Intervals for Randomized Quasi-Monte Carlo Estimators}, Proceedings of the 2023 Winter Simulation Conference (2023)
 \end{enumerate}
\end{session}

\input{sessS7.tex}

\clearpage

\begin{session}
 {Stochastic Computation and Complexity, Part III}% [1] session title
 {Stefan Heinrich}% [2] organizer one name
 {RPTU Kaiserslautern-Landau}% [3] organizer one affiliations
 {heinrich@informatik.uni-kl.de}% [4] organizer one email
 {Thomas M\"uller-Gronbach}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {University of Passau}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Thomas.Mueller-Gronbach@uni-passau.de}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S8}% [8] session id
 {\thirdorganizer{Larisa Yaroslavtseva}{University of Graz}{larisa.yaroslavtseva@uni-graz.at}}% [9] third organizer, if any

 The session is devoted to algorithms and complexity for\\
 --- quadrature and strong approximation of SDEs and SPDEs, in particular under nonstandard assumptions,\\
 --- high and infinite dimensional integration and approximation, and\\
 --- stochastic optimization and neural networks,
 including connections to functional analysis and stochastic analysis.
\end{session}

\input{sessS8.tex}

\clearpage

\begin{session}
 {Next-generation optimal experimental design: theory, scalability, and real world impact: Part I}% [1] session title
 {Florence Forbes}% [2] organizer one name
 {Inria, France}% [3] organizer one affiliations
 {florence.forbes@inria.fr}% [4] organizer one email
 {Xun Huan}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {University of Michigan, USA}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {xhuan@umich.edu}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S9}% [8] session id
 {\thirdorganizer{Youssef Marzouk}{Massachusetts Institute of Technology, USA}{ymarz@mit.edu}}% [9] third organizer, if any

 Optimal experimental design (OED) provides a mathematical framework for identifying candidate data or experimental configurations that are most useful for inference, prediction, or some other downstream goal. Though OED is hardly a new topic,\footnote{At the first session of the Indian Statistical Conference in 1938, R.\ Fisher supposedly said, ``To call in the statistician after the experiment is done may be no more than asking him to perform a postmortem examination: he may be able to say what the experiment died of.''} the need for advances in OED has never been greater than it is today. Myriad application areas have witnessed, on the one hand, an explosion in the volume of data that can be acquired, and on the other, the use of increasingly complex and computationally intensive models to interpret these data. Yet large volumes of data do not by default carry a commensurate amount of information. Moreover, we inevitably face constraints: on the costs of experimentation or data acquisition, on data storage and communication, and on the computational effort of statistical inference in complex models. OED directly addresses the associated trade-offs---e.g., between experimentation, measurement, and/or processing \textit{costs} and
 the \textit{quality} of subsequent and decision making. See {\it e.g.} [1] for a recent review of OED topics, which provides numerous other references.
 This session will highlight computational developments at the OED research frontier. Methods for stochastic simulation, high-dimensional approximation or integration, and stochastic optimization are central to modern OED and to the scaling of OED to large parameter spaces and complex statistical models. Modern machine learning methodologies---from neural network surrogates, to deep reinforcement learning in sequential OED, to modern generative models and transport methods for simulation-based inference---also play a catalyzing role in such OED approaches. Talks in this session will illuminate these emerging interactions and their role in realizing Bayesian, decision-theoretic, and information-theoretic formulations of OED for truly complex problems. Session speakers will also discuss ongoing work to develop theoretical guarantees for these new OED methodologies, and showcase applications to real-world problems ranging from sensor steering to seismology.
 \medskip
 \begin{enumerate}
 \item[{[1]}] X.\ Huan, J.\ Jagalur, Y.\ Marzouk (2024). Optimal experimental design: Formulations and computations, \textit{Acta Numerica} \textbf{33}, 715--840.
 \end{enumerate}
\end{session}

\input{sessS9.tex}

\clearpage

\begin{session}
 {Heavy-tailed Sampling}% [1] session title
 {Alex Shestopaloff}% [2] organizer one name
 {Queen Mary University of London, UK}% [3] organizer one affiliations
 {a.shestopaloff@qmul.ac.uk}% [4] organizer one email
 {Jun Yang}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {University of Copenhagen, Denmark}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {jy@math.ku.dk}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S10}% [8] session id
{}

 {}% [4] email
 {}% [7] second organizer email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 Heavy-tailed distributions frequently arise in modern statistics, machine learning, and applied sciences, yet their intricate properties pose significant challenges for computational inference. This session, Heavy-Tailed Sampling, brings together cutting-edge advances in Monte Carlo methods and stochastic optimization to address these challenges. The topics span theoretical breakthroughs and practical algorithms, showcasing how heavy-tailed phenomena influence algorithmic design and performance. Our session aims to inspire new methods and applications in the broader Monte Carlo community. The session will explore:
 \begin{itemize}
 \item
 Langevin Monte Carlo for Heavy-Tailed Distributions: A comprehensive complexity analysis of Langevin-based samplers for heavy-tailed targets using weighted Poincaré inequalities. The results reveal fundamental limits of mean-square analysis and include innovative techniques for gradient approximation.
 \item
 Stereographic MCMC: A novel class of samplers that map Euclidean spaces onto spheres to resolve mixing issues inherent to heavy-tailed targets. These methods, featuring uniform ergodicity and rapid convergence, capitalize on the "blessings of dimensionality" to enhance performance in high dimensions.
 \item
 Large Deviation Principles in MCMC: A groundbreaking application of large deviation theory to assess and improve MCMC algorithms. This approach extends to Metropolis-Hastings and related methods on general state spaces, providing new insights into empirical measure convergence and rate functions.
 \item
 Heavy-Tailed Phenomena in Stochastic Gradient Descent (SGD): An analysis of heavy-tailed noise in SGD and its impact on escaping sharp minima in deep learning. The session highlights a variant of SGD with gradient truncation, offering theoretical and empirical evidence of enhanced generalization through flatter minima.
 \end{itemize}
\end{session}

\input{sessS10.tex}

\clearpage

\begin{session}
 {Frontiers in (Quasi-)Monte Carlo and Markov Chain Monte Carlo Methods, Part I}% [1] session title
 {Sou-Cheng T.  Choi}% [2] organizer one name
 {Illinois Institute of Technology}% [3] organizer one affiliations
 {schoi32@iit.edu}% [4] organizer one email
 {Yuhan Ding}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Illinois Institute of Technology}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {yding2@iit.edu}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S11}% [8] session id
{}

 (Quasi-)Monte Carlo ((Q)MC) and Markov Chain Monte Carlo (MCMC) algorithms are fundamental tools in computational mathematics, with a wide range of applications spanning finance, physics, engineering, and more. These methods have proven invaluable in solving high-dimensional problems where traditional numerical techniques often fail, and continue to expand their reach into emerging fields such as artificial intelligence, climate modeling, precision medicine, and data science.
 Recent advances in the theoretical foundations of these methods, including convergence rates, complexity analysis, sampling techniques, error analysis, variance reduction, optimal stopping conditions, and ergodic properties, have significantly improved their accuracy, efficiency, and reliability. In addition, interdisciplinary applications are driving new developments, such as machine learning, Bayesian inference, stochastic optimization, and uncertainty quantification.
 This special session aims to bring together leading experts from academia and industry to share breakthroughs, foster interdisciplinary collaboration, and identify future research directions in the broad field of Monte Carlo methods. Participants will benefit from insights into cutting-edge research and practical applications of (Q)MC and MCMC methods, as well as opportunities to network with peers and thought leaders.
\end{session}

\input{sessS11.tex}

\clearpage

\begin{session}
 {Stochastic Computation and Complexity, Part IV}% [1] session title
 {Stefan Heinrich}% [2] organizer one name
 {RPTU Kaiserslautern-Landau}% [3] organizer one affiliations
 {heinrich@informatik.uni-kl.de}% [4] organizer one email
 {Thomas M\"uller-Gronbach}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {University of Passau}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Thomas.Mueller-Gronbach@uni-passau.de}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S12}% [8] session id
 {\thirdorganizer{Larisa Yaroslavtseva}{University of Graz}{larisa.yaroslavtseva@uni-graz.at}}% [9] third organizer, if any

 The session is devoted to algorithms and complexity for\\
 --- quadrature and strong approximation of SDEs and SPDEs, in particular under nonstandard assumptions,\\
 --- high and infinite dimensional integration and approximation, and\\
 --- stochastic optimization and neural networks,
 including connections to functional analysis and stochastic analysis.
\end{session}

\input{sessS12.tex}

\clearpage

\begin{session}
 {Next-generation optimal experimental design: theory, scalability, and real world impact: Part II}% [1] session title
 {Florence Forbes}% [2] organizer one name
 {Inria, France}% [3] organizer one affiliations
 {florence.forbes@inria.fr}% [4] organizer one email
 {Xun Huan}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {University of Michigan, USA}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {xhuan@umich.edu}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S13}% [8] session id
 {\thirdorganizer{Youssef Marzouk}{Massachusetts Institute of Technology, USA}{ymarz@mit.edu}}% [9] third organizer, if any

 Optimal experimental design (OED) provides a mathematical framework for identifying candidate data or experimental configurations that are most useful for inference, prediction, or some other downstream goal. Though OED is hardly a new topic,\footnote{At the first session of the Indian Statistical Conference in 1938, R.\ Fisher supposedly said, ``To call in the statistician after the experiment is done may be no more than asking him to perform a postmortem examination: he may be able to say what the experiment died of.''} the need for advances in OED has never been greater than it is today. Myriad application areas have witnessed, on the one hand, an explosion in the volume of data that can be acquired, and on the other, the use of increasingly complex and computationally intensive models to interpret these data. Yet large volumes of data do not by default carry a commensurate amount of information. Moreover, we inevitably face constraints: on the costs of experimentation or data acquisition, on data storage and communication, and on the computational effort of statistical inference in complex models. OED directly addresses the associated trade-offs---e.g., between experimentation, measurement, and/or processing \textit{costs} and
 the \textit{quality} of subsequent and decision making. See {\it e.g.} [1] for a recent review of OED topics, which provides numerous other references.
 This session will highlight computational developments at the OED research frontier. Methods for stochastic simulation, high-dimensional approximation or integration, and stochastic optimization are central to modern OED and to the scaling of OED to large parameter spaces and complex statistical models. Modern machine learning methodologies---from neural network surrogates, to deep reinforcement learning in sequential OED, to modern generative models and transport methods for simulation-based inference---also play a catalyzing role in such OED approaches. Talks in this session will illuminate these emerging interactions and their role in realizing Bayesian, decision-theoretic, and information-theoretic formulations of OED for truly complex problems. Session speakers will also discuss ongoing work to develop theoretical guarantees for these new OED methodologies, and showcase applications to real-world problems ranging from sensor steering to seismology.
 \medskip
 \begin{enumerate}
 \item[{[1]}] X.\ Huan, J.\ Jagalur, Y.\ Marzouk (2024). Optimal experimental design: Formulations and computations, \textit{Acta Numerica} \textbf{33}, 715--840.
 \end{enumerate}
\end{session}

\input{sessS13.tex}

\clearpage

\begin{session}
 {Advances in Rare Events Simulation}% [1] session title
 {Nadhir Ben Rached}% [2] organizer one name
 {University of Leeds, United Kingdom}% [3] organizer one affiliations
 {N.BenRached@leeds.ac.uk}% [4] organizer one email
 {Shyam Mohan Subbiah Pillai}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {RWTH Aachen University, Germany}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {subbiah@uq.rwth-aachen.de}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S14}% [8] session id
 {\thirdorganizer{Ra\'ul Tempone}{King Abdullah University of Science and Technology, Saudi Arabia}{raul.tempone@kaust.edu.sa}}% [9] third organizer, if any

 Rare events are events with small probabilities, but their occurrences are critical in many real-life applications. The problem of estimating rare event probabilities is encountered in various engineering applications (finance, wireless communications, system reliability, biology, etc.). Naive Monte Carlo simulations are, in this case, substantially expensive. This session focuses on advances in methods belonging to the class of variance reduction techniques.  These alternative methods deliver, when appropriately used, accurate estimates with a substantial amount of variance reduction compared to the naive Monte Carlo estimator.
 Proposed speakers:
 \begin{enumerate}
 \item Victor Elvira, Professor in Statistics and Data Science, University of Edinburgh, United Kingdom
 \item Bruno Tuffin, Director of Research, INRIA Rennes-Bretagne Atlantique, France
 \item Eya Ben Amar, King Abdullah University of Science and Technology, Saudi Arabia
 \item Shyam Mohan Subbiah Pillai, RWTH Aachen University, Germany
 \end{enumerate}
 \medskip
\end{session}

\input{sessS14.tex}

\clearpage

\begin{session}
 {Frontiers in (Quasi-)Monte Carlo and Markov Chain Monte Carlo Methods, Part II}% [1] session title
 {Sou-Cheng T.  Choi}% [2] organizer one name
 {Illinois Institute of Technology}% [3] organizer one affiliations
 {schoi32@iit.edu}% [4] organizer one email
 {Yuhan Ding}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Illinois Institute of Technology}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {yding2@iit.edu}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S15}% [8] session id
{}

 (Quasi-)Monte Carlo ((Q)MC) and Markov Chain Monte Carlo (MCMC) algorithms are fundamental tools in computational mathematics, with a wide range of applications spanning finance, physics, engineering, and more. These methods have proven invaluable in solving high-dimensional problems where traditional numerical techniques often fail, and continue to expand their reach into emerging fields such as artificial intelligence, climate modeling, precision medicine, and data science.
 Recent advances in the theoretical foundations of these methods, including convergence rates, complexity analysis, sampling techniques, error analysis, variance reduction, optimal stopping conditions, and ergodic properties, have significantly improved their accuracy, efficiency, and reliability. In addition, interdisciplinary applications are driving new developments, such as machine learning, Bayesian inference, stochastic optimization, and uncertainty quantification.
 This special session aims to bring together leading experts from academia and industry to share breakthroughs, foster interdisciplinary collaboration, and identify future research directions in the broad field of Monte Carlo methods. Participants will benefit from insights into cutting-edge research and practical applications of (Q)MC and MCMC methods, as well as opportunities to network with peers and thought leaders.
\end{session}

\input{sessS15.tex}

\clearpage

\begin{session}
 {Stochastic Computation and Complexity, Part V}% [1] session title
 {Stefan Heinrich}% [2] organizer one name
 {RPTU Kaiserslautern-Landau}% [3] organizer one affiliations
 {heinrich@informatik.uni-kl.de}% [4] organizer one email
 {Thomas M\"uller-Gronbach}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {University of Passau}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Thomas.Mueller-Gronbach@uni-passau.de}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S16}% [8] session id
 {\thirdorganizer{Larisa Yaroslavtseva}{University of Graz}{larisa.yaroslavtseva@uni-graz.at}}% [9] third organizer, if any

 The session is devoted to algorithms and complexity for\\
 --- quadrature and strong approximation of SDEs and SPDEs, in particular under nonstandard assumptions,\\
 --- high and infinite dimensional integration and approximation, and\\
 --- stochastic optimization and neural networks,
 including connections to functional analysis and stochastic analysis.
\end{session}

\input{sessS16.tex}

\clearpage

\begin{session}
 {Statistical Design of Experiments}% [1] session title
 {Lulu Kang}% [2] organizer one name
 {University of Massachusetts Amherst}% [3] organizer one affiliations
 {lulukang@umass.edu}% [4] organizer one email
 {Chunfang Devon Lin}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Queen's University}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {devon.lin@queensu.ca}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S17}% [8] session id
{}

 \medskip
 This session explores innovative methodologies for optimizing experimental design and factor analysis in complex, high-dimensional, and resource-constrained settings. The first talk introduces QuIP, a novel framework for designing experiments with qualitative factors using integer programming and Gaussian process models, demonstrating its effectiveness in path planning and rover trajectory optimization. The second talk addresses the challenge of cost-efficient predictive computing by proposing a multi-fidelity emulator design inspired by Multilevel Monte Carlo methods, which ensures predictive accuracy while minimizing computational costs under a tight budget. The third talk shifts focus to experiments involving both quantitative and sequence factors, presenting a new class of optimal quantitative-sequence (QS) designs that are flexible, space-filling, and asymptotically orthogonal, making them ideal for high-dimensional applications in medical science and bio-engineering. Finally, the fourth talk introduces FIRST, a model-free framework for factor importance ranking and selection using total Sobol' indices, offering a computationally efficient and consistent approach to identifying key factors in regression and classification tasks. Together, these talks highlight cutting-edge advancements in experimental design, optimization, and factor analysis, with broad applications across scientific and engineering disciplines.
\end{session}

\input{sessS17.tex}

\clearpage

\begin{session}
 {Advances in Adaptive Hamiltonian Monte Carlo}% [1] session title
 {Art B. Owen}% [2] organizer one name
 {Stanford University}% [3] organizer one affiliations
 {owen@stanford.edu}% [4] organizer one email
{}{}{}
 {S18}% [8] session id
{}

 Hamiltonian Monte Carlo (HMC) is one of the most effective tools for high-dimensional Markov chain Monte Carlo. It is the default algorithm used in probabilistic programming languages for Bayesian computation, including \texttt{Stan} [2], \texttt{PyMC} and \texttt{NumPyro} (Python), and \texttt{Turing.jl} (Julia).  While HMC handles some of the most difficult MCMC problems, it does so through the use of several tuning parameters, which can be challenging to set.
 Significant progress came from the no-U-turn sampler (NUTS) [3] and apogee-to-apogee path sampler [7], both of which dynamically adapt path lengths. More recent progress includes delayed rejection HMC [5], which locally adapts step sizes, and
 Gibbs self tuning (GIST) [1], which treats tuning parameters as random variables to maintain detailed balance.  Chirag Modi's ATLAS [5] leverages local Hessians, delayed rejection, and GIST.  AutoStep MCMC [4] adapts step sizes locally to match the variable geometry of target distributions.
 Bob Carpenter will provide an introduction to HMC, NUTS, and GIST for non-specialists. Nawaf Bou-Rabee will elaborate on GIST. Chirag Modi will discuss delayed rejection and ATLAS. Trevor Campbell will present AutoStep and related methods.
 \medskip
 \begin{description}
 \item{[1]} Bou-Rabee, B. Carpenter, and M. Marsden. GIST: Gibbs self-tuning for locally adaptive HMC. arXiv:2404.15253, 2024.
 \item{[2]} Carpenter, B. et al. 2017. Stan: A probabilistic programming language. \textit{J. Stat. Soft.},~76
 \item{[3]} Hoffman, M.~D.\ and Gelman, A. 2014. The no-U-turn sampler: Adaptively setting path lengths in HMC. \textit{J. Mach. Learn. Res.}, 15(1).
 \item{[4]} Liu, T., Campbell, T., et al. 2024. AutoStep: Locally adaptive involutive MCMC. arXiv:2410.18929, 2024.
 \item{[5]} Modi, C. 2024. ATLAS: Adapting trajectory lengths and step-size for HMC. arXiv:2410.21587
 \item{[6]} Modi, C., Barnett, A. and Carpenter, B. 2024. Delayed rejection Hamiltonian Monte Carlo for sampling multiscale distributions. \textit{Bayesian Analysis}, 19(3), 2024.
 \item{[7]} Sherlock, C., Urbas, S. and Ludkin, M. 2023. The apogee to apogee path sampler. \textit{JCGS}, 32(4).
 \end{description}
\end{session}

\input{sessS18.tex}

\clearpage

\begin{session}
 {Stochastic Optimization}% [1] session title
 {Shane G. Henderson}% [2] organizer one name
 {Cornell University}% [3] organizer one affiliations
 {sgh9@cornell.edu}% [4] organizer one email
{}{}{}
 {S19}% [8] session id
{}

 In many applications, one wishes to solve an optimization problem
 $\min_{x \in X} f(x)$, where $f(\cdot)$ and/or its derivatives can
 only be evaluated through noisy estimates obtained using Monte Carlo
 simulation. Such problems are ubiquitous in machine learning, and also
 arise in stochastic simulation applications. This session will consist
 of 3 talks in the area.
\end{session}

\input{sessS19.tex}

\clearpage

\begin{session}
 {Recent Progress on Algorithmic Discrepancy Theory and Applications}% [1] session title
 {Haotian Jiang}% [2] organizer one name
 {University of Chicago}% [3] organizer one affiliations
 {jhtdavid@uchicago.edu}% [4] organizer one email
{}{}{}
 {S20}% [8] session id
{}

 Discrepancy theory studies the irregularities of distributions. Typical questions studied in discrepancy theory include: ``What is the most uniform way of distributing n points in the unit square, and how big must the irregularity be?", ``What is the best way to divide a set of $n$ objects into two groups that are as 'similar' as possible?" These questions have been studied since the 1930s and progress on them have found extensive applications to many areas of mathematics, computer science, statistics, finance, etc.
 The past decade has seen tremendous progress in designing efficient algorithms for discrepancy questions. These developments have led to many surprising applications in areas such as differential privacy, graph sparsification, approximation algorithms and rounding, kernel density estimation, randomized controlled trials, and quasi-Monte Carlo methods.
 The goal of this special session is to present several exciting recent progress in this direction, and to facilitate cross-fertilization across different areas.
 \medskip
 A few related recent papers in this direction are listed below.
 \begin{enumerate}
 \item [{[1]}] Harshaw, Christopher, Fredrik Sävje, Daniel A. Spielman, and Peng Zhang (2024). {\it Balancing covariates in randomized experiments with the gram–schmidt walk design.} Journal of the American Statistical Association 119, no. 548 (2024): 2934-2946.
 \item[{[2]}] Bansal, Nikhil, and Haotian Jiang (2025). {\it Quasi-Monte Carlo Beyond Hardy-Krause.} In Proceedings of the 2025 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 2051-2075. Society for Industrial and Applied Mathematics, 2025.
 \item [{[3]}] Aistleitner, Christoph, Dmitriy Bilyk, and Aleksandar Nikolov (2016). {\it Tusnády’s problem, the transference principle, and non-uniform QMC sampling.} In Monte Carlo and Quasi-Monte Carlo Methods: MCQMC 2016, Stanford, CA, August 14-19 12, pp. 169-180. Springer International Publishing, 2018.
 \end{enumerate}
\end{session}

\input{sessS20.tex}

\clearpage

\begin{session}
 {Monte Carlo Applications in High-performance Computing, Computer Graphics, and Computational Science}% [1] session title
 {Michael Mascagni}% [2] organizer one name
 {Florida State University and the National Institute of Standards and Technology}% [3] organizer one affiliations
 {mascagni@fsu.edu}% [4] organizer one email
{}{}{}
 {S21}% [8] session id
{}

 Monte Carlo methods are useful for solving problems in a variety of areas.  We have four talks organized that span several areas.  First, we consider the how Monte Carlo methods can provide fault tolerance to large computations via work on simulating soft and hard faults in Monte Carlo computation on a state-of-the-art computer.  Next, we consider using Monte Carlo to create a fast and efficient computer graphics renderer. Next we consider two talks on applications of Monte Carlo to the solution of partial differential equations.  One of these talks deals specifically with equations that arise in financial computing.
\end{session}

\input{sessS21.tex}

\clearpage

\begin{session}
 {QMC and Applications Part II}% [1] session title
 {Michael Gnewuch}% [2] organizer one name
 {University of Osnabrück}% [3] organizer one affiliations
 {michael.gnewuch@uni-osnabrueck.de}% [4] organizer one email
 {Takashi Goda}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {The University of Tokyo}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {goda@frcer.t.u-tokyo.ac.jp}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S22}% [8] session id
 {\thirdorganizer{Peter Kritzer}{Austrian Academy of Sciences}{peter.kritzer@oeaw.ac.at}}% [9] third organizer, if any

 Quasi-Monte Carlo (QMC) methods have been widely studied as an effective tool for high-dimensional integration and have found applications in various fields, including computational finance, computer graphics, data compression, partial differential equations with random coefficients, and %recently also
 optimization.
 Despite their success, ongoing theoretical developments and the expansion of application areas continue to drive this research field forward. This special session is devoted to showcasing recent advances in the theory of QMC methods and their applications.
\end{session}

\input{sessS22.tex}

\clearpage

\begin{session}
 {Analysis of Langevin and Related Sampling Algorithms, Part I}% [1] session title
 {Yifan Chen}% [2] organizer one name
 {Courant Institute of Mathematical Sciences, New York University}% [3] organizer one affiliations
 {yifan.chen@nyu.edu}% [4] organizer one email
 {Xiaoou Cheng}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Courant Institute of Mathematical Sciences, New York University}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {chengxo@nyu.edu}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S23}% [8] session id
 {\thirdorganizer{Jonathan Weare}{Courant Institute of Mathematical Sciences, New York University}{weare@nyu.edu}}% [9] third organizer, if any

 {}
 Many Markov Chain Monte Carlo (MCMC) samplers are based on stochastic dynamics. Langevin dynamics serves as a fundamental basis for a vast family of extensions, such as unadjusted Langevin algorithms, kinetic/underdamped Langevin algorithms, Hamiltonian Monte Carlo, and the No-U-Turn Sampler (NUTS). The gradient flow structure of Langevin dynamics also motivates the development of a large class of novel algorithms such as stein variational gradient descent, birth-death process approaches, and those based on Fisher-Rao gradient flows. These methods have become ubiquitous across various fields, including molecular dynamics, Bayesian statistics, and machine learning. Recent years have seen significant theoretical advances in analyzing such methods, particularly in high-dimensional settings and non-convex cases. This special session aims to bring together researchers from different communities (probability, statistics, scientific computing, theoretical computer science, machine learning, etc.)\ working on analysis of sampling dynamics of Langevin and beyond to present recent progress, discuss challenges, and share ideas.
\end{session}

\input{sessS23.tex}

\clearpage

\begin{session}
 {Nested expectations: models and estimators, Part II}% [1] session title
 {Arved Bartuska}% [2] organizer one name
 {King Abdullah University of Science and Technology/RWTH Aachen University}% [3] organizer one affiliations
 {arved.bartuska@kaust.edu.sa}% [4] organizer one email
 {Abdul-Lateef Haji-Ali}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Heriot-Watt University}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {a.hajiali@hw.ac.uk}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S24}% [8] session id
{}

 Nested expectations arise in many applications, such as in engineering, mathematical finance, and medical decision-making. In addition to their nested structure, numerical estimations of such expectations are often complicated by singularities or discontinuities. Moreover, approximations when evaluating inner expectations using, for example, finite element or time-stepping schemes render traditional estimation methods such as double-loop Monte Carlo prohibitively expensive. This session will explore models and applications with this structure and methods for efficient estimation.
\end{session}

\input{sessS24.tex}

\clearpage

\begin{session}
 {QMC and Applications Part II}% [1] session title
 {Michael Gnewuch}% [2] organizer one name
 {University of Osnabrück}% [3] organizer one affiliations
 {michael.gnewuch@uni-osnabrueck.de}% [4] organizer one email
 {Takashi Goda}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {The University of Tokyo}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {goda@frcer.t.u-tokyo.ac.jp}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S25}% [8] session id
 {\thirdorganizer{Peter Kritzer}{Austrian Academy of Sciences}{peter.kritzer@oeaw.ac.at}}% [9] third organizer, if any

 Quasi-Monte Carlo (QMC) methods have been widely studied as an effective tool for high-dimensional integration and have found applications in various fields, including computational finance, computer graphics, data compression, partial differential equations with random coefficients, and %recently also
 optimization.
 Despite their success, ongoing theoretical developments and the expansion of application areas continue to drive this research field forward. This special session is devoted to showcasing recent advances in the theory of QMC methods and their applications.
\end{session}

\input{sessS25.tex}

\clearpage

\begin{session}
 {Analysis of Langevin and Related Sampling Algorithms, Part II}% [1] session title
 {Yifan Chen}% [2] organizer one name
 {Courant Institute of Mathematical Sciences, New York University}% [3] organizer one affiliations
 {yifan.chen@nyu.edu}% [4] organizer one email
 {Xiaoou Cheng}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Courant Institute of Mathematical Sciences, New York University}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {chengxo@nyu.edu}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S26}% [8] session id
 {\thirdorganizer{Jonathan Weare}{Courant Institute of Mathematical Sciences, New York University}{weare@nyu.edu}}% [9] third organizer, if any

 {}
 Many Markov Chain Monte Carlo (MCMC) samplers are based on stochastic dynamics. Langevin dynamics serves as a fundamental basis for a vast family of extensions, such as unadjusted Langevin algorithms, kinetic/underdamped Langevin algorithms, Hamiltonian Monte Carlo, and the No-U-Turn Sampler (NUTS). The gradient flow structure of Langevin dynamics also motivates the development of a large class of novel algorithms such as stein variational gradient descent, birth-death process approaches, and those based on Fisher-Rao gradient flows. These methods have become ubiquitous across various fields, including molecular dynamics, Bayesian statistics, and machine learning. Recent years have seen significant theoretical advances in analyzing such methods, particularly in high-dimensional settings and non-convex cases. This special session aims to bring together researchers from different communities (probability, statistics, scientific computing, theoretical computer science, machine learning, etc.)\ working on analysis of sampling dynamics of Langevin and beyond to present recent progress, discuss challenges, and share ideas.
\end{session}

\input{sessS26.tex}

\clearpage

\begin{session}
 {Recent Advances in Stochastic Gradient Descent}% [1] session title
 {Jing Dong}% [2] organizer one name
 {Columbia University}% [3] organizer one affiliations
 {jing.dong@gsb.columbia.edu}% [4] organizer one email
{}{}{}
 {S27}% [8] session id
{}

 Stochastic Gradient Descent (SGD) is a cornerstone optimization method in machine learning,
 renowned for its efficiency in handling large-scale data. Its iterative approach enables
 the processing of extensive datasets by updating model parameters using randomly selected
 data subsets, thereby reducing computational costs. Despite its widespread adoption, traditional
 SGD faces challenges such as convergence to sharp minima, and sensitivity to data
 distribution shifts. Addressing these challenges is crucial for enhancing model generalization,
 robustness, and overall performance in diverse applications. This session aims to delve into
 recent developments that address these challenges in SGD, presenting innovative methodologies
 and theoretical insights to enhance its effectiveness in complex learning scenarios.
 The session will have three to four speakers. Currently, the confirmed speakers are Jose
 Blanchet (Stanford University), Chang-Han Rhee (Northwestern University), and Jing Dong
 (Columbia University). Each will present their recent works on stochastic gradient descent,
 ranging from SGD and heavy-tailed phenomenon to SGD with adaptively generated data.
 Collectively, these talks will shed light on cutting-edge advancements in SGD methodologies,
 providing both theoretical frameworks and practical strategies to enhance optimization in
 complex, real-world applications.
\end{session}

\input{sessS27.tex}

\clearpage

\begin{session}
 {Forward and Inverse Problems for Stochastic Reaction Networks}% [1] session title
 {Sophia Münker}% [2] organizer one name
 {RWTH Aachen University}% [3] organizer one affiliations
 {muenker@uq.rwth-aachen.de}% [4] organizer one email
 {Chiheb Ben Hammouda}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Utrecht University}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {c.benhammouda@uu.nl}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S28}% [8] session id
 {\thirdorganizer{Raúl Tempone}{RWTH Aachen University}{tempone@uq.rwth-aachen.de}}% [9] third organizer, if any

 This session aims to bring together experts working on stochastic reaction networks and pure jump processes for modeling stochastic biological and chemical systems. The session is about recent advances in Monte Carlo methods, variance and dimension reduction techniques that are relevant for tackling forward and inverse problems.
 \medskip
 The speakers are:
 \begin{itemize}
 \item Zhou Fang (Academy of Mathematics and Systems Science, Chinese Academy of Sciences)
 \item Sophia Münker (RWTH Aachen University)
 \item Maksim Chupin (King Abdullah University of Science and Technology (KAUST))
 \item Muruhan Rathinam (University of Maryland Baltimore County)
 \end{itemize}
\end{session}

\input{sessS28.tex}

\clearpage

\begin{session}
 {Hardware or Software for (Quasi-)Monte Carlo Algorithms, Part II}% [1] session title
 {Sou-Cheng T.  Choi}% [2] organizer one name
 {Illinois Institute of Technology}% [3] organizer one affiliations
 {schoi32@iit.edu}% [4] organizer one email
 {Pieterjan Robbe}% [5] organizer two name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {Sandia National Laboratories}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {pmrobbe@sandia.gov}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
 {S29}% [8] session id
 {\thirdorganizer{Mike Giles}{University of Oxford}{mike.giles@maths.ox.ac.uk}}% [9] third organizer, if any

 Monte Carlo (MC) or quasi-Monte Carlo (QMC) algorithms are widely used in various fields such as finance, physics, and engineering for their ability to handle high-dimensional integration problems. The development and maintenance of software for (quasi-)Monte Carlo ((Q)MC) algorithms can significantly enhance the accessibility and usability of these techniques. This special session aims to bring together experts from academia and industry to discuss recent advances in (Q)MC software, share best practices, and explore future directions, fostering collaboration among researchers and practitioners.
 Topics of interest for the session include:
 \begin{itemize}
 \item Novel hardware or architectural designs for open-source (Q)MC libraries.
 \item Best collaborative practices for developing and maintaining efficient and reliable (Q)MC software.
 \item Challenges and opportunities in integrating (Q)MC methods with machine learning and AI techniques.
 \item High-performance computing solutions for (Q)MC software.
 \item Adaptation of (Q)MC software to application fields such as finance, computer graphics, sensitivity analysis, Bayesian optimization, and uncertainty quantification.
 \item Innovative approaches to enhancing and extending existing (Q)MC tools.
 \end{itemize}
\end{session}

\input{sessS29.tex}

