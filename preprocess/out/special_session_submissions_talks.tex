\section{Special Sessions}
\begin{talk}
  {Stochastic Computation and Complexity, Part I}% [1] talk title
  {3}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Mon, July 28 10:30–12:30 Track A}% [7] time slot
  {S1}% [8] talk id
  {S1}% [9] session id or photo


  {\organizer{Stefan Heinrich}% organizer two name, if needed


	{RPTU Kaiserslautern-Landau}% orgnizer two affiliations, if needed


	{heinrich@informatik.uni-kl.de}}% organizer two email


 {\organizer{Thomas M\''uller-Gronbach }% organizer one name


{University of Passau}% orgnizer one affiliations


    {Thomas.Mueller-Gronbach@uni-passau.de}}% organizer one email


  {\organizer{Larisa Yaroslavtseva}% organizer one name


	{University of Graz}% orgnizer one affiliations


	{larisa.yaroslavtseva@uni-graz.at}}% organizer one email





The session is devoted to algorithms and complexity for\\





--- quadrature and strong approximation of SDEs and SPDEs, in particular under nonstandard assumptions,\\





--- high and infinite dimensional integration and approximation, and\\





--- stochastic optimization and neural networks,





including connections to functional analysis and stochastic analysis.








\medskip





Speakers:





\begin{enumerate}


\item Andreas Neuenkirch, University of Mannheim


\item Chengcheng Ling, University of Augsburg


\item Christopher Rauh\''ogger, University of Passau


\item Verena Schwarz, University of Klagenfurt


\end{enumerate}








\end{talk}

\begin{talk}
  {Domain uncertainty quantification}% [1] talk title
  {{\tt a.zepernick@fu-berlin.de}\\{\tt philipp.guth@ricam.oeaw.ac.at}\\{\tt vesa.kaarnioja@fu-berlin.de}}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Mon, July 28 10:30–12:30 Track B}% [7] time slot
  {S2}% [8] talk id
  {S2}% [9] session id or photo
  {}% [4] email
  {}% [5] organizer name. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
  {}% [6] affiliations. Leave unchanged if there is no second organizer, otherwise fill in accordingly.
  {}% [7] email. Leave unchanged if there is no second organizer, otherwise fill in accordingly.

Uncertainty in computational measurement models poses significant challenges in engineering and applied mathematics, where inaccuracies in material properties or geometric domains can greatly impact outcomes. Geometric errors, such as manufacturing imperfections or improper modeling in applications like electronic design and tomography, can be the dominant error contributor. Some approaches to modeling domain uncertainty include homogenization, perturbation, and reference mapping techniques, which facilitate the analysis of uncertainty propagation within computational measurement models. This session brings together leading experts to present recent theoretical and computational advancements in the study of domain uncertainty quantification.

List of speakers:

1. Andr\'e-Alexander Zepernick (Free University of Berlin)

2. Carlos Jerez-Hanckes (Universidad Adolfo Ib\'{a}\~{n}ez)

3. J\''urgen D\''olz (University of Bonn)

4. Harri Hakula (Aalto University)

\end{talk}

\begin{talk}
  {Nested expectations: models and estimators, Part I}% [1] talk title
  {Arved Bartuska}% [2] speaker name
  {King Abdullah University of Science and Technology/RWTH Aachen University}% [3] affiliations
  {arved.bartuska@kaust.edu.sa}% [4] email
  {Abdul-Lateef Haji-Ali}% [5] coauthors
  {Heriot-Watt University}% [6] special session
  {Mon, July 28 10:30–12:30 Track C}% [7] time slot
  {S3}% [8] talk id
  {S3}% [9] session id or photo

Nested expectations 
arise in many applications, such as in engineering, mathematical finance, and medical decision-making. In addition to their nested structure, numerical estimations of such expectations are often complicated by singularities or discontinuities. Moreover, approximations when evaluating inner expectations using, for example, finite element or time-stepping schemes render traditional estimation methods such as double-loop Monte Carlo prohibitively expensive. This session will explore models and applications with this structure and methods for efficient estimation.

List of speakers:

Abdul-Lateef Haji-Ali (Heriot-Watt University)

Sebastian Krumscheid (Karlsruhe Institute of Technology)

Truong Vinh Hoang (RWTH Aachen University)

Vesa Kaarnioja (FU Berlin)

\end{talk}

\begin{talk}
  {Hardware or Software for (Quasi-)Monte Carlo Algorithms}% [1] talk title
  {3}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Mon, July 28 10:30–12:30 Track D}% [7] time slot
  {S4}% [8] talk id
  {S4}% [9] session id or photo
  {\organizer{Sou-Cheng T.  Choi}% organizer one name
    {Illinois Institute of Technology}% orgnizer one affiliations
    {schoi32@iit.edu}}% organizer one email
  {\organizer{Pieterjan Robbe}% organizer two name, if needed
	{Sandia National Laboratories}% orgnizer two affiliations, if needed
	{pmrobbe@sandia.gov}}% organizer two email
  {\organizer{Mike Giles}% organizer one name
	{University of Oxford}% orgnizer one affiliations
	{mike.giles@maths.ox.ac.uk}}% organizer one email

Monte Carlo (MC) or quasi-Monte Carlo (QMC) algorithms are widely used in various fields such as finance, physics, and engineering for their ability to handle high-dimensional integration problems. The development and maintenance of software for (quasi-)Monte Carlo ((Q)MC) algorithms can significantly enhance the accessibility and usability of these techniques. This special session aims to bring together experts from academia and industry to discuss recent advances in (Q)MC software, share best practices, and explore future directions, fostering collaboration among researchers and practitioners.

Topics of interest for the session include:
\begin{itemize}
    \item Novel hardware or architectural designs for open-source (Q)MC libraries.
    \item Best collaborative practices for developing and maintaining efficient and reliable (Q)MC software.
    \item Challenges and opportunities in integrating (Q)MC methods with machine learning and AI techniques.
    \item High-performance computing solutions for (Q)MC software.
    \item Adaptation of (Q)MC software to application fields such as finance, computer graphics, sensitivity analysis, Bayesian optimization, and uncertainty quantification.
    \item Innovative approaches to enhancing and extending existing (Q)MC tools.
\end{itemize}


Committed Speakers and Topics:
\begin{itemize}
\item Part 1 of the Special Session:
\begin{itemize}
    \item Speaker 1: Pieterjan Robbe, Sandia National Laboratories, Multifidelity QMC development in Dakota (https://dakota.sandia.gov/), \texttt{pmrobbe@sandia.gov}
    \item Speaker 2: Irina-Beatrice Haas, University of Oxford,  MLMC for FPGAs, \newline \texttt{Irina-Beatrice.Haas@maths.ox.ac.uk} 
    \item Speaker 3: Mike Giles, University of Oxford, CUDA implementation of MLMC (\url{https://people.maths.ox.ac.uk/gilesm/mlmc/}), \texttt{mike.giles@maths.ox.ac.uk}
    \item Speaker 4: Chung Ming Loi,  Durham University, UM-Bridge (\url{https://github.com/um-bridge}), \texttt{chung.m.loi@durham.ac.uk} %PhD student of Anne Reinarz 
\end{itemize}
\item Part 2 of the Special Session:
\begin{itemize}
    \item Speaker 5:  Niklas Baumgarten, University of Heidelberg, Software for Multilevel Monte Carlo Methods, \texttt{niklas.baumgarten@uni-heidelberg.de}
    \item Speaker 6: Aleksei Sorokin,  Illinois Institute of Technology, QMCPy's Randomization Routines and Fast Kernel Interpolation, \texttt{asorokin@hawk.iit.edu}
    \item Speaker 7:  Johannes Krotz, University of Notre Dame, Methods and Software for Hybrid Q/MC Solvers for Radiation Transport, \texttt{jkrotz@nd.edu} %postdoc of Ryan McClarren
    \item Speaker 8: Joseph Farmer, University of Notre Dame, High Performance Calculations of Radiation Emission from High Temperature Fluid Flow, \texttt{jfarmer4@nd.edu} % PhD Student of Ryan McClarren

\end{itemize}
\end{itemize}


\medskip
\begin{comment}
If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.
%APA reference style is recommended.
\begin{enumerate}
	\item[{[1]}] Niederreiter, Harald (1992). {\it Random number generation and quasi-Monte Carlo methods}. Society for Industrial and Applied Mathematics (SIAM).
	\item[{[2]}] Roberts, Gareth O, \& Rosenthal, Jeffrey S. (2002).  Optimal scaling for various Metropolis-Hastings algorithms, \textbf{16}(4), 351--367.
\end{enumerate}

Equations may be used if they are referenced. Please note that the equation numbers may be different (but will be cross-referenced correctly) in the final program book.
\end{comment}
\end{talk}

\begin{talk}
  {Stochastic Computation and Complexity, Part II}% [1] talk title
  {3}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Mon, July 28 15:30–17:30 Track F}% [7] time slot
  {S5}% [8] talk id
  {S5}% [9] session id or photo


  {\organizer{Stefan Heinrich}% organizer two name, if needed


	{RPTU Kaiserslautern-Landau}% orgnizer two affiliations, if needed


	{heinrich@informatik.uni-kl.de}}% organizer two email


 {\organizer{Thomas M\''uller-Gronbach }% organizer one name


{University of Passau}% orgnizer one affiliations


    {Thomas.Mueller-Gronbach@uni-passau.de}}% organizer one email


  {\organizer{Larisa Yaroslavtseva}% organizer one name


	{University of Graz}% orgnizer one affiliations


	{larisa.yaroslavtseva@uni-graz.at}}% organizer one email





The session is devoted to algorithms and complexity for\\





--- quadrature and strong approximation of SDEs and SPDEs, in particular under nonstandard assumptions,\\





--- high and infinite dimensional integration and approximation, and\\





--- stochastic optimization and neural networks,





including connections to functional analysis and stochastic analysis.








\medskip





Speakers:





\begin{enumerate}


\item Michael Gnewuch, Osnabr\''uck University


\item Kateryna Pozharska, Chemnitz University of Technology


\item Marcin Wnuk, Osnabr\''uck University


\item Leszek Plaskota, University of Warsaw





\end{enumerate}








\end{talk}

\begin{talk}
  {Recent advances in optimization under uncertainty}% [1] talk title
  {Philipp A. Guth}% [2] speaker name
  {RICAM, Austrian Academy of Sciences}% [3] affiliations
  {philipp.guth@ricam.oeaw.ac.at}% [4] email
  {Vesa Kaarnioja}% [5] coauthors
  {Free University of Berlin}% [6] special session
  {Mon, July 28 15:30–17:30 Track G}% [7] time slot
  {S6}% [8] talk id
  {S6}% [9] session id or photo

The quantification of uncertainties associated with large-scale optimization problems based on partial differential equation models typically involves a number of uncertainties. Some uncertain parameters may include, e.g., the material parameters, domain shape or sensor locations used to collect measurement data. The associated challenging high-dimensional integration problems can be solved efficiently using, e.g., multilevel Monte Carlo or quasi-Monte Carlo methods. This session aims to cover some recent developments in the computational and theoretical treatment of this actively developing field of research.

List of speakers:

1. Tapio Helin (LUT University)

2. Karina Koval (University of Heidelberg)

3. Johannes Milz (Georgia Institute of Technology)

4. Arved Bartuska (RWTH Aachen)

\end{talk}

\begin{talk}
  {Computational Methods for Low-discrepancy Sampling and Applications}% [1] talk title
  {2}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Mon, July 28 15:30–17:30 Track H}% [7] time slot
  {S7}% [8] talk id
  {S7}% [9] session id or photo
  {\organizer{Nathan Kirk}% organizer one name
    {Illinois Institute of Technology}% orgnizer one affiliations
    {nkirk@iit.edu}}% organizer one email
  {\organizer{François Clément}% organizer two name, if needed
	{University of Washington}% orgnizer two affiliations, if needed
	{fclement@uw.edu}}% organizer two email
  {\organizer{Name three}% organizer one name
	{Affiliation(s) three}% orgnizer one affiliations
	{organizer-three-email-goes@here}}% organizer one email

This session aims to showcase recent advancements in the optimization of sample point distributions [1, 2] and their applications. Some of the methods on display will range from deep learning methods to permutation optimization and greedy approaches [3], showcasing the usefulness of the $L_2$-discrepancies in optimizing the $L_{\infty}$ discrepancies. As a consequence of some of these improved low-discrepancy sets, an application will be shown in improved path planning in robotics [4]. Several other applications will be explored in the context of using the median over the mean of $r$ RQMC estimates as proposed in several recent papers including [5].

\medskip


\begin{enumerate}
	\item[{[1]}] T. K. Rusch, N. Kirk, M. Bronstein, C. Lemieux and D. Rus, \textit{Message-Passing Monte Carlo: Generating low-discrepancy point sets via graph neural networks}, PNAS \textbf{121} (40) e2409913121 (2024)

	\item[{[2]}] F. Clément, C. Doerr, K. Klamroth, L. Paquete, \textit{Transforming the Challenge of Constructing Low-Discrepancy Point Sets into a Permutation Selection Problem}, \url{https://arxiv.org/abs/2407.11533}.
    \item[{[3]}] F. Cl\'ement, \textit{Outperforming the Best {1D} Low-Discrepancy Constructions with a Greedy Algorithm}, \url{https://arxiv.org/abs/2406.18132}.
        \item[{[4]}] M. Chahine, T. K. Rusch, Z. J. Patterson and D. Rus, \textit{Improving Efficiency of Sampling-based Motion Planning via Message-Passing Monte Carlo}, \url{https://arxiv.org/abs/2410.03909}
        \item[{[5]}] P. L'Ecuyer, M. K. Nayakama, A. B. Owen and B. Tuffin, \textit{Confidence Intervals for Randomized Quasi-Monte Carlo Estimators}, Proceedings of the 2023 Winter Simulation Conference (2023)
\end{enumerate}

Speakers:
\begin{enumerate}
    \item François Clément (University of Washington)
    \item Nathan Kirk (Illinois Tech)
    \item Makram Chahine (MIT)
    \item Greg de Salaberry Seljak (University of Montréal)
\end{enumerate}

  
\end{talk}

\begin{talk}
  {Stochastic Computation and Complexity, Part III}% [1] talk title
  {3}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Tue, July 29 10:30–12:30 Track A}% [7] time slot
  {S8}% [8] talk id
  {S8}% [9] session id or photo


  {\organizer{Stefan Heinrich}% organizer two name, if needed


	{RPTU Kaiserslautern-Landau}% orgnizer two affiliations, if needed


	{heinrich@informatik.uni-kl.de}}% organizer two email


 {\organizer{Thomas M\''uller-Gronbach }% organizer one name


{University of Passau}% orgnizer one affiliations


    {Thomas.Mueller-Gronbach@uni-passau.de}}% organizer one email


  {\organizer{Larisa Yaroslavtseva}% organizer one name


	{University of Graz}% orgnizer one affiliations


	{larisa.yaroslavtseva@uni-graz.at}}% organizer one email





The session is devoted to algorithms and complexity for\\





--- quadrature and strong approximation of SDEs and SPDEs, in particular under nonstandard assumptions,\\





--- high and infinite dimensional integration and approximation, and\\





--- stochastic optimization and neural networks,





including connections to functional analysis and stochastic analysis.








\medskip





Speakers:





\begin{enumerate}


\item Jean-Fran\c{c}ois Chassagneux, ENSAE Paris





\item Gon\c{c}alo dos Reis, University of Edinburgh





\item Noufel Frikha, Paris 1 Panth\'eon-Sorbonne University


\item Sotirios Sabanis, University of Edinburgh





 


\end{enumerate}








\end{talk}

\begin{talk}
  {Next-generation optimal experimental design: theory, scalability, and real world impact: Part I}% [1] talk title
  {3}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Tue, July 29 10:30–12:30 Track B}% [7] time slot
  {S9}% [8] talk id
  {S9}% [9] session id or photo
  {\organizer{Florence Forbes}% organizer one name
    {Inria, France}% orgnizer one affiliations
    {florence.forbes@inria.fr}}% organizer one email
  {\organizer{Xun Huan}% organizer two name, if needed
	{University of Michigan, USA}% orgnizer two affiliations, if needed
	{xhuan@umich.edu}}% organizer two email
  {\organizer{Youssef Marzouk}% organizer one name
	{Massachusetts Institute of Technology, USA}% orgnizer one affiliations
	{ymarz@mit.edu}}% organizer one email


Optimal experimental design (OED) provides a mathematical framework for identifying candidate data or experimental configurations that are most useful for inference, prediction, or some other downstream goal. Though OED is hardly a new topic,\footnote{At the first session of the Indian Statistical Conference in 1938, R.\ Fisher supposedly said, ``To call in the statistician after the experiment is done may be no more than asking him to perform a postmortem examination: he may be able to say what the experiment died of.''} the need for advances in OED has never been greater than it is today. Myriad application areas have witnessed, on the one hand, an explosion in the volume of data that can be acquired, and on the other, the use of increasingly complex and computationally intensive models to interpret these data. Yet large volumes of data do not by default carry a commensurate amount of information. Moreover, we inevitably face constraints: on the costs of experimentation or data acquisition, on data storage and communication, and on the computational effort of statistical inference in complex models. OED directly addresses the associated trade-offs---e.g., between experimentation, measurement, and/or processing \textit{costs} and 
the \textit{quality} of subsequent and decision making. See {\it e.g.} [1] for a recent review of OED topics, which provides numerous other references.

This session will highlight computational developments at the OED research frontier. Methods for stochastic simulation, high-dimensional approximation or integration, and stochastic optimization are central to modern OED and to the scaling of OED to large parameter spaces and complex statistical models. Modern machine learning methodologies---from neural network surrogates, to deep reinforcement learning in sequential OED, to modern generative models and transport methods for simulation-based inference---also play a catalyzing role in such OED approaches. Talks in this session will illuminate these emerging interactions and their role in realizing Bayesian, decision-theoretic, and information-theoretic formulations of OED for truly complex problems. Session speakers will also discuss ongoing work to develop theoretical guarantees for these new OED methodologies, and showcase applications to real-world problems ranging from sensor steering to seismology.

\medskip

\begin{enumerate}
	\item[{[1]}] X.\ Huan, J.\ Jagalur, Y.\ Marzouk (2024). Optimal experimental design: Formulations and computations, \textit{Acta Numerica} \textbf{33}, 715--840.
	%\item[{[2]}] T. Rainforth, A. Foster, D.R. Ivanova, F. Bickford Smith. Modern Bayesian experimental design, Statistical Science 39 (1), 100-114, 2024.
\end{enumerate}


\textbf{Speakers and their affiliations}

\begin{itemize}
\item Xun Huan, xhuan@umich.edu, University of Michigan, USA
\item Adrien Corenflos, adrien.corenflos@warwick.ac.uk, University of Warwick, UK 
\item Ayoub Belhadji, abelhadj@mit.edu, MIT, USA
\end{itemize}

\end{talk}

\begin{talk}
  {Heavy-tailed Sampling}% [1] talk title
  {Alex Shestopaloff}% [2] speaker name
  {Queen Mary University of London, UK}% [3] affiliations
  {a.shestopaloff@qmul.ac.uk}% [4] email
  {Jun Yang}% [5] coauthors
  {University of Copenhagen, Denmark}% [6] special session
  {Tue, July 29 10:30–12:30 Track C}% [7] time slot
  {S10}% [8] talk id
  {S10}% [9] session id or photo

Heavy-tailed distributions frequently arise in modern statistics, machine learning, and applied sciences, yet their intricate properties pose significant challenges for computational inference. This session, Heavy-Tailed Sampling, brings together cutting-edge advances in Monte Carlo methods and stochastic optimization to address these challenges. The topics span theoretical breakthroughs and practical algorithms, showcasing how heavy-tailed phenomena influence algorithmic design and performance. Our session aims to inspire new methods and applications in the broader Monte Carlo community. The session will explore:
\begin{itemize}
    \item 
Langevin Monte Carlo for Heavy-Tailed Distributions: A comprehensive complexity analysis of Langevin-based samplers for heavy-tailed targets using weighted Poincaré inequalities. The results reveal fundamental limits of mean-square analysis and include innovative techniques for gradient approximation.
\item
Stereographic MCMC: A novel class of samplers that map Euclidean spaces onto spheres to resolve mixing issues inherent to heavy-tailed targets. These methods, featuring uniform ergodicity and rapid convergence, capitalize on the ''blessings of dimensionality'' to enhance performance in high dimensions.
\item
Large Deviation Principles in MCMC: A groundbreaking application of large deviation theory to assess and improve MCMC algorithms. This approach extends to Metropolis-Hastings and related methods on general state spaces, providing new insights into empirical measure convergence and rate functions.
\item 
Heavy-Tailed Phenomena in Stochastic Gradient Descent (SGD): An analysis of heavy-tailed noise in SGD and its impact on escaping sharp minima in deep learning. The session highlights a variant of SGD with gradient truncation, offering theoretical and empirical evidence of enhanced generalization through flatter minima.
\end{itemize}

\medskip

List of speakers
\begin{itemize}
    \item Murat A.~Erdogdu, University of Toronto, Canada
    \item Sebastiano Grazzi, Bocconi University, Italy
    \item Federica Milinanni, KTH Royal Institute of Technology, Sweden
    \item Xingyu Wang,  University of Amsterdam, Netherlands
\end{itemize}




\end{talk}

\begin{talk}
  {Frontiers in (Quasi-)Monte Carlo and Markov Chain Monte Carlo Methods}% [1] talk title
  {2}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Tue, July 29 10:30–12:30 Track D}% [7] time slot
  {S11}% [8] talk id
  {S11}% [9] session id or photo
  {\organizer{Sou-Cheng T.  Choi}% organizer one name
    {Illinois Institute of Technology}% orgnizer one affiliations
    {schoi32@iit.edu}}% organizer one email
  {\organizer{Yuhan Ding}% organizer two name, if needed
	{Illinois Institute of Technology}% orgnizer two affiliations, if needed
	{yding2@iit.edu}}% organizer two email
  {\organizer{}% organizer one name
	{}% orgnizer one affiliations
	{}}% organizer one email


(Quasi-)Monte Carlo ((Q)MC) and Markov Chain Monte Carlo (MCMC) algorithms are fundamental tools in computational mathematics, with a wide range of applications spanning finance, physics, engineering, and more. These methods have proven invaluable in solving high-dimensional problems where traditional numerical techniques often fail, and continue to expand their reach into emerging fields such as artificial intelligence, climate modeling, precision medicine, and data science.

Recent advances in the theoretical foundations of these methods, including convergence rates, complexity analysis, sampling techniques, error analysis, variance reduction, optimal stopping conditions, and ergodic properties, have significantly improved their accuracy, efficiency, and reliability. In addition, interdisciplinary applications are driving new developments, such as machine learning, Bayesian inference, stochastic optimization, and uncertainty quantification.

This special session aims to bring together leading experts from academia and industry to share breakthroughs, foster interdisciplinary collaboration, and identify future research directions in the broad field of Monte Carlo methods. Participants will benefit from insights into cutting-edge research and practical applications of (Q)MC and MCMC methods, as well as opportunities to network with peers and thought leaders.


Committed Speakers and Topics:
\begin{itemize}

\item Speaker 1: Jonathan Weare, New York University, Convergence of Langevin in high dimensions, \texttt{weare@nyu.edu}
    
\item Speaker 2: Nikhil Bansal, University of Michigan, Ann Arbor, Theoretical Randomized quasi-Monte-Carlo and discrepancy, \texttt{bansal@gmail.com}
    
\item Speaker 3: Michael Mascagni, Florida State University, Solving partial differential equations using the walk-on-spheres method, \texttt{mascagni@fsu.edu}
    
\item Speaker 4: Hwanwoo Kim, Duke University, Utilizing the Gaussian process to facilitate MCMC for Bayesian inference with intractable likelihood or to perform black-box numerical integration to get the normalizing constant, \texttt{ghksdn1227@gmail.com}
\end{itemize}



\begin{comment}
If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.
%APA reference style is recommended.
\begin{enumerate}
	
\item[{[1]}] Niederreiter, Harald (1992). {\it Random number generation and quasi-Monte Carlo methods}. Society for Industrial and Applied Mathematics (SIAM).
	
\item[{[2]}] Roberts, Gareth O, \& Rosenthal, Jeffrey S. (2002).  Optimal scaling for various Metropolis-Hastings algorithms, \textbf{16}(4), 351--367.
\end{enumerate}

Equations may be used if they are referenced. Please note that the equation numbers may be different (but will be cross-referenced correctly) in the final program book.
\end{comment}
\end{talk}

\begin{talk}
  {Stochastic Computation and Complexity, Part IV}% [1] talk title
  {3}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Tue, July 29 15:30–17:30 Track F}% [7] time slot
  {S12}% [8] talk id
  {S12}% [9] session id or photo


  {\organizer{Stefan Heinrich}% organizer two name, if needed


	{RPTU Kaiserslautern-Landau}% orgnizer two affiliations, if needed


	{heinrich@informatik.uni-kl.de}}% organizer two email


 {\organizer{Thomas M\''uller-Gronbach }% organizer one name


{University of Passau}% orgnizer one affiliations


    {Thomas.Mueller-Gronbach@uni-passau.de}}% organizer one email


  {\organizer{Larisa Yaroslavtseva}% organizer one name


	{University of Graz}% orgnizer one affiliations


	{larisa.yaroslavtseva@uni-graz.at}}% organizer one email





The session is devoted to algorithms and complexity for\\





--- quadrature and strong approximation of SDEs and SPDEs, in particular under nonstandard assumptions,\\





--- high and infinite dimensional integration and approximation, and\\





--- stochastic optimization and neural networks,





including connections to functional analysis and stochastic analysis.








\medskip





Speakers:





\begin{enumerate}


\item Larisa Yaroslavtseva, University of Graz


\item Gunther Leobacher, University of Graz


\item Andr\'e Herzwurm, Rosenheim Technical University of Applied Sciences


\item Alexander Steinecke, University of Leoben


 


\end{enumerate}








\end{talk}

\begin{talk}
  {Next-generation optimal experimental design: theory, scalability, and real world impact: Part II}% [1] talk title
  {3}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Tue, July 29 15:30–17:30 Track G}% [7] time slot
  {S13}% [8] talk id
  {S13}% [9] session id or photo
  {\organizer{Florence Forbes}% organizer one name
    {Inria, France}% orgnizer one affiliations
    {florence.forbes@inria.fr}}% organizer one email
  {\organizer{Xun Huan}% organizer two name, if needed
	{University of Michigan, USA}% orgnizer two affiliations, if needed
	{xhuan@umich.edu}}% organizer two email
  {\organizer{Youssef Marzouk}% organizer one name
	{Massachusetts Institute of Technology, USA}% orgnizer one affiliations
	{ymarz@mit.edu}}% organizer one email


Optimal experimental design (OED) provides a mathematical framework for identifying candidate data or experimental configurations that are most useful for inference, prediction, or some other downstream goal. Though OED is hardly a new topic,\footnote{At the first session of the Indian Statistical Conference in 1938, R.\ Fisher supposedly said, ``To call in the statistician after the experiment is done may be no more than asking him to perform a postmortem examination: he may be able to say what the experiment died of.''} the need for advances in OED has never been greater than it is today. Myriad application areas have witnessed, on the one hand, an explosion in the volume of data that can be acquired, and on the other, the use of increasingly complex and computationally intensive models to interpret these data. Yet large volumes of data do not by default carry a commensurate amount of information. Moreover, we inevitably face constraints: on the costs of experimentation or data acquisition, on data storage and communication, and on the computational effort of statistical inference in complex models. OED directly addresses the associated trade-offs---e.g., between experimentation, measurement, and/or processing \textit{costs} and 
the \textit{quality} of subsequent and decision making. See {\it e.g.} [1] for a recent review of OED topics, which provides numerous other references.

This session will highlight computational developments at the OED research frontier. Methods for stochastic simulation, high-dimensional approximation or integration, and stochastic optimization are central to modern OED and to the scaling of OED to large parameter spaces and complex statistical models. Modern machine learning methodologies---from neural network surrogates, to deep reinforcement learning in sequential OED, to modern generative models and transport methods for simulation-based inference---also play a catalyzing role in such OED approaches. Talks in this session will illuminate these emerging interactions and their role in realizing Bayesian, decision-theoretic, and information-theoretic formulations of OED for truly complex problems. Session speakers will also discuss ongoing work to develop theoretical guarantees for these new OED methodologies, and showcase applications to real-world problems ranging from sensor steering to seismology.

\medskip

\begin{enumerate}
	\item[{[1]}] X.\ Huan, J.\ Jagalur, Y.\ Marzouk (2024). Optimal experimental design: Formulations and computations, \textit{Acta Numerica} \textbf{33}, 715--840.
	%\item[{[2]}] T. Rainforth, A. Foster, D.R. Ivanova, F. Bickford Smith. Modern Bayesian experimental design, Statistical Science 39 (1), 100-114, 2024.
\end{enumerate}


\textbf{Speakers and their affiliations}

\begin{itemize}
\item Alen Alexanderian,  aalexan3@ncsu.edu, North Carolina State University, USA

\item Jacopo Iollo, jacopo.iollo@inria.fr, INRIA, Universit\'e Grenoble Alpes, France

\item Tommie Catanach, tacatan@sandia.gov , Sandia National Laboratories, USA

\end{itemize}

\end{talk}

\begin{talk}
  {Advances in Rare Events Simulation}% [1] talk title
  {3}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Tue, July 29 15:30–17:30 Track H}% [7] time slot
  {S14}% [8] talk id
  {S14}% [9] session id or photo
  {\organizer{Nadhir Ben Rached}% organizer one name
    {University of Leeds, United Kingdom}% orgnizer one affiliations
    {N.BenRached@leeds.ac.uk}}% organizer one email
  {\organizer{Shyam Mohan Subbiah Pillai}% organizer two name, if needed
	{RWTH Aachen University, Germany}% orgnizer two affiliations, if needed
	{subbiah@uq.rwth-aachen.de}}% organizer two email
  {\organizer{Ra\'ul Tempone}% organizer one name
	{King Abdullah University of Science and Technology, Saudi Arabia}% orgnizer one affiliations
	{raul.tempone@kaust.edu.sa}}% organizer one email

Rare events are events with small probabilities, but their occurrences are critical in many real-life applications. The problem of estimating rare event probabilities is encountered in various engineering applications (finance, wireless communications, system reliability, biology, etc.). Naive Monte Carlo simulations are, in this case, substantially expensive. This session focuses on advances in methods belonging to the class of variance reduction techniques.  These alternative methods deliver, when appropriately used, accurate estimates with a substantial amount of variance reduction compared to the naive Monte Carlo estimator. 

Proposed speakers:

\begin{enumerate}
	\item Victor Elvira, Professor in Statistics and Data Science, University of Edinburgh, United Kingdom
	\item Bruno Tuffin, Director of Research, INRIA Rennes-Bretagne Atlantique, France
	\item Eya Ben Amar, King Abdullah University of Science and Technology, Saudi Arabia
	\item Shyam Mohan Subbiah Pillai, RWTH Aachen University, Germany
\end{enumerate}

\medskip
%
%If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
%Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.
%%APA reference style is recommended.
%\begin{enumerate}
%	\item[{[1]}] Niederreiter, Harald (1992). {\it Random number generation and quasi-Monte Carlo methods}. Society for Industrial and Applied Mathematics (SIAM).
%	\item[{[2]}] Roberts, Gareth O, \& Rosenthal, Jeffrey S. (2002).  Optimal scaling for various Metropolis-Hastings algorithms, \textbf{16}(4), 351--367.
%\end{enumerate}
%
%Equations may be used if they are referenced. Please note that the equation numbers may be different (but will be cross-referenced correctly) in the final program book.

\end{talk}

\begin{talk}
  {Frontiers in (Quasi-)Monte Carlo and Markov Chain Monte Carlo Methods}% [1] talk title
  {2}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Tue, July 29 15:30–17:30 Track I}% [7] time slot
  {S15}% [8] talk id
  {S15}% [9] session id or photo
  {\organizer{Sou-Cheng T.  Choi}% organizer one name
    {Illinois Institute of Technology}% orgnizer one affiliations
    {schoi32@iit.edu}}% organizer one email
  {\organizer{Yuhan Ding}% organizer two name, if needed
	{Illinois Institute of Technology}% orgnizer two affiliations, if needed
	{yding2@iit.edu}}% organizer two email
  {\organizer{}% organizer one name
	{}% orgnizer one affiliations
	{}}% organizer one email


(Quasi-)Monte Carlo ((Q)MC) and Markov Chain Monte Carlo (MCMC) algorithms are fundamental tools in computational mathematics, with a wide range of applications spanning finance, physics, engineering, and more. These methods have proven invaluable in solving high-dimensional problems where traditional numerical techniques often fail, and continue to expand their reach into emerging fields such as artificial intelligence, climate modeling, precision medicine, and data science.

Recent advances in the theoretical foundations of these methods, including convergence rates, complexity analysis, sampling techniques, error analysis, variance reduction, optimal stopping conditions, and ergodic properties, have significantly improved their accuracy, efficiency, and reliability. In addition, interdisciplinary applications are driving new developments, such as machine learning, Bayesian inference, stochastic optimization, and uncertainty quantification.

This special session aims to bring together leading experts from academia and industry to share breakthroughs, foster interdisciplinary collaboration, and identify future research directions in the broad field of Monte Carlo methods. Participants will benefit from insights into cutting-edge research and practical applications of (Q)MC and MCMC methods, as well as opportunities to network with peers and thought leaders.


Committed Speakers and Topics:
\begin{itemize}

\item Speaker 1: Jonathan Weare, New York University, Convergence of Langevin in high dimensions, \texttt{weare@nyu.edu}
    
\item Speaker 2: Nikhil Bansal, University of Michigan, Ann Arbor, Theoretical Randomized quasi-Monte-Carlo and discrepancy, \texttt{bansal@gmail.com}
    
\item Speaker 3: Michael Mascagni, Florida State University, Solving partial differential equations using the walk-on-spheres method, \texttt{mascagni@fsu.edu}
    
\item Speaker 4: Hwanwoo Kim, Duke University, Utilizing the Gaussian process to facilitate MCMC for Bayesian inference with intractable likelihood or to perform black-box numerical integration to get the normalizing constant, \texttt{ghksdn1227@gmail.com}
\end{itemize}



\begin{comment}
If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.
%APA reference style is recommended.
\begin{enumerate}
	
\item[{[1]}] Niederreiter, Harald (1992). {\it Random number generation and quasi-Monte Carlo methods}. Society for Industrial and Applied Mathematics (SIAM).
	
\item[{[2]}] Roberts, Gareth O, \& Rosenthal, Jeffrey S. (2002).  Optimal scaling for various Metropolis-Hastings algorithms, \textbf{16}(4), 351--367.
\end{enumerate}

Equations may be used if they are referenced. Please note that the equation numbers may be different (but will be cross-referenced correctly) in the final program book.
\end{comment}
\end{talk}

\begin{talk}
  {Stochastic Computation and Complexity, Part V}% [1] talk title
  {3}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Wed, July 30 10:30–12:30 Track A}% [7] time slot
  {S16}% [8] talk id
  {S16}% [9] session id or photo


  {\organizer{Stefan Heinrich}% organizer two name, if needed


	{RPTU Kaiserslautern-Landau}% orgnizer two affiliations, if needed


	{heinrich@informatik.uni-kl.de}}% organizer two email


 {\organizer{Thomas M\''uller-Gronbach }% organizer one name


{University of Passau}% orgnizer one affiliations


    {Thomas.Mueller-Gronbach@uni-passau.de}}% organizer one email


  {\organizer{Larisa Yaroslavtseva}% organizer one name


	{University of Graz}% orgnizer one affiliations


	{larisa.yaroslavtseva@uni-graz.at}}% organizer one email





The session is devoted to algorithms and complexity for\\





--- quadrature and strong approximation of SDEs and SPDEs, in particular under nonstandard assumptions,\\





--- high and infinite dimensional integration and approximation, and\\





--- stochastic optimization and neural networks,





including connections to functional analysis and stochastic analysis.








\medskip





Speakers:





\begin{enumerate}


\item Stefan Heinrich, RPTU Kaiserslautern-Landau


\item Bernd K\''a\ss emodel, Chemnitz University of Technology


\item Matti Vihola, University of Jyv\''askyl\''a 


\item Klaus Ritter, RPTU Kaiserslautern-Landau


 


\end{enumerate}








\end{talk}

\begin{talk}
  {Statistical Design of Experiments}% [1] talk title
  {2}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Wed, July 30 10:30–12:30 Track B}% [7] time slot
  {S17}% [8] talk id
  {S17}% [9] session id or photo
  {\organizer{Lulu Kang}% organizer one name
    {University of Massachusetts Amherst}% orgnizer one affiliations
    {lulukang@umass.edu}}% organizer one email
  {\organizer{Chunfang Devon Lin}% organizer two name, if needed
	{Queen's University}% orgnizer two affiliations, if needed
	{devon.lin@queensu.ca}}% organizer two email
  {\organizer{Name three}% organizer one name
	{Affiliation(s) three}% orgnizer one affiliations
	{organizer-three-email-goes@here}}% organizer one email


\medskip

This session explores innovative methodologies for optimizing experimental design and factor analysis in complex, high-dimensional, and resource-constrained settings. The first talk introduces QuIP, a novel framework for designing experiments with qualitative factors using integer programming and Gaussian process models, demonstrating its effectiveness in path planning and rover trajectory optimization. The second talk addresses the challenge of cost-efficient predictive computing by proposing a multi-fidelity emulator design inspired by Multilevel Monte Carlo methods, which ensures predictive accuracy while minimizing computational costs under a tight budget. The third talk shifts focus to experiments involving both quantitative and sequence factors, presenting a new class of optimal quantitative-sequence (QS) designs that are flexible, space-filling, and asymptotically orthogonal, making them ideal for high-dimensional applications in medical science and bio-engineering. Finally, the fourth talk introduces FIRST, a model-free framework for factor importance ranking and selection using total Sobol' indices, offering a computationally efficient and consistent approach to identifying key factors in regression and classification tasks. Together, these talks highlight cutting-edge advancements in experimental design, optimization, and factor analysis, with broad applications across scientific and engineering disciplines.

We list the speakers and title of their talks below. 

\begin{enumerate}
\item Simon Mak, Assistant Professor, Department of Statistical Science at Duke University. \\
Talk title: QuIP: Experimental design for expensive simulators with many Qualitative factors via Integer Programming

% Abstract: The need to explore and/or optimize expensive simulators with many qualitative factors arises in broad scientific and engineering problems. Our motivating application lies in path planning -- the exploration of feasible paths for navigation, which plays an important role in robotics, surgical planning and assembly planning. Here, the feasibility of a path is evaluated via expensive virtual experiments, and its parameter space is typically discrete and high-dimensional. A carefully selected experimental design is thus essential for timely decision-making. We propose here a novel framework, called QuIP, for experimental design of Qualitative factors via integer programming under a Gaussian process surrogate model with exchangeable covariance kernel. For initial design, we show that its asymptotic D-optimal design can be formulated as a variant of the well-known assignment problem in operations research, which can be efficiently solved to global optimality using state-of-the-art integer programming solvers. For sequential design (specifically, for active learning or black-box optimization), we show that its design criterion can similarly be formulated as an assignment problem, thus enabling efficient and reliable optimization with existing solvers. We then demonstrate the effectiveness of QuIP over existing methods in a suite of path planning experiments and an application to rover trajectory optimization.

\item Chih-Li Sung, Assistant Professor in the Department of Statistics and Probability at Michigan State University.\\
Talk title: Stacking designs: designing multi-fidelity computer experiments with target predictive accuracy
% Abstract: In an era where scientific experiments can be very costly, multi-fidelity emulators provide a useful tool for cost-efficient predictive scientific computing. For scientific applications, the experimenter is often limited by a tight computational budget, and thus wishes to (i) maximize predictive power of the multi-fidelity emulator via a careful design of experiments, and (ii) ensure this model achieves a desired error tolerance with some notion of confidence. Existing design methods, however, do not jointly tackle objectives (i) and (ii). Inspired by the Multilevel Monte Carlo (MLMC) methods, we propose a novel stacking design approach that addresses both goals. A multi-level reproducing kernel Hilbert space (RKHS) interpolator is first introduced to build the emulator, under which our stacking design provides a sequential approach for designing multi-fidelity runs such that a desired prediction error is met under regularity assumptions. We then prove a novel cost complexity theorem that, under this multi-level interpolator, establishes a bound on the computation cost (for training data simulation) needed to achieve a prediction bound. This result provides novel insights on conditions under which the proposed multi-fidelity approach improves upon a conventional RKHS interpolator which relies on a single fidelity level.

\item Qian Xiao, Associate Professor in the Department of Statistics, School of Mathematical Sciences at Shanghai Jiao Tong University, Shanghai, China. \\
Talk title: Optimal Design of Experiments With Quantitative-sequence Factors
% Abstract: A new type of experiments with joint considerations of quantitative and sequence factors are recently drawing much attention in medical science, bio-engineering and many other disciplines. The input spaces of such experiments are semi-discrete and often very large. Thus, efficient and economic experimental designs are required. Based on the transformations and aggregations of good lattice point sets, we construct a new class of optimal quantitative-sequence (QS) designs which are marginally coupled, pair-balanced, space-filling and asymptotically orthogonal. The proposed QS designs have certain flexibility in run and factor sizes, and are especially appealing for high-dimensional cases.
\item Chaofan Huang, Ph.D. student in the School of Industrial and Systems Engineering at Georgia Institute of Technology. \\
Title: Factor Importance Ranking and Selection using Total Indices
% Abstract: Factor importance measures the impact of each feature on output prediction accuracy. In this paper, we focus on the intrinsic importance as proposed by Williamson et al. (2023), which defines the importance of a factor as the reduction in predictive potential when that factor is removed. To bypass the modeling step required by the existing estimator, we present the equivalence between predictiveness potential and total Sobol' indices from global sensitivity analysis, and introduce a novel model-free consistent estimator that can be directly computed from noisy data. Integrating with forward selection and backward elimination gives rise to FIRST, Factor Importance Ranking and Selection using Total (Sobol') indices. Extensive simulations are provided to demonstrate the effectiveness of FIRST on regression and binary classification problems, and a clear advantage over the state-of-the-art methods.
\end{enumerate}

\end{talk}

\begin{talk}
  {Stochastic Optimization}% [1] talk title
  {1}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Wed, July 30 14:00–16:00 Track F}% [7] time slot
  {S19}% [8] talk id
  {S19}% [9] session id or photo
  {\organizer{Shane G. Henderson}% organizer one name
    {Cornell University}% orgnizer one affiliations
    {sgh9@cornell.edu}}% organizer one email
%  {\organizer{Name two}% organizer two name, if needed
%	{Affiliation(s) two}% orgnizer two affiliations, if needed
%	{organizer-two-email-goes@here}}% organizer two email
%  {\organizer{Name three}% organizer one name
%	{Affiliation(s) three}% orgnizer one affiliations
%	{organizer-three-email-goes@here}}% organizer one email

~In many applications, one wishes to solve an optimization problem
$\min_{x \in X} f(x)$, where $f(\cdot)$ and/or its derivatives can
only be evaluated through noisy estimates obtained using Monte Carlo
simulation. Such problems are ubiquitous in machine learning, and also
arise in stochastic simulation applications. This session will consist
of 3 talks in the area.

Proposed Speakers
\begin{enumerate}
\item Raghu Bollapragada, Graduate Program in Operations Research and Industrial Engineering, University of Texas
  at Austin.
\item Raghu Pasupathy, Department of Statistics, Purdue University.
\item Shane G. Henderson, School of Operations Research and Information
    Engineering, Cornell University.
\end{enumerate}

\medskip

%If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
%Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.
%APA reference style is recommended.
%\begin{enumerate}
%	\item[{[1]}] Niederreiter, Harald (1992). {\it Random number generation and quasi-Monte Carlo methods}. Society for Industrial and Applied Mathematics (SIAM).
%	\item[{[2]}] Roberts, Gareth O, \& Rosenthal, Jeffrey S. (2002).  Optimal scaling for various Metropolis-Hastings algorithms, \textbf{16}(4), 351--367.
%\end{enumerate}

%Equations may be used if they are referenced. Please note that the equation numbers may be different (but will be cross-referenced correctly) in the final program book.

\end{talk}

\begin{talk}
  {Recent Progress on Algorithmic Discrepancy Theory and Applications}% [1] talk title
  {1}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Wed, July 30 14:00–16:00 Track G}% [7] time slot
  {S20}% [8] talk id
  {S20}% [9] session id or photo
  {\organizer{Haotian Jiang}% organizer one name
    {University of Chicago}% orgnizer one affiliations
    {jhtdavid@uchicago.edu}}% organizer one email
 %  {\organizer{Name two}% organizer two name, if needed
	% {Affiliation(s) two}% orgnizer two affiliations, if needed
	% {organizer-two-email-goes@here}}% organizer two email
 %  {\organizer{Name three}% organizer one name
	% {Affiliation(s) three}% orgnizer one affiliations
	% {organizer-three-email-goes@here}}% organizer one email

%Your special session abstract goes here, including the list of speakers and their affiliations. Please do not use your own commands or macros.

Discrepancy theory studies the irregularities of distributions. Typical questions studied in discrepancy theory include: ``What is the most uniform way of distributing n points in the unit square, and how big must the irregularity be?'', ``What is the best way to divide a set of $n$ objects into two groups that are as 'similar' as possible?'' These questions have been studied since the 1930s and progress on them have found extensive applications to many areas of mathematics, computer science, statistics, finance, etc. 

The past decade has seen tremendous progress in designing efficient algorithms for discrepancy questions. These developments have led to many surprising applications in areas such as differential privacy, graph sparsification, approximation algorithms and rounding, kernel density estimation, randomized controlled trials, and quasi-Monte Carlo methods. 

The goal of this special session is to present several exciting recent progress in this direction, and to facilitate cross-fertilization across different areas. Tentative list of speakers:  
\begin{enumerate}
    \item Haotian Jiang. University of Chicago, USA. \texttt{jhtdavid@uchicago.edu}. 
    \item Peng Zhang. Rutgers University, USA. \texttt{pz149@rutgers.edu}. 
    \item Aleksandar Nikolov. University of Toronto. \texttt{anikolov@cs.toronto.edu}.
\end{enumerate}

\medskip



% If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
% Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.

A few related recent papers in this direction are listed below. 

\begin{enumerate}
\item [{[1]}] Harshaw, Christopher, Fredrik Sävje, Daniel A. Spielman, and Peng Zhang (2024). {\it Balancing covariates in randomized experiments with the gram–schmidt walk design.} Journal of the American Statistical Association 119, no. 548 (2024): 2934-2946.
\item[{[2]}] Bansal, Nikhil, and Haotian Jiang (2025). {\it Quasi-Monte Carlo Beyond Hardy-Krause.} In Proceedings of the 2025 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 2051-2075. Society for Industrial and Applied Mathematics, 2025. 
\item [{[3]}] Aistleitner, Christoph, Dmitriy Bilyk, and Aleksandar Nikolov (2016). {\it Tusnády’s problem, the transference principle, and non-uniform QMC sampling.} In Monte Carlo and Quasi-Monte Carlo Methods: MCQMC 2016, Stanford, CA, August 14-19 12, pp. 169-180. Springer International Publishing, 2018.
	% \item[{[1]}] Niederreiter, Harald (1992). {\it Random number generation and quasi-Monte Carlo methods}. Society for Industrial and Applied Mathematics (SIAM).
	% \item[{[2]}] L’Ecuyer, Pierre, \& Christiane Lemieux. (2002). Recent advances in randomized quasi-Monte Carlo methods. Modeling uncertainty: An examination of stochastic theory, methods, and applications, 419-474.
\end{enumerate}

% Equations may be used if they are referenced. Please note that the equation numbers may be different (but will be cross-referenced correctly) in the final program book.
  
\end{talk}

\begin{talk}
  {Monte Carlo Applications in High-performance Computing, Computer Graphics, and Computational Science}% [1] talk title
  {1}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Wed, July 30 14:00–16:00 Track H}% [7] time slot
  {S21}% [8] talk id
  {S21}% [9] session id or photo
  {\organizer{Michael Mascagni}% organizer one name
    {Florida State University and the National Institute of Standards and Technology}% orgnizer one affiliations
    {mascagni@fsu.edu}}% organizer one email
  {\organizer{Name two}% organizer two name, if needed
	{Affiliation(s) two}% orgnizer two affiliations, if needed
	{organizer-two-email-goes@here}}% organizer two email
  {\organizer{Name three}% organizer one name
	{Affiliation(s) three}% orgnizer one affiliations
	{organizer-three-email-goes@here}}% organizer one email

Monte Carlo methods are useful for solving problems in a variety of areas.  We have four talks organized that span several areas.  First, we consider the how Monte Carlo methods can provide fault tolerance to large computations via work on simulating soft and hard faults in Monte Carlo computation on a state-of-the-art computer.  Next, we consider using Monte Carlo to create a fast and efficient computer graphics renderer. Next we consider two talks on applications of Monte Carlo to the solution of partial differential equations.  One of these talks deals specifically with equations that arise in financial computing.

The list of proposed speakers is (in alphabetical order):
\begin{enumerate}
\item Arash Fahim, Department of Mathematics, Florida State University
\item Sharanya Jayaraman, Department of Computer Science, Florida State University
\item Rohan Sawahney, High-Fidelity Physics Research Group, Nvidia Corporation
\item Silei Song, Department of Computer Science, Florida State University
\end{enumerate}

\medskip

%If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
%Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.

%\begin{enumerate}
%	\item[{[1]}] Niederreiter, Harald (1992). {\it Random number generation and quasi-Monte Carlo methods}. Society for Industrial and Applied Mathematics (SIAM).
%	\item[{[2]}] L’Ecuyer, Pierre, \& Christiane Lemieux. (2002). Recent advances in randomized quasi-Monte Carlo methods. Modeling uncertainty: An examination of stochastic theory, methods, and applications, 419-474.
%\end{enumerate}

%Equations may be used if they are referenced. Please note that the equation numbers may be different (but will be cross-referenced correctly) in the final program book.
  
\end{talk}

\begin{talk}
  {QMC and Applications Part II}% [1] talk title
  {3}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Thu, July 31 10:30–12:30 Track A}% [7] time slot
  {S22}% [8] talk id
  {S22}% [9] session id or photo
  {\organizer{Michael Gnewuch}% organizer one name
    {University of Osnabrück}% orgnizer one affiliations
    {michael.gnewuch@uni-osnabrueck.de}}% organizer one email
  {\organizer{Takashi Goda}% organizer two name, if needed
	{The University of Tokyo}% orgnizer two affiliations, if needed
	{goda@frcer.t.u-tokyo.ac.jp}}% organizer two email
  {\organizer{Peter Kritzer}% organizer three name
	{Austrian Academy of Sciences}% orgnizer three affiliations
	{peter.kritzer@oeaw.ac.at}}% organizer three email

%Your special session abstract goes here, including the list of speakers and their affiliations. Please do not use your own commands or macros.
Quasi-Monte Carlo (QMC) methods have been widely studied as an effective tool for high-dimensional integration and have found applications in various fields, including computational finance, computer graphics, data compression, partial differential equations with random coefficients, and %recently also 
optimization.
Despite their success, ongoing theoretical developments and the expansion of application areas continue to drive this research field forward. This special session is devoted to showcasing recent advances in the theory of QMC methods and their applications.

The confirmed speakers (in alphabetical order) are
\begin{itemize}
\item Dirk Nuyens (KU Leuven, Belgium) 
\item Art Owen (Stanford University, USA)
\item Zexin Pan (Austrian Academy of Sciences, Austria)
\item Kosuke Suzuki (Yamagata University, Japan)
\end{itemize}


\iffalse
If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.

\begin{enumerate}
	\item[{[1]}] Niederreiter, Harald (1992). {\it Random number generation and quasi-Monte Carlo methods}. Society for Industrial and Applied Mathematics (SIAM).
	\item[{[2]}] L’Ecuyer, Pierre, \& Christiane Lemieux. (2002). Recent advances in randomized quasi-Monte Carlo methods. Modeling uncertainty: An examination of stochastic theory, methods, and applications, 419-474.
\end{enumerate}

Equations may be used if they are referenced. Please note that the equation numbers may be different (but will be cross-referenced correctly) in the final program book.
\fi 

\end{talk}

\begin{talk}
  {3}% [1] talk title
  {}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Thu, July 31 10:30–12:30 Track B}% [7] time slot
  {S23}% [8] talk id
  {S23}% [9] session id or photo
  {\organizer{Yifan Chen}% organizer one name
    {Courant Institute of Mathematical Sciences, New York University}% orgnizer one affiliations
    {yifan.chen@nyu.edu}}% organizer one email
  {\organizer{Xiaoou Cheng}% organizer two name, if needed
	{Courant Institute of Mathematical Sciences, New York University}% orgnizer two affiliations, if needed
	{chengxo@nyu.edu}}% organizer two email
    {\organizer{Jonathan Weare}
    {Courant Institute of Mathematical Sciences, New York University}
    {weare@nyu.edu}}
 

% Your special session abstract goes here, including the list of speakers and their affiliations. Please do not use your own commands or macros.

% Many Markov Chain Monte Carlo (MCMC) samplers follow certain stochastic dynamics. Unadjust Langevin algorithm provides a conceptual starting point for a giant family of extensions, which include the kinetic/underdamped Langevin, Hamiltonian Monte Carlo, and No-U-Turn Sampler (NUTS).

Many Markov Chain Monte Carlo (MCMC) samplers are based on stochastic dynamics. Langevin dynamics serves as a fundamental basis for a vast family of extensions, such as unadjusted Langevin algorithms, kinetic/underdamped Langevin algorithms, Hamiltonian Monte Carlo, and the No-U-Turn Sampler (NUTS). The gradient flow structure of Langevin dynamics also motivates the development of a large class of novel algorithms such as stein variational gradient descent, birth-death process approaches, and those based on Fisher-Rao gradient flows. These methods have become ubiquitous across various fields, including molecular dynamics, Bayesian statistics, and machine learning. Recent years have seen significant theoretical advances in analyzing such methods, particularly in high-dimensional settings and non-convex cases. This special session aims to bring together researchers from different communities (probability, statistics, scientific computing, theoretical computer science, machine learning, etc.)\ working on analysis of sampling dynamics of Langevin and beyond to present recent progress, discuss challenges, and share ideas. 

[\textbf{To conference organizers}: One of our speakers in our two-part sessions has other commitment until July 30. Thus, we prefer both of our sessions to be scheduled during July 31 -- Aug 1. July 30 is also acceptable if the later dates are impossible. We really appreciate your help to make our sessions possible.]


%%%%%% REMEMBER %%%%%%
\medskip
\textbf{List of speakers}: 
\begin{enumerate}
    \item Nawaf Bou-Rabee, Rutgers University 
    \item Lihan Wang, Carnegie Mellon University
    \item Peter A.~Whalley, ETH Zurich
    \item Xiaoou Cheng, New York University
\end{enumerate}

% If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
% Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.

% \begin{enumerate}
% 	\item[{[1]}] Niederreiter, Harald (1992). {\it Random number generation and quasi-Monte Carlo methods}. Society for Industrial and Applied Mathematics (SIAM).
% 	\item[{[2]}] L’Ecuyer, Pierre, \& Christiane Lemieux. (2002). Recent advances in randomized quasi-Monte Carlo methods. Modeling uncertainty: An examination of stochastic theory, methods, and applications, 419-474.
% \end{enumerate}

% Equations may be used if they are referenced. Please note that the equation numbers may be different (but will be cross-referenced correctly) in the final program book.
  
\end{talk}

\begin{talk}
  {Nested expectations: models and estimators, Part II}% [1] talk title
  {Arved Bartuska}% [2] speaker name
  {King Abdullah University of Science and Technology/RWTH Aachen University}% [3] affiliations
  {arved.bartuska@kaust.edu.sa}% [4] email
  {Abdul-Lateef Haji-Ali}% [5] coauthors
  {Heriot-Watt University}% [6] special session
  {Thu, July 31 10:30–12:30 Track C}% [7] time slot
  {S24}% [8] talk id
  {S24}% [9] session id or photo

Nested expectations arise in many applications, such as in engineering, mathematical finance, and medical decision-making. In addition to their nested structure, numerical estimations of such expectations are often complicated by singularities or discontinuities. Moreover, approximations when evaluating inner expectations using, for example, finite element or time-stepping schemes render traditional estimation methods such as double-loop Monte Carlo prohibitively expensive. This session will explore models and applications with this structure and methods for efficient estimation.

List of speakers:

Ra\'{u}l Tempone (King Abdullah University of Science and Technology/RWTH Aachen University)

Andr\'{e} Gustavo Carlon (RWTH Aachen University)

Zhijian He (South China University of Technology)

Philipp Guth (Johann Radon Institute for Computational and Applied Mathematics)

\end{talk}

\begin{talk}
  {QMC and Applications Part II}% [1] talk title
  {3}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Thu, July 31 15:30–17:30 Track F}% [7] time slot
  {S25}% [8] talk id
  {S25}% [9] session id or photo
  {\organizer{Michael Gnewuch}% organizer one name
    {University of Osnabrück}% orgnizer one affiliations
    {michael.gnewuch@uni-osnabrueck.de}}% organizer one email
  {\organizer{Takashi Goda}% organizer two name, if needed
	{The University of Tokyo}% orgnizer two affiliations, if needed
	{goda@frcer.t.u-tokyo.ac.jp}}% organizer two email
  {\organizer{Peter Kritzer}% organizer three name
	{Austrian Academy of Sciences}% orgnizer three affiliations
	{peter.kritzer@oeaw.ac.at}}% organizer three email

%Your special session abstract goes here, including the list of speakers and their affiliations. Please do not use your own commands or macros.
Quasi-Monte Carlo (QMC) methods have been widely studied as an effective tool for high-dimensional integration and have found applications in various fields, including computational finance, computer graphics, data compression, partial differential equations with random coefficients, and %recently also 
optimization.
Despite their success, ongoing theoretical developments and the expansion of application areas continue to drive this research field forward. This special session is devoted to showcasing recent advances in the theory of QMC methods and their applications.

The confirmed speakers (in alphabetical order) are
\begin{itemize}
\item Dirk Nuyens (KU Leuven, Belgium) 
\item Art Owen (Stanford University, USA)
\item Zexin Pan (Austrian Academy of Sciences, Austria)
\item Kosuke Suzuki (Yamagata University, Japan)
\end{itemize}


\iffalse
If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.

\begin{enumerate}
	\item[{[1]}] Niederreiter, Harald (1992). {\it Random number generation and quasi-Monte Carlo methods}. Society for Industrial and Applied Mathematics (SIAM).
	\item[{[2]}] L’Ecuyer, Pierre, \& Christiane Lemieux. (2002). Recent advances in randomized quasi-Monte Carlo methods. Modeling uncertainty: An examination of stochastic theory, methods, and applications, 419-474.
\end{enumerate}

Equations may be used if they are referenced. Please note that the equation numbers may be different (but will be cross-referenced correctly) in the final program book.
\fi 

\end{talk}

\begin{talk}
  {3}% [1] talk title
  {}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Thu, July 31 15:30–17:30 Track G}% [7] time slot
  {S26}% [8] talk id
  {S26}% [9] session id or photo
  {\organizer{Yifan Chen}% organizer one name
    {Courant Institute of Mathematical Sciences, New York University}% orgnizer one affiliations
    {yifan.chen@nyu.edu}}% organizer one email
  {\organizer{Xiaoou Cheng}% organizer two name, if needed
	{Courant Institute of Mathematical Sciences, New York University}% orgnizer two affiliations, if needed
	{chengxo@nyu.edu}}% organizer two email
    {\organizer{Jonathan Weare}
    {Courant Institute of Mathematical Sciences, New York University}
    {weare@nyu.edu}}
 

% Your special session abstract goes here, including the list of speakers and their affiliations. Please do not use your own commands or macros.

% Many Markov Chain Monte Carlo (MCMC) samplers follow certain stochastic dynamics. Unadjust Langevin algorithm provides a conceptual starting point for a giant family of extensions, which include the kinetic/underdamped Langevin, Hamiltonian Monte Carlo, and No-U-Turn Sampler (NUTS).

Many Markov Chain Monte Carlo (MCMC) samplers are based on stochastic dynamics. Langevin dynamics serves as a fundamental basis for a vast family of extensions, such as unadjusted Langevin algorithms, kinetic/underdamped Langevin algorithms, Hamiltonian Monte Carlo, and the No-U-Turn Sampler (NUTS). The gradient flow structure of Langevin dynamics also motivates the development of a large class of novel algorithms such as stein variational gradient descent, birth-death process approaches, and those based on Fisher-Rao gradient flows. These methods have become ubiquitous across various fields, including molecular dynamics, Bayesian statistics, and machine learning. Recent years have seen significant theoretical advances in analyzing such methods, particularly in high-dimensional settings and non-convex cases. This special session aims to bring together researchers from different communities (probability, statistics, scientific computing, theoretical computer science, machine learning, etc.)\ working on analysis of sampling dynamics of Langevin and beyond to present recent progress, discuss challenges, and share ideas.

[\textbf{To conference organizers}: One of our speakers in our two-part sessions has other commitment until July 30. Thus, we prefer both of our sessions to be scheduled during July 31 -- Aug 1. July 30 is also acceptable if the later dates are impossible. We really appreciate your help to make our sessions possible.]

%%%%%% REMEMBER %%%%%%
\medskip
\textbf{List of speakers}: 
\begin{enumerate}
    \item Molei Tao, Georgia Institute of Technology 
    \item Krishnakumar Balasubramanian, University of California, Davis
    \item Yifan Chen, New York University
    \item Siddharth Mitra, Yale University
\end{enumerate}

% If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
% Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.

% \begin{enumerate}
% 	\item[{[1]}] Niederreiter, Harald (1992). {\it Random number generation and quasi-Monte Carlo methods}. Society for Industrial and Applied Mathematics (SIAM).
% 	\item[{[2]}] L’Ecuyer, Pierre, \& Christiane Lemieux. (2002). Recent advances in randomized quasi-Monte Carlo methods. Modeling uncertainty: An examination of stochastic theory, methods, and applications, 419-474.
% \end{enumerate}

% Equations may be used if they are referenced. Please note that the equation numbers may be different (but will be cross-referenced correctly) in the final program book.
  
\end{talk}

\begin{talk}
  {Recent Advances in Stochastic Gradient Descent}% [1] talk title
  {1}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Thu, July 31 15:30–17:30 Track H}% [7] time slot
  {S27}% [8] talk id
  {S27}% [9] session id or photo
  {\organizer{Jing Dong}% organizer one name
    {Columbia University}% orgnizer one affiliations
    {jing.dong@gsb.columbia.edu}}% organizer one email
  %{\organizer{Name two}% organizer two name, if needed
	%{Affiliation(s) two}% orgnizer two affiliations, if needed
	%{organizer-two-email-goes@here}}% organizer two email
  %{\organizer{Name three}% organizer one name
	%{Affiliation(s) three}% orgnizer one affiliations
	%{organizer-three-email-goes@here}}% organizer one email

Stochastic Gradient Descent (SGD) is a cornerstone optimization method in machine learning,
renowned for its efficiency in handling large-scale data. Its iterative approach enables
the processing of extensive datasets by updating model parameters using randomly selected
data subsets, thereby reducing computational costs. Despite its widespread adoption, traditional
SGD faces challenges such as convergence to sharp minima, and sensitivity to data
distribution shifts. Addressing these challenges is crucial for enhancing model generalization,
robustness, and overall performance in diverse applications. This session aims to delve into
recent developments that address these challenges in SGD, presenting innovative methodologies
and theoretical insights to enhance its effectiveness in complex learning scenarios.

The session will have three to four speakers. Currently, the confirmed speakers are Jose
Blanchet (Stanford University), Chang-Han Rhee (Northwestern University), and Jing Dong
(Columbia University). Each will present their recent works on stochastic gradient descent,
ranging from SGD and heavy-tailed phenomenon to SGD with adaptively generated data.

Collectively, these talks will shed light on cutting-edge advancements in SGD methodologies,
providing both theoretical frameworks and practical strategies to enhance optimization in
complex, real-world applications.

\end{talk}

\begin{talk}
  {Forward and Inverse Problems for Stochastic Reaction Networks}% [1] talk title
  {3}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Fri, August 1 9:00–10:30 Track A}% [7] time slot
  {S28}% [8] talk id
  {S28}% [9] session id or photo
  {\organizer{Sophia Münker}% organizer one name
    {RWTH Aachen University}% orgnizer one affiliations
    {muenker@uq.rwth-aachen.de}}% organizer one email
  {\organizer{Chiheb Ben Hammouda}% organizer two name, if needed
	{Utrecht University}% orgnizer two affiliations, if needed
	{c.benhammouda@uu.nl}}% organizer two email
  {\organizer{Raúl Tempone}% organizer one name
	{RWTH Aachen University}% orgnizer one affiliations
	{tempone@uq.rwth-aachen.de}}% organizer one email

This session aims to bring together experts working on stochastic reaction networks and pure jump processes for modeling stochastic biological and chemical systems. The session is about recent advances in Monte Carlo methods, variance and dimension reduction techniques that are relevant for tackling forward and inverse problems.

\medskip
The speakers are:
\begin{itemize}
    \item Zhou Fang (Academy of Mathematics and Systems Science, Chinese Academy of Sciences)
    \item Sophia Münker (RWTH Aachen University)
    \item Maksim Chupin (King Abdullah University of Science and Technology (KAUST))
    \item Muruhan Rathinam (University of Maryland Baltimore County)
\end{itemize}
  
\end{talk}

\begin{talk}
  {Hardware or Software for (Quasi-)Monte Carlo Algorithms}% [1] talk title
  {3}% [2] speaker name
  {}% [3] affiliations
  {}% [4] email
  {}% [5] coauthors
  {}% [6] special session
  {Fri, August 1 9:00–10:30 Track B}% [7] time slot
  {S29}% [8] talk id
  {S29}% [9] session id or photo
  {\organizer{Sou-Cheng T.  Choi}% organizer one name
    {Illinois Institute of Technology}% orgnizer one affiliations
    {schoi32@iit.edu}}% organizer one email
  {\organizer{Pieterjan Robbe}% organizer two name, if needed
	{Sandia National Laboratories}% orgnizer two affiliations, if needed
	{pmrobbe@sandia.gov}}% organizer two email
  {\organizer{Mike Giles}% organizer one name
	{University of Oxford}% orgnizer one affiliations
	{mike.giles@maths.ox.ac.uk}}% organizer one email

Monte Carlo (MC) or quasi-Monte Carlo (QMC) algorithms are widely used in various fields such as finance, physics, and engineering for their ability to handle high-dimensional integration problems. The development and maintenance of software for (quasi-)Monte Carlo ((Q)MC) algorithms can significantly enhance the accessibility and usability of these techniques. This special session aims to bring together experts from academia and industry to discuss recent advances in (Q)MC software, share best practices, and explore future directions, fostering collaboration among researchers and practitioners.

Topics of interest for the session include:
\begin{itemize}
    \item Novel hardware or architectural designs for open-source (Q)MC libraries.
    \item Best collaborative practices for developing and maintaining efficient and reliable (Q)MC software.
    \item Challenges and opportunities in integrating (Q)MC methods with machine learning and AI techniques.
    \item High-performance computing solutions for (Q)MC software.
    \item Adaptation of (Q)MC software to application fields such as finance, computer graphics, sensitivity analysis, Bayesian optimization, and uncertainty quantification.
    \item Innovative approaches to enhancing and extending existing (Q)MC tools.
\end{itemize}


Committed Speakers and Topics:
\begin{itemize}
\item Part 1 of the Special Session:
\begin{itemize}
    \item Speaker 1: Pieterjan Robbe, Sandia National Laboratories, Multifidelity QMC development in Dakota (https://dakota.sandia.gov/), \texttt{pmrobbe@sandia.gov}
    \item Speaker 2: Irina-Beatrice Haas, University of Oxford,  MLMC for FPGAs, \newline \texttt{Irina-Beatrice.Haas@maths.ox.ac.uk} 
    \item Speaker 3: Mike Giles, University of Oxford, CUDA implementation of MLMC (\url{https://people.maths.ox.ac.uk/gilesm/mlmc/}), \texttt{mike.giles@maths.ox.ac.uk}
    \item Speaker 4: Chung Ming Loi,  Durham University, UM-Bridge (\url{https://github.com/um-bridge}), \texttt{chung.m.loi@durham.ac.uk} %PhD student of Anne Reinarz 
\end{itemize}
\item Part 2 of the Special Session:
\begin{itemize}
    \item Speaker 5:  Niklas Baumgarten, University of Heidelberg, Software for Multilevel Monte Carlo Methods, \texttt{niklas.baumgarten@uni-heidelberg.de}
    \item Speaker 6: Aleksei Sorokin,  Illinois Institute of Technology, QMCPy's Randomization Routines and Fast Kernel Interpolation, \texttt{asorokin@hawk.iit.edu}
    \item Speaker 7:  Johannes Krotz, University of Notre Dame, Methods and Software for Hybrid Q/MC Solvers for Radiation Transport, \texttt{jkrotz@nd.edu} %postdoc of Ryan McClarren
    \item Speaker 8: Joseph Farmer, University of Notre Dame, High Performance Calculations of Radiation Emission from High Temperature Fluid Flow, \texttt{jfarmer4@nd.edu} % PhD Student of Ryan McClarren

\end{itemize}
\end{itemize}


\medskip
\begin{comment}
If you would like to include references, please do so by creating a simple list numbered by [1], [2], [3], \ldots. See example below.
Please do not use the \texttt{bibliography} environment or \texttt{bibtex} files.
%APA reference style is recommended.
\begin{enumerate}
	\item[{[1]}] Niederreiter, Harald (1992). {\it Random number generation and quasi-Monte Carlo methods}. Society for Industrial and Applied Mathematics (SIAM).
	\item[{[2]}] Roberts, Gareth O, \& Rosenthal, Jeffrey S. (2002).  Optimal scaling for various Metropolis-Hastings algorithms, \textbf{16}(4), 351--367.
\end{enumerate}

Equations may be used if they are referenced. Please note that the equation numbers may be different (but will be cross-referenced correctly) in the final program book.
\end{comment}
\end{talk}
